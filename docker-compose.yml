services:
  mlflow:
    image: ghcr.io/mlflow/mlflow:latest
    container_name: mlflow
    ports:
      - "5001:5000"
    env_file:
      - config.env
    environment:
      MLFLOW_S3_ENDPOINT_URL: https://s3.amazonaws.com
    command: >
      mlflow server
      --backend-store-uri s3://mlops24-haowei-bucket/mlruns
      --default-artifact-root s3://mlops24-haowei-bucket/artifacts
      --host 0.0.0.0
      --port 5000
    restart: unless-stopped

  web:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: fastapi_app
    depends_on:
      - mlflow
    env_file:
      - config.env
    ports:
      - "8000:8000"
    environment:
      ENV: production
      MODEL_PATH: /app/models/model.joblib
      MLFLOW_TRACKING_URI: http://mlflow:5000
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
