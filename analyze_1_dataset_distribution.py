"""
Script 1: Dataset Distribution Analysis
========================================
Analiza la distribuci√≥n de clases, balance, y estad√≠sticas b√°sicas.

Usage:
    python3 analyze_1_dataset_distribution.py
"""

import pandas as pd
import numpy as np
from pathlib import Path
import sys

def analyze_dataset_distribution():
    """An√°lisis completo de distribuci√≥n del dataset."""
    
    # Paths
    data_path = Path("data/processed/turkish_music_emotion_v2_cleaned_full.csv")
    
    if not data_path.exists():
        print(f"‚ùå ERROR: No se encontr√≥ {data_path}")
        sys.exit(1)
    
    # Cargar dataset
    print("üìÇ Cargando dataset...")
    df = pd.read_csv(data_path)
    
    # Normalizar labels
    df['Class'] = df['Class'].str.strip().str.lower()
    
    print("\n" + "=" * 70)
    print("üìä AN√ÅLISIS DE DISTRIBUCI√ìN DE CLASES")
    print("=" * 70)
    
    # Distribuci√≥n b√°sica
    class_counts = df['Class'].value_counts().sort_index()
    print("\n1Ô∏è‚É£ Conteo de samples por clase:")
    print("-" * 50)
    for emotion, count in class_counts.items():
        pct = (count / len(df)) * 100
        bar = "‚ñà" * int(pct / 2)
        print(f"  {emotion:10s}: {count:3d} samples ({pct:5.1f}%) {bar}")
    
    print(f"\nüìä Total samples: {len(df)}")
    print(f"üìä Total features: {len(df.columns) - 1}")
    
    # Balance metrics
    print("\n2Ô∏è‚É£ M√©tricas de balance:")
    print("-" * 50)
    min_class = class_counts.min()
    max_class = class_counts.max()
    balance_ratio = min_class / max_class
    
    print(f"  Clase m√°s grande: {class_counts.idxmax()} ({max_class} samples)")
    print(f"  Clase m√°s peque√±a: {class_counts.idxmin()} ({min_class} samples)")
    print(f"  Balance ratio (min/max): {balance_ratio:.2%}")
    
    if balance_ratio < 0.70:
        print(f"  ‚ö†Ô∏è  ADVERTENCIA: Dataset desbalanceado (ratio < 70%)")
    else:
        print(f"  ‚úÖ Dataset razonablemente balanceado")
    
    # Estad√≠sticas por clase
    print("\n3Ô∏è‚É£ Estad√≠sticas de features por clase:")
    print("-" * 50)
    
    feature_cols = [col for col in df.columns if col != 'Class']
    
    # Filtrar NaN values antes de ordenar
    unique_classes = df['Class'].dropna().unique()
    
    # Identificar columnas num√©ricas solamente
    numeric_cols = df[feature_cols].select_dtypes(include=[np.number]).columns.tolist()
    non_numeric_cols = [col for col in feature_cols if col not in numeric_cols]
    
    if non_numeric_cols:
        print(f"\n‚ö†Ô∏è  ADVERTENCIA: Se encontraron {len(non_numeric_cols)} columnas NO NUM√âRICAS:")
        for col in non_numeric_cols[:5]:
            print(f"    - {col}")
        if len(non_numeric_cols) > 5:
            print(f"    ... y {len(non_numeric_cols) - 5} m√°s")
        print(f"\n  Usando solo {len(numeric_cols)} columnas num√©ricas para estad√≠sticas")
    
    for emotion in sorted(unique_classes):
        subset = df[df['Class'] == emotion][numeric_cols]
        print(f"\n  {emotion.upper()}:")
        print(f"    Samples: {len(subset)}")
        if len(numeric_cols) > 0:
            print(f"    Features mean: {subset.mean().mean():.4f}")
            print(f"    Features std: {subset.std().mean():.4f}")
            print(f"    Features median: {subset.median().mean():.4f}")
            print(f"    Missing values: {subset.isnull().sum().sum()}")
        else:
            print(f"    ‚ö†Ô∏è  No hay columnas num√©ricas para calcular estad√≠sticas")
    
    # Verificar NaN values
    print("\n4Ô∏è‚É£ Verificaci√≥n de integridad de datos:")
    print("-" * 50)
    total_nans = df[numeric_cols].isnull().sum().sum() if numeric_cols else 0
    if total_nans > 0:
        print(f"  ‚ö†Ô∏è  Se encontraron {total_nans} valores NaN")
    else:
        print(f"  ‚úÖ No hay valores NaN en features num√©ricas")
    
    # Duplicados
    duplicates = df.duplicated().sum()
    print(f"\n  Filas duplicadas: {duplicates}")
    if duplicates > 0:
        print(f"  ‚ö†Ô∏è  Se encontraron {duplicates} filas duplicadas")
    else:
        print(f"  ‚úÖ No hay filas duplicadas")
    
    print("\n" + "=" * 70)
    print("‚úÖ An√°lisis completado")
    print("=" * 70)
    
    return df, class_counts

if __name__ == "__main__":
    df, class_counts = analyze_dataset_distribution()
