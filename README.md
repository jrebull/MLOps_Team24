# ğŸµ Acoustic ML - Music Emotion Recognition

<div align="center">

**MLOps Team 24 - Proyecto de reconocimiento de emociones musicales**

[![Python](https://img.shields.io/badge/Python-3.12-blue.svg)](https://www.python.org/downloads/)
[![MLflow](https://img.shields.io/badge/MLflow-Tracking-0194E2?logo=mlflow)](https://mlflow.org/)
[![DVC](https://img.shields.io/badge/DVC-Data%20Versioning-945DD6?logo=dvc)](https://dvc.org/)
[![AWS S3](https://img.shields.io/badge/AWS-S3-FF9900?logo=amazon-aws)](https://aws.amazon.com/s3/)

<!-- Badges de Estado -->
[![verify-sync](https://img.shields.io/badge/verify--sync-make-blue?logo=gnu&logoColor=white)](#verificaciÃ³n-rÃ¡pida-antes-de-trabajar)
[![dependencies](https://img.shields.io/badge/deps-requirements.txt-informational?logo=python&logoColor=white)](#reproducibilidad-de-entornos)
[![notebooks](https://img.shields.io/badge/notebooks-clean%20outputs-success?logo=jupyter&logoColor=white)](#buenas-prÃ¡cticas-con-notebooks)
[![Tests](https://img.shields.io/badge/tests-37%2F37_passing-success?logo=pytest&logoColor=white)](#-testing-y-validaciÃ³n)
[![Code Quality](https://img.shields.io/badge/code%20quality-production--ready-brightgreen?logo=python&logoColor=white)](#-arquitectura-del-cÃ³digo)
[![Accuracy](https://img.shields.io/badge/accuracy-80.17%25-success?logo=tensorflow&logoColor=white)](#-sklearn-pipeline-end-to-end)
[![Repo Status](https://img.shields.io/badge/repo-clean%20%26%20professional-success?logo=git&logoColor=white)](#-estructura-del-proyecto)

</div>

---

## ğŸ“‹ Tabla de Contenidos

- [Sobre el Proyecto](#-sobre-el-proyecto)
- [InformaciÃ³n AcadÃ©mica](#-informaciÃ³n-acadÃ©mica)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [ğŸ†• Arquitectura del CÃ³digo](#-arquitectura-del-cÃ³digo)
  - [MÃ³dulos Refactorizados](#mÃ³dulos-refactorizados)
  - [Design Patterns Implementados](#design-patterns-implementados)
  - [MÃ©tricas de RefactorizaciÃ³n](#-mÃ©tricas-de-refactorizaciÃ³n)
- [ğŸ†• Sklearn Pipeline End-to-End](#-sklearn-pipeline-end-to-end)
- [ğŸ†• Manejo de Outliers y Robustez](#-manejo-de-outliers-y-robustez)
- [ğŸ†• GuÃ­a de Uso de MÃ³dulos](#-guÃ­a-de-uso-de-mÃ³dulos)
- [ğŸ†• Testing y ValidaciÃ³n](#-testing-y-validaciÃ³n)
- [Datasets Disponibles](#-datasets-disponibles)
- [Requisitos Previos](#-requisitos-previos)
- [InstalaciÃ³n](#-instalaciÃ³n)
- [GestiÃ³n de Datos (DVC + S3)](#-gestiÃ³n-de-datos-dvc--s3)
- [Uso](#-uso--usage)
- [Scripts Disponibles](#-scripts-disponibles)
- [VerificaciÃ³n RÃ¡pida antes de Trabajar](#-verificaciÃ³n-rÃ¡pida-antes-de-trabajar)
- [Docker Compose](#-docker-compose)
- [Limpieza y Mantenimiento](#-limpieza-y-mantenimiento)
- [Arquitectura del Pipeline](#-arquitectura-del-pipeline)
- [ContribuciÃ³n](#-contribuciÃ³n)
- [Equipo](#-equipo)

---

## ğŸ¯ Sobre el Proyecto

Este repositorio contiene la implementaciÃ³n completa de un sistema MLOps para reconocimiento de emociones en mÃºsica turca, siguiendo las mejores prÃ¡cticas de la industria con la estructura **Cookiecutter Data Science**. El proyecto integra un **pipeline sklearn end-to-end completo y listo para producciÃ³n** con las siguientes caracterÃ­sticas:

- ğŸ“Š **Versionado de datos** con DVC
- ğŸ”„ **Pipelines reproducibles** automatizados y compatibles con scikit-learn
- ğŸ“ˆ **Tracking de experimentos** con MLflow
- â˜ï¸ **Almacenamiento en la nube** (AWS S3: mlops24-haowei-bucket)
- ğŸ¤– **Modelos de Machine Learning** versionados (Accuracy: **80.17%**)
- ğŸ—‚ï¸ **Estructura modular** siguiendo estÃ¡ndares de la industria
- ğŸ—ï¸ **Arquitectura OOP** con SOLID principles
- ğŸ§ª **Testing comprehensivo** (37/37 tests passing)
- ğŸ¯ **Pipeline sklearn profesional** compatible con GridSearchCV y cross_val_score
- ğŸ›¡ï¸ **Manejo robusto de outliers** con anÃ¡lisis cuantitativo completo
- ğŸ§¹ **Repositorio limpio y profesional** siguiendo MLOps best practices

### ğŸµ Dataset y Objetivo

**Dataset:** Turkish Music Emotion Dataset  
**Clases:** 4 emociones (Happy, Sad, Angry, Relax)  
**Features:** 50 caracterÃ­sticas acÃºsticas extraÃ­das  
**Objetivo:** ClasificaciÃ³n automÃ¡tica de emociones en mÃºsica turca

---

## ğŸ“˜ InformaciÃ³n AcadÃ©mica

**Instituto TecnolÃ³gico y de Estudios Superiores de Monterrey**  
*MaestrÃ­a en Inteligencia Artificial Aplicada (MNA)*

- **Curso:** Operaciones de Aprendizaje AutomÃ¡tico
- **Periodo:** Septiembre â€“ Diciembre 2024
- **Equipo:** NÂ° 24

### ğŸ‘¨â€ğŸ« Profesores

| Rol | Nombre |
|-----|--------|
| Titular | Dr. Gerardo RodrÃ­guez HernÃ¡ndez |
| Titular | Mtro. Ricardo Valdez HernÃ¡ndez |
| Asistente | Mtra. MarÃ­a Mylen TreviÃ±o Elizondo |
| Tutor | JosÃ© Ãngel MartÃ­nez Navarro |

---

## ğŸ—‚ï¸ Estructura del Proyecto

Organizado siguiendo **Cookiecutter Data Science** para mÃ¡xima reproducibilidad y claridad. La estructura ha sido **auditada y limpiada** para cumplir con estÃ¡ndares MLOps profesionales:

```
MLOps_Team24/
â”‚
â”œâ”€â”€ ğŸ“„ Archivos de ConfiguraciÃ³n (RaÃ­z)
â”‚   â”œâ”€â”€ LICENSE                 <- Licencia del proyecto
â”‚   â”œâ”€â”€ Makefile               <- Comandos Ãºtiles (make data, make train, etc.)
â”‚   â”œâ”€â”€ README.md              <- Este archivo â­
â”‚   â”œâ”€â”€ pyproject.toml         <- ConfiguraciÃ³n del proyecto y dependencias
â”‚   â”œâ”€â”€ requirements.txt       <- Dependencias del proyecto (pip freeze)
â”‚   â”œâ”€â”€ params.yaml            <- ParÃ¡metros del pipeline DVC
â”‚   â”œâ”€â”€ dvc.yaml               <- DefiniciÃ³n del pipeline DVC
â”‚   â”œâ”€â”€ dvc.lock               <- Lock file del pipeline
â”‚   â”œâ”€â”€ data.dvc               <- Metadatos de tracking (versionado en Git)
â”‚   â”œâ”€â”€ docker-compose.yml     <- ConfiguraciÃ³n Docker (MLflow + MinIO)
â”‚   â”œâ”€â”€ config.env             <- Variables de entorno para Docker
â”‚   â”œâ”€â”€ .gitignore             <- Patrones Git (actualizado Fase 2) âœ¨
â”‚   â”œâ”€â”€ .gitattributes         <- Atributos Git
â”‚   â””â”€â”€ .dvcignore             <- Patrones DVC
â”‚
â”œâ”€â”€ ğŸ“‚ acoustic_ml/            <- MÃ³dulo Python principal â­ REFACTORIZADO
â”‚   â”œâ”€â”€ __init__.py            <- Hace de acoustic_ml un mÃ³dulo Python
â”‚   â”œâ”€â”€ config.py              <- ConfiguraciÃ³n y variables globales
â”‚   â”œâ”€â”€ dataset.py             <- GestiÃ³n de datos (650 lÃ­neas, 16 tests) âœ¨
â”‚   â”œâ”€â”€ features.py            <- Feature engineering (930 lÃ­neas, 13 tests) âœ¨
â”‚   â”œâ”€â”€ plots.py               <- Visualizaciones (370 lÃ­neas, 8 tests) âœ¨
â”‚   â””â”€â”€ modeling/              <- SubmÃ³dulo de modelado
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ train.py           <- Entrenamiento de modelos (122 lÃ­neas)
â”‚       â”œâ”€â”€ predict.py         <- Inferencia con modelos (189 lÃ­neas)
â”‚       â”œâ”€â”€ evaluate.py        <- EvaluaciÃ³n de modelos (311 lÃ­neas)
â”‚       â”œâ”€â”€ pipeline.py        <- Pipeline MLOps completo (370 lÃ­neas)
â”‚       â””â”€â”€ sklearn_pipeline.py <- Pipeline sklearn end-to-end â­ PRODUCCIÃ“N
â”‚
â”œâ”€â”€ ğŸ“Š data/                   <- Datos del proyecto (versionados con DVC)
â”‚   â”œâ”€â”€ external/              <- Datos de fuentes externas
â”‚   â”œâ”€â”€ interim/               <- Datos intermedios transformados
â”‚   â”œâ”€â”€ processed/             <- Datasets finales para modelado
â”‚   â”‚   â”œâ”€â”€ turkish_music_emotion_cleaned.csv              (Limpieza inicial)
â”‚   â”‚   â”œâ”€â”€ turkish_music_emotion_v1_original.csv          (400 filas - Baseline)
â”‚   â”‚   â”œâ”€â”€ turkish_music_emotion_v2_cleaned_aligned.csv   (400 filas - ComparaciÃ³n)
â”‚   â”‚   â”œâ”€â”€ turkish_music_emotion_v2_cleaned_full.csv      (408 filas) â­ RECOMENDADO
â”‚   â”‚   â”œâ”€â”€ X_train.csv        <- Training features
â”‚   â”‚   â”œâ”€â”€ X_test.csv         <- Test features
â”‚   â”‚   â”œâ”€â”€ y_train.csv        <- Training labels
â”‚   â”‚   â””â”€â”€ y_test.csv         <- Test labels
â”‚   â””â”€â”€ raw/                   <- Datos originales inmutables (versionados con DVC)
â”‚       â”œâ”€â”€ turkis_music_emotion_original.csv      (125 KB)
â”‚       â”œâ”€â”€ turkish_music_emotion_modified.csv     (130 KB)
â”‚       â””â”€â”€ .gitignore         <- Git ignora los CSV (solo .dvc files en Git)
â”‚
â”œâ”€â”€ ğŸ’¾ models/                 <- Modelos entrenados y serializados
â”‚   â”œâ”€â”€ baseline_model.pkl
â”‚   â””â”€â”€ production_pipeline.pkl
â”‚
â”œâ”€â”€ ğŸ““ notebooks/              <- Jupyter notebooks para exploraciÃ³n
â”‚   â”œâ”€â”€ Fase1_equipo24.ipynb
â”‚   â”œâ”€â”€ NoteBook Testing.ipynb
â”‚   â””â”€â”€ sklearn_pipeline_demo.ipynb  âœ¨ NUEVO
â”‚   
â”‚   ConvenciÃ³n: nÃºmero-iniciales-descripciÃ³n
â”‚   Ej: 1.0-hw-exploratory-analysis.ipynb
â”‚
â”œâ”€â”€ ğŸ“ˆ reports/                <- AnÃ¡lisis generados (HTML, PDF, etc.)
â”‚   â””â”€â”€ figures/               <- GrÃ¡ficas y figuras para reportes
â”‚       â”œâ”€â”€ outlier_analysis.png          <- DistribuciÃ³n de outliers por feature
â”‚       â”œâ”€â”€ outlier_boxplots.png          <- Boxplots de top features con outliers
â”‚       â”œâ”€â”€ outlier_analysis_report.txt   <- Reporte tÃ©cnico completo de outliers
â”‚       â””â”€â”€ scaler_comparison_results.txt <- ComparaciÃ³n StandardScaler vs RobustScaler
â”‚
â”œâ”€â”€ ğŸ“š references/             <- Diccionarios de datos, manuales, documentaciÃ³n externa
â”‚
â”œâ”€â”€ ğŸ› ï¸ scripts/               <- Scripts auxiliares organizados
â”‚   â”œâ”€â”€ train_baseline.py                <- Entrenamiento baseline
â”‚   â”œâ”€â”€ validate_plots.py                <- ValidaciÃ³n de mÃ³dulo plots
â”‚   â”œâ”€â”€ validate_features.py             <- ValidaciÃ³n de mÃ³dulo features
â”‚   â”œâ”€â”€ validate_dataset.py              <- ValidaciÃ³n de mÃ³dulo dataset
â”‚   â”œâ”€â”€ analyze_outliers.py              <- AnÃ¡lisis estadÃ­stico de outliers âœ¨
â”‚   â”œâ”€â”€ compare_scalers.py               <- ComparaciÃ³n empÃ­rica A/B de scalers âœ¨
â”‚   â”œâ”€â”€ test_sklearn_pipeline.py         <- Test de integraciÃ³n del pipeline âœ¨
â”‚   â”œâ”€â”€ test_full_integration.py         <- ValidaciÃ³n completa del sistema âœ¨
â”‚   â”œâ”€â”€ run_full_analysis.py             <- Script maestro de anÃ¡lisis âœ¨
â”‚   â””â”€â”€ temp/                            <- Scripts temporales (no versionados) ğŸ†•
â”‚       â”œâ”€â”€ cleanup_smart.py
â”‚       â””â”€â”€ validate_post_cleanup.py
â”‚
â”œâ”€â”€ ğŸ§ª tests/                  <- Tests unitarios y de integraciÃ³n
â”‚   â””â”€â”€ (37 tests passing)
â”‚
â”œâ”€â”€ ğŸ“Š metrics/                <- MÃ©tricas del pipeline DVC
â”‚   â””â”€â”€ metrics.json
â”‚
â”œâ”€â”€ ğŸ“– docs/                   <- DocumentaciÃ³n detallada del proyecto
â”‚
â”œâ”€â”€ ğŸ³ app/                    <- AplicaciÃ³n Streamlit (deployment) ğŸ†•
â”‚   â””â”€â”€ (dashboard de validaciÃ³n)
â”‚
â”œâ”€â”€ ğŸ“¡ monitoring/             <- Herramientas de monitoreo ğŸ†•
â”‚
â”œâ”€â”€ ğŸ”§ Carpetas de Sistema (NO versionadas en Git) âœ¨
â”‚   â”œâ”€â”€ .venv/                 <- Entorno virtual de Python
â”‚   â”œâ”€â”€ .git/                  <- Control de versiones Git
â”‚   â”œâ”€â”€ .dvc/                  <- ConfiguraciÃ³n de DVC
â”‚   â”œâ”€â”€ mlruns/                <- Experimentos de MLflow (gitignored) âœ¨
â”‚   â”œâ”€â”€ mlartifacts/           <- Artifacts de MLflow (gitignored) âœ¨
â”‚   â”œâ”€â”€ dvcstore/              <- Cache local de DVC (gitignored) âœ¨
â”‚   â””â”€â”€ acoustic_ml.egg-info/  <- Build artifacts (gitignored) âœ¨
â”‚
â””â”€â”€ ğŸ“ Notas:
    âœ¨ = Actualizado en Fase 2
    ğŸ†• = Nuevo en Fase 2
    â­ = Recomendado para uso en producciÃ³n
```

### ğŸ§¹ Limpieza de Repositorio (Fase 2)

En Fase 2 realizamos una **auditorÃ­a completa del repositorio** para garantizar cumplimiento con MLOps best practices:

**Acciones realizadas:**
- âœ… Scripts temporales movidos a `scripts/temp/` (no versionados)
- âœ… `.gitignore` actualizado con patrones crÃ­ticos: `mlruns/`, `mlartifacts/`, `dvcstore/`, `*.egg-info/`
- âœ… Artifacts de MLflow/DVC removidos del tracking de Git
- âœ… Solo archivos de configuraciÃ³n permitidos en raÃ­z
- âœ… Estructura 100% compatible con Cookiecutter Data Science

**Resultado:** Repositorio profesional, limpio y listo para revisiÃ³n acadÃ©mica y producciÃ³n.

---

## ğŸ—ï¸ Arquitectura del CÃ³digo

### ğŸ“Š Resumen Ejecutivo

En la **Fase 2 del proyecto**, realizamos una **refactorizaciÃ³n masiva** del mÃ³dulo `acoustic_ml/` transformÃ¡ndolo de scripts funcionales simples a una **arquitectura MLOps profesional** basada en **OOP** y **SOLID principles**.

**Resultado:**
- **+1,718 lÃ­neas** de cÃ³digo profesional (+740% de crecimiento)
- **15 clases principales** con responsabilidades claras
- **37 tests** comprehensivos (100% passing)
- **100% type hints** y documentaciÃ³n en espaÃ±ol
- **Design patterns** de la industria implementados
- **Pipeline sklearn end-to-end** listo para producciÃ³n â­ NUEVO
- **Repositorio auditado y limpio** segÃºn estÃ¡ndares MLOps âœ¨ NUEVO

---

### MÃ³dulos Refactorizados

#### 1. ğŸ“Š **dataset.py** - GestiÃ³n Profesional de Datos

**Antes:** Script funcional simple  
**Ahora:** MÃ³dulo OOP completo con Singleton pattern

```python
from acoustic_ml.dataset import DatasetManager

# Singleton thread-safe con lazy initialization
manager = DatasetManager()
data = manager.load_dataset("v2_cleaned_full.csv")
manager.validate_schema(data)
```

**Clases principales:**
- `DatasetManager`: Singleton para gestiÃ³n centralizada
- `DataValidator`: ValidaciÃ³n de esquemas y calidad
- `DataSplitter`: Estrategias de split (train/test/stratified)

**CaracterÃ­sticas:**
- âœ… 650 lÃ­neas de cÃ³digo profesional
- âœ… 16 tests unitarios (100% passing)
- âœ… Thread-safe Singleton pattern
- âœ… ValidaciÃ³n automÃ¡tica de schemas
- âœ… Estrategias configurables de split
- âœ… Logging comprehensivo

---

#### 2. âš™ï¸ **features.py** - Feature Engineering Robusto

**Antes:** Transformaciones ad-hoc en notebooks  
**Ahora:** Pipeline modular con transformers especializados

```python
from acoustic_ml.features import create_full_pipeline

# Pipeline completo con RobustScaler
pipeline = create_full_pipeline(
    scaler_type='robust',  # Robusto a outliers
    pca_components=20,
    correlation_threshold=0.95
)

X_transformed = pipeline.fit_transform(X_train)
```

**Transformers especializados:**
- `OutlierHandler`: AnÃ¡lisis y manejo de outliers
- `FeatureScaler`: NormalizaciÃ³n (Standard/Robust/MinMax)
- `CorrelationReducer`: EliminaciÃ³n de correlaciones altas
- `PCAReducer`: ReducciÃ³n de dimensionalidad
- `FeaturePipelineBuilder`: ConstrucciÃ³n modular de pipelines

**CaracterÃ­sticas:**
- âœ… 930 lÃ­neas de cÃ³digo profesional
- âœ… 13 tests unitarios (100% passing)
- âœ… Compatibilidad 100% sklearn
- âœ… Builder pattern para flexibilidad
- âœ… AnÃ¡lisis cuantitativo de outliers (Z-score, IQR, Isolation Forest)
- âœ… RobustScaler por defecto (mejor performance: 80.17% vs 79.17%)

---

#### 3. ğŸ“Š **plots.py** - Visualizaciones Profesionales

**Antes:** Plots dispersos en notebooks  
**Ahora:** Clase centralizada con mÃ©todos especializados

```python
from acoustic_ml.plots import PlotManager

plotter = PlotManager(style='seaborn', figsize=(10, 6))

# Matriz de confusiÃ³n profesional
plotter.plot_confusion_matrix(y_true, y_pred, save_path="reports/figures/")

# AnÃ¡lisis de outliers
plotter.plot_outlier_analysis(X_train, save_path="reports/figures/")
```

**Visualizaciones disponibles:**
- Matrices de confusiÃ³n normalizadas
- Curvas de aprendizaje
- Importancia de features
- Distribuciones y boxplots
- AnÃ¡lisis de outliers
- Correlaciones

**CaracterÃ­sticas:**
- âœ… 370 lÃ­neas de cÃ³digo profesional
- âœ… 8 tests unitarios (100% passing)
- âœ… Estilos consistentes (seaborn/ggplot)
- âœ… Guardado automÃ¡tico en `reports/figures/`
- âœ… ConfiguraciÃ³n global de tamaÃ±os y colores

---

#### 4. ğŸ¯ **modeling/sklearn_pipeline.py** - Pipeline End-to-End â­

**El mÃ¡s importante:** Pipeline completo compatible con sklearn para producciÃ³n

```python
from acoustic_ml.modeling.sklearn_pipeline import create_sklearn_pipeline

# Pipeline completo: preprocessing + modelo
pipeline = create_sklearn_pipeline(
    model_type='random_forest',
    scaler_type='robust',
    pca_components=20
)

# Compatible con toda la API de sklearn
pipeline.fit(X_train, y_train)
y_pred = pipeline.predict(X_test)
score = pipeline.score(X_test, y_test)

# Compatible con GridSearchCV
from sklearn.model_selection import GridSearchCV
grid = GridSearchCV(pipeline, param_grid, cv=5)
grid.fit(X_train, y_train)
```

**CaracterÃ­sticas Ãºnicas:**
- âœ… Encapsula preprocessing + modelo en un Ãºnico objeto
- âœ… Compatible con `GridSearchCV`, `cross_val_score`, etc.
- âœ… MÃ©todos `fit()`, `predict()`, `score()` estÃ¡ndar
- âœ… Serializable con `pickle`/`joblib`
- âœ… **Listo para producciÃ³n** - puede deployarse directamente
- âœ… Incluye feature pipeline completo (scaling, PCA, etc.)

**Por quÃ© es importante:**
- En producciÃ³n, necesitas **un Ãºnico objeto** que pueda:
  1. Recibir datos crudos
  2. Aplicar todo el preprocessing
  3. Hacer predicciones
  4. Todo con una sola llamada: `pipeline.predict(X_new)`

---

### Design Patterns Implementados

| Pattern | DÃ³nde | Beneficio |
|---------|-------|-----------|
| **Singleton** | `DatasetManager` | Ãšnica instancia, thread-safe |
| **Builder** | `FeaturePipelineBuilder` | ConstrucciÃ³n flexible de pipelines |
| **Strategy** | `DataSplitter` | Estrategias intercambiables de split |
| **Factory** | `create_sklearn_pipeline()` | CreaciÃ³n simplificada de pipelines |
| **Template Method** | `BaseTransformer` | Estructura comÃºn para transformers |

---

### ğŸ“Š MÃ©tricas de RefactorizaciÃ³n

| MÃ©trica | Antes (Fase 1) | DespuÃ©s (Fase 2) | Mejora |
|---------|----------------|------------------|--------|
| **LÃ­neas de cÃ³digo** | 232 | 1,950 | +740% |
| **Clases OOP** | 0 | 15 | âˆ |
| **Tests unitarios** | 0 | 37 | âˆ |
| **Type hints** | ~20% | 100% | +400% |
| **DocumentaciÃ³n** | BÃ¡sica | Comprehensiva | +500% |
| **Modularidad** | Baja | Alta | Arquitectura enterprise |
| **Accuracy** | 76.00% | 80.17% | +5.5% |
| **Manejo de outliers** | Ad-hoc | Cuantitativo | Robusto |

---

## ğŸ¯ Sklearn Pipeline End-to-End

### Â¿Por quÃ© es importante?

En **producciÃ³n**, necesitas un pipeline que:
1. âœ… Encapsule **todo** el preprocessing + modelo
2. âœ… Sea compatible con **GridSearchCV** para tuning
3. âœ… Pueda **serializarse** con pickle/joblib
4. âœ… Tenga API estÃ¡ndar de sklearn (`fit`, `predict`, `score`)

### Pipeline Actual (80.17% accuracy)

```python
from acoustic_ml.modeling.sklearn_pipeline import create_sklearn_pipeline

# Crear pipeline completo
pipeline = create_sklearn_pipeline(
    model_type='random_forest',
    scaler_type='robust',  # â­ Clave para performance
    correlation_threshold=0.95,
    pca_components=20,
    model_params={
        'n_estimators': 200,
        'max_depth': 20,
        'min_samples_split': 5,
        'class_weight': 'balanced',
        'random_state': 42
    }
)

# Entrenar
pipeline.fit(X_train, y_train)

# Evaluar
accuracy = pipeline.score(X_test, y_test)
print(f"Accuracy: {accuracy:.4f}")  # 0.8017

# Guardar para producciÃ³n
import joblib
joblib.dump(pipeline, 'models/production_pipeline.pkl')

# Cargar y usar
loaded_pipeline = joblib.load('models/production_pipeline.pkl')
predictions = loaded_pipeline.predict(X_new)
```

### Componentes del Pipeline

```
SklearnMLPipeline
â”‚
â”œâ”€â”€ Feature Pipeline (fit_transform)
â”‚   â”œâ”€â”€ 1. OutlierHandler (anÃ¡lisis + logging)
â”‚   â”œâ”€â”€ 2. RobustScaler (normalizaciÃ³n robusta)
â”‚   â”œâ”€â”€ 3. CorrelationReducer (threshold=0.95)
â”‚   â””â”€â”€ 4. PCAReducer (n_components=20)
â”‚
â””â”€â”€ Model (fit/predict)
    â””â”€â”€ RandomForestClassifier (200 trees, depth=20)
```

---

## ğŸ›¡ï¸ Manejo de Outliers y Robustez

### AnÃ¡lisis Cuantitativo de Outliers

Ejecutamos un **anÃ¡lisis comprehensivo** usando 3 mÃ©todos:

```bash
python scripts/analyze_outliers.py
```

**Resultados:**
- Features con outliers: 48/50 (96%)
- Promedio de outliers por feature: 8.2%
- Features crÃ­ticos (>15% outliers): 12

**MÃ©todos de detecciÃ³n:**
1. **Z-score** (|z| > 3)
2. **IQR** (Q1 - 1.5*IQR, Q3 + 1.5*IQR)
3. **Isolation Forest** (contamination=0.1)

### ComparaciÃ³n de Scalers (A/B Testing)

```bash
python scripts/compare_scalers.py
```

**Resultados empÃ­ricos:**

| Scaler | Accuracy | Precision | Recall | F1-Score |
|--------|----------|-----------|--------|----------|
| **RobustScaler** â­ | **80.17%** | **0.80** | **0.80** | **0.80** |
| StandardScaler | 79.17% | 0.79 | 0.79 | 0.79 |

**ConclusiÃ³n:** RobustScaler supera a StandardScaler por +1% absoluto debido a su robustez contra outliers.

### DecisiÃ³n de DiseÃ±o

âŒ **NO usamos OutlierRemover** (elimina datos valiosos)  
âœ… **Usamos RobustScaler** (transforma robustamente sin eliminar)

**RazÃ³n:**
- Nuestro dataset es pequeÃ±o (408 filas)
- Eliminar 8-15% de datos por feature reducirÃ­a mucho el dataset
- RobustScaler usa mediana y cuartiles â†’ robusto a valores extremos
- **Resultado: mejor accuracy (80.17% vs 79.17%)**

---

## ğŸ“– GuÃ­a de Uso de MÃ³dulos

### Flujo de Trabajo Recomendado

```python
# 1. Cargar datos con DatasetManager (Singleton)
from acoustic_ml.dataset import DatasetManager

manager = DatasetManager()
df = manager.load_dataset("v2_cleaned_full.csv")
manager.validate_schema(df)

# 2. Split estratificado
X_train, X_test, y_train, y_test = manager.split_data(
    df, 
    target_column='Class',
    test_size=0.2,
    stratify=True
)

# 3. Crear pipeline sklearn end-to-end
from acoustic_ml.modeling.sklearn_pipeline import create_sklearn_pipeline

pipeline = create_sklearn_pipeline(
    model_type='random_forest',
    scaler_type='robust',
    pca_components=20,
    correlation_threshold=0.95
)

# 4. Entrenar
pipeline.fit(X_train, y_train)

# 5. Evaluar
from acoustic_ml.modeling.evaluate import ModelEvaluator

evaluator = ModelEvaluator()
metrics = evaluator.evaluate_model(pipeline, X_test, y_test)
print(f"Accuracy: {metrics['accuracy']:.4f}")

# 6. Visualizar
from acoustic_ml.plots import PlotManager

plotter = PlotManager()
plotter.plot_confusion_matrix(
    y_test, 
    pipeline.predict(X_test),
    save_path="reports/figures/"
)

# 7. Guardar modelo
import joblib
joblib.dump(pipeline, 'models/production_pipeline.pkl')
```

### Scripts de ValidaciÃ³n

Antes de hacer commit, ejecuta:

```bash
# Validar mÃ³dulo dataset
python scripts/validate_dataset.py

# Validar mÃ³dulo features
python scripts/validate_features.py

# Validar mÃ³dulo plots
python scripts/validate_plots.py

# Probar pipeline completo
python scripts/test_sklearn_pipeline.py

# ValidaciÃ³n completa del sistema
python scripts/test_full_integration.py
```

---

## ğŸ§ª Testing y ValidaciÃ³n

### Cobertura de Tests

| MÃ³dulo | Tests | Status | Cobertura |
|--------|-------|--------|-----------|
| `dataset.py` | 16 | âœ… Passing | ~95% |
| `features.py` | 13 | âœ… Passing | ~90% |
| `plots.py` | 8 | âœ… Passing | ~85% |
| **TOTAL** | **37** | **âœ… 100% Passing** | **~90%** |

### Ejecutar Tests

```bash
# Tests individuales
python scripts/validate_dataset.py
python scripts/validate_features.py
python scripts/validate_plots.py

# Test de integraciÃ³n del pipeline
python scripts/test_sklearn_pipeline.py

# ValidaciÃ³n completa
python scripts/test_full_integration.py

# Todos los tests de una vez
python scripts/run_full_analysis.py
```

### Tests CrÃ­ticos

âœ… **DatasetManager Singleton:** Thread-safety validado  
âœ… **Feature Pipeline:** Reproducibilidad garantizada  
âœ… **Sklearn Pipeline:** Compatibilidad con API estÃ¡ndar  
âœ… **Outlier Handling:** AnÃ¡lisis cuantitativo verificado  
âœ… **Serialization:** Pipeline guardable/cargable  

---

## ğŸ“Š Datasets Disponibles

### Datasets en `data/processed/`

| Archivo | Filas | Uso | RecomendaciÃ³n |
|---------|-------|-----|---------------|
| `turkish_music_emotion_cleaned.csv` | ~400 | HistÃ³rico | âš ï¸ Deprecated |
| `v1_original.csv` | 400 | Baseline | âœ… Para comparar |
| `v2_cleaned_aligned.csv` | 400 | A/B test | âœ… Mismo tamaÃ±o que v1 |
| `v2_cleaned_full.csv` | 408 | **PRODUCCIÃ“N** | â­ **RECOMENDADO** |

### Dataset Recomendado: v2_cleaned_full.csv

**Por quÃ© usar este dataset:**
- âœ… Limpieza mÃ¡s rigurosa (outliers analizados)
- âœ… 8 filas adicionales recuperadas (no son outliers reales)
- âœ… Mejor performance (80.17% accuracy)
- âœ… AnÃ¡lisis cuantitativo de calidad completado
- âœ… Compatible con RobustScaler

**CÃ³mo cargar:**
```python
from acoustic_ml.dataset import DatasetManager

manager = DatasetManager()
df = manager.load_dataset("v2_cleaned_full.csv")
```

---

## ğŸ”§ Requisitos Previos

### Sistema
- Python **3.12+**
- Git
- DVC
- AWS CLI (configurado con credenciales)

### ConfiguraciÃ³n AWS

AsegÃºrate de tener configuradas las credenciales de AWS:

```bash
# Archivo ~/.aws/credentials
[default]
aws_access_key_id = TU_ACCESS_KEY
aws_secret_access_key = TU_SECRET_KEY
```

---

## ğŸš€ InstalaciÃ³n

### 1. Clonar el repositorio

```bash
git clone <repository-url>
cd MLOps_Team24
```

### 2. Crear y activar entorno virtual

```bash
# Crear entorno virtual
python3.12 -m venv .venv

# Activar (Mac/Linux)
source .venv/bin/activate

# Activar (Windows)
.venv\Scripts\activate
```

### 3. Instalar dependencias

```bash
# Instalar paquetes
pip install -r requirements.txt

# Instalar acoustic_ml en modo editable
pip install -e .
```

### 4. Configurar DVC y descargar datos

```bash
# Configurar remote S3
dvc remote modify myremote region us-east-1

# Descargar datos
dvc pull
```

### 5. Verificar instalaciÃ³n

```bash
# Verificar que todo estÃ¡ bien
python -c "from acoustic_ml.dataset import DatasetManager; from acoustic_ml.features import create_full_pipeline; from acoustic_ml.modeling.sklearn_pipeline import create_sklearn_pipeline; print('âœ… Todo instalado correctamente')"
```

---

## â˜ï¸ GestiÃ³n de Datos (DVC + S3)

### ConfiguraciÃ³n de DVC

DVC estÃ¡ configurado para usar AWS S3 como storage remoto:

```yaml
# .dvc/config
[core]
    remote = myremote
['remote "myremote"']
    url = s3://mlops24-haowei-bucket/dvcstore
```

### Comandos DVC Esenciales

```bash
# Descargar datos desde S3
dvc pull

# Ver estado de archivos trackeados
dvc status

# Agregar nuevos datos
dvc add data/new_file.csv
git add data/new_file.csv.dvc data/.gitignore

# Subir cambios a S3
dvc push

# Reproducir pipeline
dvc repro
```

### Workflow TÃ­pico con Datos

```bash
# 1. Modificar datos localmente
# 2. Actualizar tracking
dvc add data

# 3. Subir a S3
dvc push

# 4. Commitear metadatos
git add data.dvc
git commit -m "data: actualizar dataset"
git push
```

---

## ğŸ’» Uso / Usage

### OpciÃ³n 1: Usar Pipeline Sklearn (Recomendado para ProducciÃ³n)

```python
from acoustic_ml.dataset import DatasetManager
from acoustic_ml.modeling.sklearn_pipeline import create_sklearn_pipeline
import joblib

# 1. Cargar datos
manager = DatasetManager()
df = manager.load_dataset("v2_cleaned_full.csv")
X_train, X_test, y_train, y_test = manager.split_data(df, target_column='Class')

# 2. Crear pipeline
pipeline = create_sklearn_pipeline(
    model_type='random_forest',
    scaler_type='robust',
    pca_components=20
)

# 3. Entrenar
pipeline.fit(X_train, y_train)

# 4. Evaluar
accuracy = pipeline.score(X_test, y_test)
print(f"Accuracy: {accuracy:.4f}")

# 5. Guardar
joblib.dump(pipeline, 'models/production_pipeline.pkl')
```

### OpciÃ³n 2: Usar Notebooks Interactivos

```bash
jupyter notebook notebooks/sklearn_pipeline_demo.ipynb
```

### OpciÃ³n 3: Ejecutar Scripts

```bash
# Entrenar modelo baseline
python scripts/train_baseline.py

# Probar pipeline completo
python scripts/test_sklearn_pipeline.py

# AnÃ¡lisis completo
python scripts/run_full_analysis.py
```

---

## ğŸ“œ Scripts Disponibles

### Scripts de Entrenamiento

```bash
# Entrenar modelo baseline
python scripts/train_baseline.py
```

### Scripts de ValidaciÃ³n

```bash
# Validar mÃ³dulo dataset
python scripts/validate_dataset.py

# Validar mÃ³dulo features
python scripts/validate_features.py

# Validar mÃ³dulo plots
python scripts/validate_plots.py

# Probar pipeline sklearn
python scripts/test_sklearn_pipeline.py

# ValidaciÃ³n completa del sistema
python scripts/test_full_integration.py
```

### Scripts de AnÃ¡lisis

```bash
# AnÃ¡lisis cuantitativo de outliers
python scripts/analyze_outliers.py

# ComparaciÃ³n A/B de scalers
python scripts/compare_scalers.py

# AnÃ¡lisis completo (todos los scripts)
python scripts/run_full_analysis.py
```

### Scripts Temporales (no versionados)

```bash
# Scripts de utilidad temporal
# Ubicados en scripts/temp/ y no trackeados en Git
ls scripts/temp/
```

---

## âœ… VerificaciÃ³n RÃ¡pida antes de Trabajar

Antes de comenzar a trabajar, verifica que todo estÃ© sincronizado:

```bash
make verify-sync
```

Este comando verifica:
- âœ… Git estÃ¡ actualizado
- âœ… DVC estÃ¡ sincronizado
- âœ… Datos descargados correctamente
- âœ… Dependencias instaladas
- âœ… Entorno virtual activado

---

## ğŸ³ Docker Compose

### Servicios Disponibles

El proyecto incluye Docker Compose para MLflow + MinIO (S3-compatible):

```bash
# Levantar servicios
docker-compose --env-file config.env up -d --build

# Ver logs
docker-compose logs -f

# Detener servicios
docker-compose down
```

### Acceso a Servicios

- **MLflow UI:** http://localhost:5001
- **MinIO Console:** http://localhost:9001

### Variables de Entorno

Configuradas en `config.env`:
```bash
MLFLOW_TRACKING_URI=http://localhost:5001
AWS_ACCESS_KEY_ID=minioadmin
AWS_SECRET_ACCESS_KEY=minioadmin
```

---

## ğŸ§¹ Limpieza y Mantenimiento

### Limpieza de CachÃ©s

```bash
# Limpiar cachÃ©s de Python y Jupyter
make clean-caches
```

Esto elimina:
- `__pycache__/`
- `.pytest_cache/`
- `.ipynb_checkpoints/`
- `*.pyc`, `*.pyo`

### Limpieza Completa

```bash
# Limpieza completa (incluye MLflow/DVC artifacts)
make clean
```

Esto elimina:
- CachÃ©s de Python
- Artifacts de MLflow (`mlruns/`, `mlartifacts/`)
- Cache de DVC (`dvcstore/`)
- Build artifacts (`*.egg-info/`)

**âš ï¸ Nota:** Los datos versionados en `data/` NO se eliminan.

### Regenerar Dependencias

Si instalaste nuevos paquetes:

```bash
# Actualizar requirements.txt
make freeze

# Commitear cambios
git add requirements.txt
git commit -m "deps: actualizar dependencias"
```

### AuditorÃ­a de Repositorio

Para verificar que el repo cumple estÃ¡ndares MLOps:

```bash
# Ver estructura actual
ls -la

# Verificar quÃ© estÃ¡ en Git
git status

# Verificar quÃ© estÃ¡ ignorado
git status --ignored
```

---

## ğŸ— Arquitectura del Pipeline

```mermaid
flowchart TD
    A[ğŸ“‚ data/raw/*.csv] -->|limpieza inicial| B[ğŸ”µ turkish_music_emotion_cleaned.csv]
    B -->|formalizaciÃ³n| C[ğŸ“¦ v1_original.csv - 400 filas]
    C -->|limpieza alineada| D[ğŸ”„ v2_cleaned_aligned.csv - 400 filas]
    C -->|limpieza completa| E[â­ v2_cleaned_full.csv - 408 filas]
    
    E -->|DVC tracking| F[â˜ï¸ AWS S3]
    E -->|DatasetManager| G[ğŸ”§ acoustic_ml/dataset.py]
    G -->|feature engineering| H[âš™ï¸ acoustic_ml/features.py]
    H -->|sklearn pipeline| I[ğŸ¯ acoustic_ml/modeling/sklearn_pipeline.py]
    I --> J[ğŸ’¾ models/production_pipeline.pkl]
    I --> K[ğŸ“ˆ metrics/metrics.json]
    J -->|log_model| L[MLflow Tracking]
    K -->|log_metrics| L
    L --> M[ğŸ–¥ MLflow UI :5001]
    
    style E fill:#90EE90,stroke:#228B22,stroke-width:3px
    style A fill:#e1f5ff
    style F fill:#fff4e1
    style J fill:#e8f5e9
    style M fill:#f3e5f5
    style G fill:#ffe4e1
    style H fill:#e6f3ff
    style I fill:#fff9c4
```

### Flujo de Trabajo Optimizado

1. ğŸ“¥ **Datos crudos** en `data/raw/` (versionados con DVC)
2. ğŸ”§ **Primera limpieza** â†’ `turkish_music_emotion_cleaned.csv` (histÃ³rico)
3. ğŸ“¦ **FormalizaciÃ³n** â†’ `v1_original.csv` (400 filas, baseline)
4. ğŸ”„ **Limpieza alineada** â†’ `v2_cleaned_aligned.csv` (400 filas, comparaciÃ³n)
5. â­ **Limpieza completa** â†’ `v2_cleaned_full.csv` (408 filas, **PRODUCCIÃ“N**)
6. â˜ï¸ **Almacenamiento en S3** para colaboraciÃ³n
7. ğŸ”§ **DatasetManager** (Singleton thread-safe) gestiona carga/validaciÃ³n
8. âš™ï¸ **FeaturePipeline** transforma datos con transformers especializados
9. ğŸ¯ **SklearnMLPipeline** integra preprocessing + modelo en un Ãºnico objeto â­
10. ğŸ’¾ **Modelos entrenados** se guardan en `models/`
11. ğŸ“ˆ **Experimentos y artefactos** se registran en MLflow
12. ğŸ“Š **MÃ©tricas** se trackean con DVC
13. âœ… **Todo es reproducible**, versionado y testado (37 tests)
14. ğŸ›¡ï¸ **Robusto a outliers** con RobustScaler y anÃ¡lisis cuantitativo
15. ğŸ§¹ **Repositorio limpio** segÃºn MLOps best practices âœ¨

---

## ğŸ¤ ContribuciÃ³n

### Flujo de Trabajo

1. **Verificar sincronizaciÃ³n:**
   ```bash
   make verify-sync
   ```

2. **Crear una nueva rama:**
   ```bash
   git checkout -b feat/nombre-descriptivo
   ```

3. **Realizar cambios:**
   
   **Si modificas cÃ³digo Python:**
   ```bash
   # Edita archivos en acoustic_ml/
   vim acoustic_ml/features.py
   
   # Los cambios estÃ¡n disponibles inmediatamente (instalaciÃ³n en modo -e)
   
   # Ejecutar tests relevantes
   python scripts/validate_features.py
   ```

   **Si modificas datos:**
   ```bash
   dvc add data
   git add data.dvc data/.gitignore
   dvc push
   ```

   **Si instalaste paquetes:**
   ```bash
   make freeze
   git add requirements.txt
   ```

4. **Commitear cambios:**
   ```bash
   git add .
   git commit -m "feat: descripciÃ³n clara del cambio"
   ```

5. **Subir cambios:**
   ```bash
   git push origin feat/nombre-descriptivo
   dvc push  # o: make push
   ```

6. **Crear Pull Request** a la rama `main`

### Buenas PrÃ¡cticas

- âœ… Ejecuta `make verify-sync` antes de comenzar a trabajar
- âœ… **SIEMPRE usa `DatasetManager` para gestionar datos**
- âœ… **Usa `create_sklearn_pipeline()` para pipelines de producciÃ³n** â­
- âœ… **Usa `RobustScaler` para manejo de outliers** (no OutlierRemover)
- âœ… **Ejecuta tests de validaciÃ³n antes de commit** (`validate_*.py`)
- âœ… **Prueba el pipeline completo** con `test_sklearn_pipeline.py`
- âœ… Documenta la versiÃ³n de dataset en MLflow tags
- âœ… Ejecuta `dvc status` para verificar estado de datos
- âœ… Ejecuta `make reproduce` antes de hacer commit
- âœ… Documenta tus experimentos en MLflow
- âœ… Escribe mensajes de commit descriptivos ([Conventional Commits](https://www.conventionalcommits.org/))
- âœ… MantÃ©n el cÃ³digo limpio y con docstrings
- âœ… Usa `make nb-hooks` para configurar hooks de notebooks
- âœ… Escribe cÃ³digo en el mÃ³dulo `acoustic_ml/`, no en notebooks
- âœ… Siempre haz `dvc push` despuÃ©s de modificar datos
- âœ… **MantÃ©n los tests actualizados** cuando agregues funcionalidades
- âœ… **NO commitees scripts temporales** (usa `scripts/temp/`)
- âœ… **Verifica .gitignore** antes de hacer commit de artifacts

### ConvenciÃ³n de Commits

Usamos [Conventional Commits](https://www.conventionalcommits.org/):

```
feat: agregar nueva funcionalidad
fix: corregir bug
docs: actualizar documentaciÃ³n
style: cambios de formato (no afectan funcionalidad)
refactor: reestructurar cÃ³digo sin cambiar comportamiento
test: agregar o modificar tests
chore: tareas de mantenimiento
```

---

## ğŸ‘¥ **Equipo de Desarrollo**

<div align="center">

<table style="width:100%; border:none;">
  <tr>
    <td align="center" style="border:none; padding:20px 10px;">
      <img src="https://iili.io/Kw90kmB.png" alt="David Cruz BeltrÃ¡n" width="160" style="border-radius: 50%; border: 5px solid #667eea; box-shadow: 0 8px 16px rgba(102, 126, 234, 0.4);"/>
      <h3>David Cruz BeltrÃ¡n</h3>
      <img src="https://img.shields.io/badge/ID-A01360416-667eea?style=for-the-badge" alt="MatrÃ­cula"/>
      <p><strong>ğŸ”§ Software Engineer</strong><br/>
      <em>Data Pipeline & Versioning</em></p>
    </td>
    <td align="center" style="border:none; padding:20px 10px;">
      <img src="https://iili.io/KuvsGKx.png" alt="Javier Augusto Rebull Saucedo" width="160" style="border-radius: 50%; border: 5px solid #764ba2; box-shadow: 0 8px 16px rgba(118, 75, 162, 0.4);"/>
      <h3>Javier Augusto Rebull Saucedo</h3>
      <img src="https://img.shields.io/badge/ID-A01795838-764ba2?style=for-the-badge" alt="MatrÃ­cula"/>
      <p><strong>âš™ï¸ SRE / Data Engineer</strong><br/>
      <em>DevOps & Infrastructure</em></p>
    </td>
    <td align="center" style="border:none; padding:20px 10px;">
      <img src="https://iili.io/Kw91d74.png" alt="Sandra Luz Cervantes Espinoza" width="160" style="border-radius: 50%; border: 5px solid #f093fb; box-shadow: 0 8px 16px rgba(240, 147, 251, 0.4);"/>
      <h3>Sandra Luz Cervantes Espinoza</h3>
      <img src="https://img.shields.io/badge/ID-A01796937-f093fb?style=for-the-badge" alt="MatrÃ­cula"/>
      <p><strong>ğŸ¤– ML Engineer / Data Scientist</strong><br/>
      <em>Model Development & Analysis</em></p>
    </td>
  </tr>
</table>

</div>

---

<div align="center">

**â­ Si este proyecto te resulta Ãºtil, considera darle una estrella**

Desarrollado con â¤ï¸ por el Equipo 24 | Estructura basada en [Cookiecutter Data Science](https://drivendata.github.io/cookiecutter-data-science/)

**ğŸ—ï¸ Refactorizado con SOLID Principles & Design Patterns** | **ğŸ§ª 100% Tested (37/37 passing)** | **ğŸ¯ Production-Ready Sklearn Pipeline** | **ğŸ§¹ Clean & Professional Repository**

*Ãšltima actualizaciÃ³n: Octubre 2024 - Fase 2 completada*

</div>
