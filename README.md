# üéµ Acoustic ML - Turkish Music Emotion Recognition

<div align="center">

**MLOps Team 24 - Sistema profesional de reconocimiento de emociones musicales**

[![Python](https://img.shields.io/badge/Python-3.12+-blue.svg)](https://www.python.org/downloads/)
[![MLflow](https://img.shields.io/badge/MLflow-Tracking-0194E2?logo=mlflow)](https://mlflow.org/)
[![DVC](https://img.shields.io/badge/DVC-Data%20Versioning-945DD6?logo=dvc)](https://dvc.org/)
[![AWS S3](https://img.shields.io/badge/AWS-S3-FF9900?logo=amazon-aws)](https://aws.amazon.com/s3/)
[![Streamlit](https://img.shields.io/badge/Streamlit-Dashboard-FF4B4B?logo=streamlit)](https://mlopsteam24-cookiecutter.streamlit.app)

<!-- Badges de Estado -->
[![Cookiecutter](https://img.shields.io/badge/cookiecutter-95.2%25-success?logo=cookiecutter&logoColor=white)](#-estructura-del-proyecto)
[![Tests](https://img.shields.io/badge/tests-33%20passing-success?logo=pytest&logoColor=white)](#-testing-unitarias-e-integraci√≥n)
[![Code Quality](https://img.shields.io/badge/code-production--ready-brightgreen?logo=python&logoColor=white)](#-arquitectura-del-c√≥digo)
[![Accuracy](https://img.shields.io/badge/accuracy-80.17%25-success?logo=tensorflow&logoColor=white)](#-modelo-y-resultados)
[![Docker](https://img.shields.io/badge/docker--ready-blue?logo=docker&logoColor=white)](#-docker--containerizaci√≥n)
[![Repo Status](https://img.shields.io/badge/repo-phase%203%20production-blue?logo=git&logoColor=white)](#-informaci√≥n-acad√©mica)

</div>

---

## üìã Tabla de Contenidos

- [Sobre el Proyecto](#-sobre-el-proyecto)
- [Informaci√≥n Acad√©mica](#-informaci√≥n-acad√©mica)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [Arquitectura del C√≥digo](#-arquitectura-del-c√≥digo)
- [Modelo y Resultados](#-modelo-y-resultados)
- [MLOps Infrastructure](#-mlops-infrastructure)
- [Instalaci√≥n y Configuraci√≥n](#-instalaci√≥n-y-configuraci√≥n)
- [Uso del Sistema](#-uso-del-sistema)
- [Scripts Disponibles](#-scripts-disponibles)
- [Testing & Quality Assurance](#-testing--quality-assurance)
- [API Serving with FastAPI](#-api-serving-with-fastapi)
- [Data Drift Detection & Monitoring](#-data-drift-detection--monitoring)
- [Docker & Containerization](#-docker--containerization)
- [Publicaci√≥n en DockerHub](#-publicaci√≥n-en-dockerhub)
- [Reproducibility & Seeds](#-reproducibility--seeds)
- [Phase 3 Requirements Checklist](#-phase-3-requirements-checklist)
- [Project Structure](#-project-structure)
- [Streamlit App - Production Demo](#-streamlit-app---production-demo)
- [Monitoring y Validaci√≥n](#-monitoring-y-validaci√≥n)
- [Workflows y Contribuci√≥n](#-workflows-y-contribuci√≥n)
- [Equipo](#-equipo-de-desarrollo)

---

## üéØ Sobre el Proyecto

Este repositorio implementa un sistema MLOps completo y profesional para **clasificaci√≥n de emociones en m√∫sica turca**, siguiendo las mejores pr√°cticas de la industria con estructura **Cookiecutter Data Science** (95.2% de cumplimiento verificado).

### üéµ Dataset y Objetivo

- **Dataset:** Turkish Music Emotion Dataset
- **Clases:** 4 emociones (Happy, Sad, Angry, Relax)
- **Features:** 50+ caracter√≠sticas ac√∫sticas extra√≠das
- **Objetivo:** Clasificaci√≥n autom√°tica de emociones musicales
- **Modelo Actual:** Random Forest optimizado con 80.17% accuracy

### üöÄ Caracter√≠sticas Principales

#### MLOps Foundation
- üìä **Versionado de datos** con DVC + AWS S3
- üîÑ **Pipelines reproducibles** automatizados
- üìà **Experiment tracking** con MLflow
- ‚òÅÔ∏è **Cloud storage** en S3 (mlops24-haowei-bucket)
- üê≥ **Containerizaci√≥n** con Docker Compose

#### Code y Arquitectura
- üèóÔ∏è **M√≥dulo Python profesional** (`acoustic_ml`)
- üéØ **Pipeline sklearn end-to-end** listo para producci√≥n
- üß™ **Testing comprehensivo** con 33 tests automatizados
- üõ°Ô∏è **Manejo robusto de outliers** y datos
- üåê **API REST** con FastAPI y Pydantic schemas

#### Fase 3: Production-Ready Deployment
- üê≥ **Containerizaci√≥n Docker** con docker-compose
- üîç **Data Drift Detection** con statistical monitoring
- üì° **CI/CD Pipelines** automatizados
- ‚öôÔ∏è **Health Checks** y monitoring endpoints
- üîÑ **Reproducibilidad garantizada** con seeds y DVC

#### Monitoring y Validaci√≥n
- üìä **Dashboard Streamlit** para validaci√≥n Cookiecutter
- üîç **Validaci√≥n automatizada** de entornos y datos
- üìà **7 experimentos MLflow** documentados
- ‚úÖ **Verificaci√≥n de sincronizaci√≥n** DVC + Git + S3

---

## üìò Informaci√≥n Acad√©mica

**Instituto Tecnol√≥gico y de Estudios Superiores de Monterrey**  
*Maestr√≠a en Inteligencia Artificial Aplicada (MNA)*

- **Curso:** Operaciones de Aprendizaje Autom√°tico
- **Periodo:** Septiembre ‚Äì Diciembre 2024
- **Equipo:** N¬∞ 24
- **Fase Actual:** Fase 3 - Implementaci√≥n en Producci√≥n üöÄ

### üë®‚Äçüè´ Profesores

| Rol | Nombre |
|-----|--------|
| Titular | Dr. Gerardo Rodr√≠guez Hern√°ndez |
| Titular | Mtro. Ricardo Valdez Hern√°ndez |
| Asistente | Mtra. Mar√≠a Mylen Trevi√±o Elizondo |
| Tutor | Jos√© √Ångel Mart√≠nez Navarro |

---

## üóÇÔ∏è Estructura del Proyecto

Organizaci√≥n completa siguiendo **Cookiecutter Data Science** con 95.2% de cumplimiento verificado:

```
MLOps_Team24/
‚îÇ
‚îú‚îÄ‚îÄ üìÑ Configuraci√≥n (Ra√≠z)
‚îÇ   ‚îú‚îÄ‚îÄ README.md              <- Este archivo ‚≠ê
‚îÇ   ‚îú‚îÄ‚îÄ Makefile               <- Comandos make (data, train, reproduce, etc.)
‚îÇ   ‚îú‚îÄ‚îÄ MakefileGitOK          <- Makefile alternativo
‚îÇ   ‚îú‚îÄ‚îÄ pyproject.toml         <- Configuraci√≥n proyecto Python
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt       <- Dependencias producci√≥n (pip freeze)
‚îÇ   ‚îú‚îÄ‚îÄ params.yaml            <- Par√°metros pipeline DVC
‚îÇ   ‚îú‚îÄ‚îÄ dvc.yaml               <- Definici√≥n pipeline DVC
‚îÇ   ‚îú‚îÄ‚îÄ dvc.lock               <- Lock file pipeline
‚îÇ   ‚îú‚îÄ‚îÄ data.dvc               <- Tracking metadatos datos
‚îÇ   ‚îú‚îÄ‚îÄ docker-compose.yml     <- Stack MLflow + MinIO
‚îÇ   ‚îî‚îÄ‚îÄ config.env             <- Variables entorno Docker
‚îÇ
‚îú‚îÄ‚îÄ üì¶ acoustic_ml/            <- M√≥dulo Python principal ‚≠ê
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py            
‚îÇ   ‚îú‚îÄ‚îÄ config.py              <- Configuraci√≥n global del sistema
‚îÇ   ‚îú‚îÄ‚îÄ dataset.py             <- DatasetManager (Singleton, thread-safe)
‚îÇ   ‚îú‚îÄ‚îÄ features.py            <- Feature engineering & transformers
‚îÇ   ‚îú‚îÄ‚îÄ plots.py               <- Visualizaciones y gr√°ficas
‚îÇ   ‚îú‚îÄ‚îÄ archive/               <- C√≥digo legacy versionado
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dataset_legacy.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ features_legacy.py
‚îÇ   ‚îî‚îÄ‚îÄ modeling/              <- Subm√≥dulo de modelado
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ train.py           <- Training logic
‚îÇ       ‚îú‚îÄ‚îÄ predict.py         <- Inference
‚îÇ       ‚îú‚îÄ‚îÄ evaluate.py        <- Evaluation metrics
‚îÇ       ‚îú‚îÄ‚îÄ pipeline.py        <- MLOps pipeline completo
‚îÇ       ‚îú‚îÄ‚îÄ sklearn_pipeline.py <- Pipeline sklearn production-ready
‚îÇ       ‚îî‚îÄ‚îÄ *.backup           <- Backups de versiones previas
‚îÇ
‚îú‚îÄ‚îÄ üåê app/                    <- API REST (FastAPI)
‚îÇ   ‚îú‚îÄ‚îÄ main.py                <- Entry point aplicaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ api/                   
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py            <- Router principal
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ endpoints.py       <- Endpoints API
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ schemas.py         <- Pydantic schemas
‚îÇ   ‚îú‚îÄ‚îÄ core/                  
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.py          <- Configuraci√≥n API
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ logger.py          <- Logging setup
‚îÇ   ‚îî‚îÄ‚îÄ services/              
‚îÇ       ‚îî‚îÄ‚îÄ model_service.py   <- Servicio de modelo
‚îÇ
‚îú‚îÄ‚îÄ üìä data/                   <- Datos (versionados con DVC)
‚îÇ   ‚îú‚îÄ‚îÄ external/              <- Fuentes externas
‚îÇ   ‚îú‚îÄ‚îÄ interim/               <- Transformaciones intermedias
‚îÇ   ‚îú‚îÄ‚îÄ processed/             <- Datasets finales ‚≠ê
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ turkish_music_emotion_v1_original.csv      (400 filas - Baseline)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ turkish_music_emotion_v2_cleaned_aligned.csv (400 filas)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ turkish_music_emotion_v2_cleaned_full.csv    (408 filas) ‚≠ê PRODUCCI√ìN
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ turkish_music_emotion_v2_transformed.csv
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ eda_report.txt
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ split_metadata.json
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ X_train.csv, X_test.csv
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ y_train.csv, y_test.csv
‚îÇ   ‚îî‚îÄ‚îÄ raw/                   <- Datos originales inmutables
‚îÇ       ‚îú‚îÄ‚îÄ turkis_music_emotion_original.csv     (125 KB)
‚îÇ       ‚îî‚îÄ‚îÄ turkish_music_emotion_modified.csv    (130 KB)
‚îÇ
‚îú‚îÄ‚îÄ üíæ models/                 <- Modelos serializados
‚îÇ   ‚îú‚îÄ‚îÄ baseline/              
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ random_forest_baseline.pkl
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ gradient_boosting_baseline.pkl
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ xgboost_baseline.pkl
‚îÇ   ‚îú‚îÄ‚îÄ optimized/             <- Modelos optimizados ‚≠ê
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ production_model.pkl              (Modelo actual 80.17%)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ production_model_metadata.json
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ best_model_*.pkl                  (Versiones fechadas)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ model_metadata_*.json
‚îÇ   ‚îú‚îÄ‚îÄ baseline.dvc           <- Tracking baseline models
‚îÇ   ‚îú‚îÄ‚îÄ optimized.dvc          <- Tracking optimized models
‚îÇ   ‚îú‚îÄ‚îÄ baseline_model.pkl     
‚îÇ   ‚îî‚îÄ‚îÄ test_model.pkl         
‚îÇ
‚îú‚îÄ‚îÄ üìà mlflow_artifacts/       <- Experimentos MLflow
‚îÇ   ‚îú‚îÄ‚îÄ exp_01_Random_Forest_Current_Best/
‚îÇ   ‚îú‚îÄ‚îÄ exp_02_Random_Forest_Deep/
‚îÇ   ‚îú‚îÄ‚îÄ exp_03_Random_Forest_Simple/
‚îÇ   ‚îú‚îÄ‚îÄ exp_04_Gradient_Boosting/
‚îÇ   ‚îú‚îÄ‚îÄ exp_05_Gradient_Boosting_Conservative/
‚îÇ   ‚îú‚îÄ‚îÄ exp_06_Logistic_Regression_Baseline/
‚îÇ   ‚îú‚îÄ‚îÄ exp_07_SVM_RBF/
‚îÇ   ‚îú‚îÄ‚îÄ experiments_summary.csv
‚îÇ   ‚îú‚îÄ‚îÄ experiments_report.txt
‚îÇ   ‚îî‚îÄ‚îÄ experiment_run_*.log
‚îÇ
‚îú‚îÄ‚îÄ üìì notebooks/              <- Jupyter notebooks
‚îÇ   ‚îú‚îÄ‚îÄ 1.0-team-eda-turkish-music.ipynb       (EDA inicial)
‚îÇ   ‚îú‚îÄ‚îÄ 1.1-team-dataset-comparison.ipynb      (Comparaci√≥n datasets)
‚îÇ   ‚îú‚îÄ‚îÄ 2.0-team-preprocessing.ipynb           (Preprocessing)
‚îÇ   ‚îú‚îÄ‚îÄ 3.0-team-modeling-evaluation.ipynb     (Modelado)
‚îÇ   ‚îî‚îÄ‚îÄ archive/               <- Notebooks legacy
‚îÇ       ‚îú‚îÄ‚îÄ 0.0-team-testing.ipynb
‚îÇ       ‚îî‚îÄ‚îÄ 1.2-team-fase1-final.ipynb
‚îÇ
‚îú‚îÄ‚îÄ üìä monitoring/             <- Sistema de monitoring
‚îÇ   ‚îú‚îÄ‚îÄ dashboard/             
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ streamlit_dashboard.py         ‚≠ê Dashboard Cookiecutter
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ validate_cookiecutter.py       
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ requirements_dashboard.txt
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îî‚îÄ‚îÄ README.md              
‚îÇ
‚îú‚îÄ‚îÄ üìà reports/                <- Reportes y an√°lisis
‚îÇ   ‚îú‚îÄ‚îÄ figures/               <- Visualizaciones ‚≠ê
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ confusion_matrices_top3.png
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ final_confusion_matrix.png
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ baseline_comparison.png
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ roc_curves.png
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ outlier_analysis.png
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ outlier_boxplots.png
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ plot_*.png         (M√∫ltiples visualizaciones EDA)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ outlier_analysis_report.txt
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ scaler_comparison_results.txt
‚îÇ   ‚îú‚îÄ‚îÄ baseline_model_evaluation/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ classification_report.txt
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ confusion_matrix.png
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ metrics.json
‚îÇ   ‚îú‚îÄ‚îÄ baseline_results.csv
‚îÇ   ‚îú‚îÄ‚îÄ hyperparameter_search_results.csv
‚îÇ   ‚îú‚îÄ‚îÄ final_model_evaluation.json
‚îÇ   ‚îú‚îÄ‚îÄ modeling_report.txt
‚îÇ   ‚îú‚îÄ‚îÄ metrics.json
‚îÇ   ‚îî‚îÄ‚îÄ turkish_dataset_comparison_report.txt
‚îÇ
‚îú‚îÄ‚îÄ üìö references/             <- Documentaci√≥n externa
‚îÇ   ‚îú‚îÄ‚îÄ Diccionario_Variables_Musica_Turca.xlsx
‚îÇ   ‚îú‚îÄ‚îÄ Referencias_APA.xlsx
‚îÇ   ‚îú‚îÄ‚îÄ Team24_Machine Learning Canvas v1.0.pdf
‚îÇ   ‚îú‚îÄ‚îÄ Fase 1_Equipo24.pdf
‚îÇ   ‚îú‚îÄ‚îÄ Fase 2_Equipo24.pdf
‚îÇ   ‚îî‚îÄ‚îÄ Fase 01 MNA MLOps Team 24 Octubre 2025.mp4
‚îÇ
‚îú‚îÄ‚îÄ üõ†Ô∏è scripts/               <- Scripts organizados por funci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ analysis/              <- Scripts de an√°lisis
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ analyze_outliers.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ compare_scalers.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ run_full_analysis.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îÇ   ‚îú‚îÄ‚îÄ training/              <- Scripts de entrenamiento
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train_baseline.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ run_mlflow_experiments.py     ‚≠ê Experimentos MLflow
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ run_mlflow_experiments.py.backup
‚îÇ   ‚îú‚îÄ‚îÄ validation/            <- Scripts de validaci√≥n
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ verify_sync.py     ‚≠ê Verificaci√≥n DVC+Git+S3
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îÇ   ‚îú‚îÄ‚îÄ pipelines/             
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ml_pipeline.py
‚îÇ   ‚îú‚îÄ‚îÄ temp/                  <- Scripts temporales (gitignored)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cleanup_*.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fix_*.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_*.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ update_*.py
‚îÇ   ‚îî‚îÄ‚îÄ validate_final.py
‚îÇ
‚îú‚îÄ‚îÄ üß™ tests/                  <- Test suite
‚îÇ   ‚îú‚îÄ‚îÄ test_dataset_equivalence.py
‚îÇ   ‚îú‚îÄ‚îÄ test_full_integration.py      ‚≠ê Integration tests
‚îÇ   ‚îú‚îÄ‚îÄ test_ml_pipeline.py
‚îÇ   ‚îú‚îÄ‚îÄ test_sklearn_pipeline.py
‚îÇ   ‚îú‚îÄ‚îÄ validate_cookiecutter.py
‚îÇ   ‚îú‚îÄ‚îÄ validate_dataset.py
‚îÇ   ‚îú‚îÄ‚îÄ validate_features.py
‚îÇ   ‚îú‚îÄ‚îÄ validate_plots.py
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îÇ
‚îú‚îÄ‚îÄ üìö docs/                   <- Documentaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ setup_guide.md
‚îÇ   ‚îú‚îÄ‚îÄ ml_pipeline.md
‚îÇ   ‚îú‚îÄ‚îÄ api_endpoints.md
‚îÇ   ‚îú‚îÄ‚îÄ deployment_guide.md
‚îÇ   ‚îî‚îÄ‚îÄ references.md
‚îÇ
‚îú‚îÄ‚îÄ üóÑÔ∏è mlartifacts/           <- MLflow local artifacts
‚îú‚îÄ‚îÄ üóÑÔ∏è dvcstore/              <- DVC local cache
‚îî‚îÄ‚îÄ üì¶ acoustic_ml.egg-info/  <- Package metadata

```

### üìä Resumen de Directorios

| Directorio | Prop√≥sito | DVC Tracked | Git Tracked |
|-----------|-----------|-------------|-------------|
| `acoustic_ml/` | M√≥dulo Python principal | ‚ùå | ‚úÖ |
| `app/` | API REST FastAPI | ‚ùå | ‚úÖ |
| `data/` | Datasets (raw, processed) | ‚úÖ | ‚ö†Ô∏è (.dvc only) |
| `models/` | Modelos serializados | ‚úÖ | ‚ö†Ô∏è (.dvc only) |
| `notebooks/` | Jupyter notebooks | ‚ùå | ‚úÖ |
| `scripts/` | Scripts auxiliares | ‚ùå | ‚úÖ |
| `tests/` | Test suite | ‚ùå | ‚úÖ |
| `reports/` | Reportes y figuras | ‚ùå | ‚úÖ |
| `monitoring/` | Dashboard y validaci√≥n | ‚ùå | ‚úÖ |
| `mlflow_artifacts/` | Experimentos MLflow | ‚ùå | ‚úÖ |
| `mlartifacts/` | MLflow local store | ‚ùå | ‚ùå |
| `dvcstore/` | DVC local cache | ‚ùå | ‚ùå |

---

## üèóÔ∏è Arquitectura del C√≥digo

### M√≥dulo Principal: `acoustic_ml`

M√≥dulo Python profesional con arquitectura limpia y bien documentada:

#### **1. `config.py`** - Configuraci√≥n Global
```python
# Paths, constants, logging configuration
PROJECT_ROOT = Path(__file__).parent.parent
DATA_DIR = PROJECT_ROOT / "data"
MODELS_DIR = PROJECT_ROOT / "models"
```

#### **2. `dataset.py`** - Gesti√≥n de Datos
- **`DatasetManager`**: Singleton thread-safe para carga de datos
- **Funciones**: `load_dataset()`, `validate_dataset()`, `get_data_splits()`
- **Testing**: 16+ tests de validaci√≥n
- **Features**: Caching, validaci√≥n autom√°tica, metadata tracking

#### **3. `features.py`** - Feature Engineering
- **`FeaturePipeline`**: Pipeline de transformaci√≥n completo
- **Transformers**: `OutlierHandler`, `FeatureScaler`, `FeatureSelector`
- **An√°lisis**: Detecci√≥n de outliers, scaling robusto
- **Testing**: 13+ tests comprehensivos

#### **4. `plots.py`** - Visualizaciones
- Confusion matrices, ROC curves, distribution plots
- Outlier analysis visualizations
- Feature importance plots
- **Testing**: 8+ tests de generaci√≥n de plots

#### **5. `modeling/`** - Subm√≥dulo de Modelado

```
modeling/
‚îú‚îÄ‚îÄ train.py           <- L√≥gica de entrenamiento
‚îú‚îÄ‚îÄ predict.py         <- Inferencia y predicciones
‚îú‚îÄ‚îÄ evaluate.py        <- M√©tricas y evaluaci√≥n
‚îú‚îÄ‚îÄ pipeline.py        <- Pipeline MLOps completo
‚îî‚îÄ‚îÄ sklearn_pipeline.py <- Pipeline sklearn production-ready ‚≠ê
```

**Pipeline Sklearn (Production-Ready)**:
```python
from acoustic_ml.modeling.sklearn_pipeline import create_sklearn_pipeline

# Pipeline completo: preprocessing + modelo
pipeline = create_sklearn_pipeline(model_type='random_forest')

# Compatible con GridSearchCV, cross_val_score
pipeline.fit(X_train, y_train)
predictions = pipeline.predict(X_test)
```

### Design Patterns Implementados

1. **Singleton Pattern**: `DatasetManager` para gesti√≥n centralizada
2. **Factory Pattern**: Creaci√≥n de pipelines y modelos
3. **Strategy Pattern**: Diferentes algoritmos de scaling/preprocessing
4. **Pipeline Pattern**: Composici√≥n de transformadores sklearn

### M√©tricas de Calidad

- ‚úÖ **Modularidad**: C√≥digo organizado en m√≥dulos especializados
- ‚úÖ **Testing**: Suite comprehensiva de tests
- ‚úÖ **Documentaci√≥n**: Docstrings completos en todo el c√≥digo
- ‚úÖ **Type Hints**: Tipado est√°tico en funciones cr√≠ticas
- ‚úÖ **SOLID Principles**: Arquitectura limpia y extensible
- ‚úÖ **Production-Ready**: Pipeline sklearn compatible con MLflow

---

## üéØ Modelo y Resultados

### Modelo Actual en Producci√≥n

- **Algoritmo**: Random Forest Optimizado
- **Accuracy**: **80.17%**
- **Location**: `models/optimized/production_model.pkl`
- **Dataset**: v2_cleaned_full.csv (408 filas)
- **Features**: 50+ caracter√≠sticas ac√∫sticas

### Experimentos MLflow

Se ejecutaron **7 experimentos** documentados en `mlflow_artifacts/`:

| Experimento | Modelo | Accuracy | F1-Score |
|------------|--------|----------|----------|
| exp_01 | Random Forest (Current Best) | 80.17% | 0.80 |
| exp_02 | Random Forest (Deep) | 78.5% | 0.78 |
| exp_03 | Random Forest (Simple) | 76.2% | 0.76 |
| exp_04 | Gradient Boosting | 77.8% | 0.77 |
| exp_05 | Gradient Boosting (Conservative) | 75.9% | 0.75 |
| exp_06 | Logistic Regression | 72.3% | 0.71 |
| exp_07 | SVM RBF | 74.1% | 0.73 |

**Resumen**: `mlflow_artifacts/experiments_summary.csv`

### Features Clave

Las 50+ caracter√≠sticas ac√∫sticas incluyen:

- **MFCC** (Mel-Frequency Cepstral Coefficients): 1-13 con mean/std
- **Spectral Features**: Centroid, Rolloff, Bandwidth, Contrast
- **Temporal Features**: Zero Crossing Rate, Tempo
- **Energy Features**: RMS Energy, Low Energy
- **Statistical**: Mean, Std, Min, Max por feature

### Pipeline de Datos

```
Raw Audio ‚Üí Feature Extraction ‚Üí Cleaning ‚Üí Transformation ‚Üí Model Training
```

1. **Raw Data**: Archivos CSV con caracter√≠sticas pre-extra√≠das
2. **Cleaning**: Eliminaci√≥n de duplicados, manejo de missing values
3. **Feature Engineering**: Scaling, selection, outlier handling
4. **Model Training**: Random Forest con hyperparameter tuning
5. **Evaluation**: Cross-validation, confusion matrix, classification report

---

## üöÄ MLOps Infrastructure

### DVC (Data Version Control)

**Configuraci√≥n**:
```yaml
# .dvc/config
remote:
  mlops24-s3:
    url: s3://mlops24-haowei-bucket/dvcstore
```

**Archivos Trackeados**:
- `data.dvc` ‚Üí Carpeta `data/` completa
- `models/baseline.dvc` ‚Üí Modelos baseline
- `models/optimized.dvc` ‚Üí Modelos optimizados

**Comandos Clave**:
```bash
dvc pull              # Descargar datos desde S3
dvc push              # Subir datos a S3
dvc status            # Ver cambios pendientes
dvc repro             # Reproducir pipeline
```

### MLflow (Experiment Tracking)

**Configuraci√≥n Docker**:
```yaml
# docker-compose.yml
services:
  mlflow:
    image: ghcr.io/mlflow/mlflow:latest
    ports:
      - "5001:5000"
    volumes:
      - ./mlartifacts:/mlflow/mlartifacts
```

**Uso**:
```bash
docker-compose up -d    # Iniciar MLflow
# Acceder: http://localhost:5001
```

**Tracking**:
- 7 experimentos registrados
- M√©tricas: accuracy, f1-score, precision, recall
- Artifacts: modelos, confusion matrices, classification reports

### AWS S3 (Cloud Storage)

**Bucket**: `mlops24-haowei-bucket`

**Estructura en S3**:
```
s3://mlops24-haowei-bucket/
‚îú‚îÄ‚îÄ dvcstore/
‚îÇ   ‚îú‚îÄ‚îÄ files/md5/...
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ models/
```

**Sincronizaci√≥n**:
```bash
# Verificar sync
make verify-sync

# O manualmente
python scripts/validation/verify_sync.py
```

### Cookiecutter Compliance

**Dashboard de Validaci√≥n**: [https://mlopsteam24-cookiecutter2.streamlit.app](https://mlopsteam24-cookiecutter2.streamlit.app)

**Cumplimiento**: **95.2%**

**Validaci√≥n Local**:
```bash
cd monitoring/dashboard
streamlit run streamlit_dashboard.py
```

---

## üíª Instalaci√≥n y Configuraci√≥n

### Requisitos Previos

- **Python**: 3.12+
- **Git**: Latest version
- **DVC**: Latest version
- **AWS CLI**: Configurado con credenciales
- **Docker** (opcional): Para MLflow

### Instalaci√≥n Paso a Paso

#### 1. Clonar el Repositorio

```bash
git clone <repository-url>
cd MLOps_Team24
```

#### 2. Crear Entorno Virtual

**Opci√≥n A: conda**
```bash
conda create -n acoustic_ml python=3.12
conda activate acoustic_ml
```

**Opci√≥n B: venv**
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# o
venv\Scripts\activate     # Windows
```

#### 3. Instalar Dependencias

```bash
pip install -r requirements.txt
```

#### 4. Instalar M√≥dulo en Modo Desarrollo

```bash
pip install -e .
```

Esto instala `acoustic_ml` como m√≥dulo editable.

#### 5. Configurar AWS Credentials

```bash
aws configure
# Ingresar:
# AWS Access Key ID
# AWS Secret Access Key
# Default region: us-east-1
```

#### 6. Configurar DVC Remote

```bash
dvc remote add -d mlops24-s3 s3://mlops24-haowei-bucket/dvcstore
dvc remote modify mlops24-s3 region us-east-1
```

#### 7. Descargar Datos

```bash
dvc pull
```

Esto descarga:
- `data/` completo desde S3
- `models/` baseline y optimized

#### 8. Verificar Instalaci√≥n

```bash
# Test imports
python -c "import acoustic_ml; print(acoustic_ml.__version__)"

# Verificar sync
make verify-sync
```

#### 9. (Opcional) Iniciar MLflow

```bash
docker-compose up -d
# Acceder: http://localhost:5001
```

---

## üìñ Uso del Sistema

### üéµ Opci√≥n 1: Usar la Aplicaci√≥n Web (Recomendado)

La forma m√°s r√°pida de probar el sistema es usando nuestra **app de Streamlit desplegada**:

**üåê URL**: [tu-url-de-streamlit].streamlit.app

**Funcionalidades**:
- üéº An√°lisis de emociones en tiempo real
- üìä Visualizaciones interactivas (waveform, spectrogram)
- üìÅ Subir tus propios archivos de audio (.mp3, .wav)
- üéØ Predicci√≥n con modelo Random Forest (76.9% accuracy)
- üìà Feature importance analysis
- üîÑ Batch analysis de m√∫ltiples canciones

Ver la secci√≥n [üéµ Streamlit App - Production Demo](#-streamlit-app---production-demo) para m√°s detalles.

---

### üñ•Ô∏è Opci√≥n 2: Uso Local del M√≥dulo Python

#### 1. Cargar Datos

```python
from acoustic_ml.dataset import load_dataset

# Cargar dataset principal (408 filas)
df = load_dataset('v2_cleaned_full')
print(f"Dataset shape: {df.shape}")

# O cargar con splits predefinidos
X_train, X_test, y_train, y_test = load_dataset('v2_cleaned_full', return_splits=True)
print(f"Train: {X_train.shape}, Test: {X_test.shape}")

# Ver las clases disponibles
print(f"Emotions: {y_train.unique()}")  # ['Happy', 'Sad', 'Angry', 'Relax']
```

#### 2. Feature Engineering

```python
from acoustic_ml.features import FeaturePipeline

# Crear pipeline de transformaci√≥n
pipeline = FeaturePipeline()

# Fit y transform sobre datos de entrenamiento
X_transformed = pipeline.fit_transform(X_train, y_train)

# Transform datos de test (sin fit)
X_test_transformed = pipeline.transform(X_test)

print(f"Features originales: {X_train.shape[1]}")
print(f"Features transformados: {X_transformed.shape[1]}")
```

#### 3. Entrenar Modelo desde Cero

```python
from acoustic_ml.modeling.sklearn_pipeline import create_sklearn_pipeline
from acoustic_ml.dataset import load_dataset
from sklearn.metrics import classification_report, accuracy_score

# 1. Cargar datos
X_train, X_test, y_train, y_test = load_dataset('v2_cleaned_full', return_splits=True)

# 2. Crear pipeline completo (preprocessing + modelo)
model_pipeline = create_sklearn_pipeline(model_type='random_forest')

# 3. Entrenar
print("Entrenando modelo...")
model_pipeline.fit(X_train, y_train)

# 4. Predecir
predictions = model_pipeline.predict(X_test)
probabilities = model_pipeline.predict_proba(X_test)

# 5. Evaluar
accuracy = accuracy_score(y_test, predictions)
print(f"\n‚úÖ Accuracy: {accuracy:.2%}")
print("\nClassification Report:")
print(classification_report(y_test, predictions))

# 6. Guardar modelo
import joblib
joblib.dump(model_pipeline, 'models/my_model.pkl')
print("\nüíæ Modelo guardado en: models/my_model.pkl")
```

#### 4. Hacer Predicciones con Modelo Pre-entrenado

```python
import joblib
import pandas as pd
from acoustic_ml.dataset import load_dataset

# 1. Cargar modelo pre-entrenado
model = joblib.load('models/optimized/production_model.pkl')
print("‚úÖ Modelo cargado (Accuracy: 80.17%)")

# 2. Cargar datos nuevos
X_test, _, _, y_test = load_dataset('v2_cleaned_full', return_splits=True)

# 3. Hacer predicciones
predictions = model.predict(X_test)
probabilities = model.predict_proba(X_test)

# 4. Ver resultados
for i in range(5):  # Primeras 5 predicciones
    true_label = y_test.iloc[i]
    pred_label = predictions[i]
    confidence = probabilities[i].max()
    
    print(f"\nCanci√≥n {i+1}:")
    print(f"  Real: {true_label}")
    print(f"  Predicci√≥n: {pred_label} (confianza: {confidence:.2%})")
    print(f"  ‚úÖ Correcto" if true_label == pred_label else "  ‚ùå Incorrecto")
```

#### 5. Predicci√≥n de una Sola Canci√≥n

```python
import joblib
import numpy as np

# Cargar modelo
model = joblib.load('models/optimized/production_model.pkl')

# Features de una nueva canci√≥n (50+ caracter√≠sticas ac√∫sticas)
new_song_features = np.array([
    [0.123, -0.456, 0.789, ...]  # MFCC, spectral features, etc.
])

# Predecir emoci√≥n
emotion = model.predict(new_song_features)[0]
confidence = model.predict_proba(new_song_features)[0]

print(f"Emoci√≥n detectada: {emotion}")
print(f"Confianzas: Happy={confidence[0]:.2%}, Sad={confidence[1]:.2%}, "
      f"Angry={confidence[2]:.2%}, Relax={confidence[3]:.2%}")
```

#### 6. Visualizaciones

```python
from acoustic_ml.plots import plot_confusion_matrix, plot_feature_importance
import matplotlib.pyplot as plt

# Confusion matrix
fig = plot_confusion_matrix(
    y_test, 
    predictions, 
    save_path='reports/figures/my_confusion_matrix.png'
)
plt.show()

# Feature importance (requiere modelo con feature_importances_)
feature_names = X_train.columns.tolist()
plot_feature_importance(
    model.named_steps['classifier'],  # Extraer clasificador del pipeline
    feature_names, 
    top_n=20,
    save_path='reports/figures/feature_importance.png'
)
plt.show()
```

#### 7. Batch Prediction (M√∫ltiples Canciones)

```python
import joblib
import pandas as pd
from pathlib import Path

# Cargar modelo
model = joblib.load('models/optimized/production_model.pkl')

# Cargar dataset con canciones nuevas
songs_df = pd.read_csv('data/processed/turkish_music_emotion_v2_cleaned_full.csv')

# Separar features y target
X = songs_df.drop('Class', axis=1)
y_true = songs_df['Class']

# Batch prediction
predictions = model.predict(X)
probabilities = model.predict_proba(X)

# Crear DataFrame con resultados
results_df = pd.DataFrame({
    'Song_ID': range(len(predictions)),
    'True_Emotion': y_true,
    'Predicted_Emotion': predictions,
    'Confidence': probabilities.max(axis=1),
    'Correct': predictions == y_true.values
})

# Guardar resultados
results_df.to_csv('reports/batch_predictions.csv', index=False)
print(f"\n‚úÖ Predicciones guardadas en: reports/batch_predictions.csv")
print(f"\nAccuracy general: {results_df['Correct'].mean():.2%}")
print(f"Total canciones: {len(results_df)}")
print(f"Correctas: {results_df['Correct'].sum()}")
print(f"Incorrectas: {(~results_df['Correct']).sum()}")
```

---

### üöÄ Scripts R√°pidos (L√≠nea de Comando)

#### Entrenar Modelo Baseline

```bash
# Entrenar Random Forest baseline
python scripts/training/train_baseline.py

# Output: models/baseline/random_forest_baseline.pkl
```

#### Ejecutar Todos los Experimentos MLflow

```bash
# Ejecuta 7 experimentos con diferentes modelos
python scripts/training/run_mlflow_experiments.py

# Ver resultados en: http://localhost:5001 (MLflow UI)
```

#### An√°lisis Exploratorio

```bash
# An√°lisis de outliers
python scripts/analysis/analyze_outliers.py

# Comparaci√≥n de scalers (StandardScaler vs RobustScaler)
python scripts/analysis/compare_scalers.py

# An√°lisis completo
python scripts/analysis/run_full_analysis.py
```

#### Validaci√≥n y Testing

```bash
# Validaci√≥n completa del sistema
python tests/test_full_integration.py

# Tests espec√≠ficos
python tests/test_sklearn_pipeline.py
python tests/test_dataset_equivalence.py
```

---

### üìä Workflow Completo: De Cero a Producci√≥n

```bash
# 1. Setup inicial
conda activate acoustic_ml
dvc pull  # Descargar datos

# 2. Exploraci√≥n (opcional)
jupyter notebook notebooks/1.0-team-eda-turkish-music.ipynb

# 3. Entrenar modelo
python scripts/training/train_baseline.py

# 4. Experimentaci√≥n con MLflow
docker-compose up -d  # Iniciar MLflow UI
python scripts/training/run_mlflow_experiments.py

# 5. Evaluar mejor modelo
python -c "
from acoustic_ml.dataset import load_dataset
from acoustic_ml.modeling.sklearn_pipeline import create_sklearn_pipeline
from sklearn.metrics import classification_report

X_train, X_test, y_train, y_test = load_dataset('v2_cleaned_full', return_splits=True)
model = create_sklearn_pipeline('random_forest')
model.fit(X_train, y_train)
predictions = model.predict(X_test)
print(classification_report(y_test, predictions))
"

# 6. Guardar modelo final
python -c "
import joblib
from acoustic_ml.modeling.sklearn_pipeline import create_sklearn_pipeline
model = create_sklearn_pipeline('random_forest')
# ... entrenar ...
joblib.dump(model, 'models/optimized/production_model.pkl')
print('‚úÖ Modelo guardado')
"

# 7. Deploy (Streamlit app o API)
# Ver secci√≥n de Streamlit App
```

---

## üõ†Ô∏è Scripts Disponibles

### Makefile Commands

El proyecto incluye un `Makefile` con comandos √∫tiles:

```bash
make data           # Descarga datos con DVC
make train          # Entrena modelo baseline
make reproduce      # Reproduce pipeline DVC completo
make clean          # Limpia archivos temporales
make verify-sync    # Verifica sincronizaci√≥n DVC+Git+S3
make freeze         # Actualiza requirements.txt
make test           # Ejecuta tests
make mlflow         # Inicia MLflow UI
make help           # Muestra todos los comandos
```

### Scripts de Training

```bash
# Entrenamiento baseline
python scripts/training/train_baseline.py

# Experimentos MLflow (7 modelos)
python scripts/training/run_mlflow_experiments.py
```

### Scripts de An√°lisis

```bash
# An√°lisis de outliers
python scripts/analysis/analyze_outliers.py

# Comparaci√≥n de scalers
python scripts/analysis/compare_scalers.py

# An√°lisis completo
python scripts/analysis/run_full_analysis.py
```

### Scripts de Validaci√≥n

```bash
# Verificar sincronizaci√≥n DVC+Git+S3
python scripts/validation/verify_sync.py

# Validaci√≥n Cookiecutter
python tests/validate_cookiecutter.py

# Tests de integraci√≥n
python tests/test_full_integration.py
```

---

## üß™ Testing & Quality Assurance

### Ejecutar Tests

```bash
# Ejecutar todos los tests con output detallado
pytest tests/ -v

# Modo quiet (resumen)
pytest tests/ -q

# Tests espec√≠ficos con traceback corto
pytest tests/ -v --tb=short

# Con cobertura
pytest tests/ --cov=acoustic_ml
```

### Suite de 33 Tests

**Ubicaci√≥n**: `tests/` (4 m√≥dulos principales)

| M√≥dulo | Tipo | Cantidad | Prop√≥sito |
|--------|------|----------|----------|
| `test_dataset_equivalence.py` | Unitario | 8 tests | Validar DatasetManager, cargas, transformaciones |
| `test_sklearn_pipeline.py` | Unitario | 7 tests | Pipeline sklearn, features, scalers |
| `test_full_integration.py` | Integraci√≥n | 12 tests | End-to-end: data ‚Üí model ‚Üí predict |
| `test_api_endpoints.py` | API | 6 tests | FastAPI endpoints (TestClient, no servidor) |

### Tipos de Tests

**Unitarios (15 tests)**:
```bash
pytest tests/test_dataset_equivalence.py -v  # DatasetManager, data loading
pytest tests/test_sklearn_pipeline.py -v     # Feature engineering, pipeline creation
```

**Integraci√≥n (12 tests)**:
```bash
pytest tests/test_full_integration.py -v     # Full pipeline: train ‚Üí predict
```

**API (6 tests)**:
```bash
pytest tests/test_api_endpoints.py -v        # /health, /predict, /train, /models
```

### Resultado Esperado

```
tests/test_dataset_equivalence.py::test_load_data PASSED
tests/test_dataset_equivalence.py::test_dataset_manager PASSED
tests/test_sklearn_pipeline.py::test_create_pipeline PASSED
tests/test_sklearn_pipeline.py::test_feature_transform PASSED
tests/test_full_integration.py::test_train_predict_pipeline PASSED
tests/test_api_endpoints.py::test_health_check PASSED
tests/test_api_endpoints.py::test_predict_endpoint PASSED

========================== 33 passed in 2.45s ==========================
```

### Validaci√≥n R√°pida Post-Cambios

```bash
# Quick test despu√©s de editar c√≥digo
make test

# O directamente
pytest tests/ -q
```

---

## üåê API Serving with FastAPI

### Endpoints Disponibles

| M√©todo | Endpoint | Descripci√≥n |
|--------|----------|-------------|
| `GET` | `/` | Root endpoint - API status |
| `GET` | `/api/v1/health` | Health check del sistema |
| `POST` | `/api/v1/predict` | Predicci√≥n single de emoci√≥n |
| `POST` | `/api/v1/train` | Trigger retraining del modelo |
| `GET` | `/api/v1/models` | Listar modelos disponibles |

### Iniciar Localmente

```bash
# Opci√≥n 1: Uvicorn directo
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# Opci√≥n 2: Desde app/main.py
python app/main.py

# Opci√≥n 3: Con gunicorn (producci√≥n)
gunicorn app.main:app --workers 4 --worker-class uvicorn.workers.UvicornWorker
```

**Acceso a documentaci√≥n autom√°tica**:
```
Swagger UI:  http://localhost:8000/docs
ReDoc:       http://localhost:8000/redoc
OpenAPI:     http://localhost:8000/openapi.json
```

### Ejemplo: POST /api/v1/predict

**Request JSON**:
```bash
curl -X POST "http://localhost:8000/api/v1/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "chroma_stft": 0.45,
    "chroma_stft_std": 0.32,
    "mfcc_1": 12.5,
    "mfcc_1_std": 8.3,
    "mfcc_2": -5.2,
    "mfcc_2_std": 3.1,
    "mfcc_3": 2.1,
    "mfcc_3_std": 1.8,
    "mfcc_4": 0.9,
    "mfcc_4_std": 0.7,
    "mfcc_5": -1.2,
    "mfcc_5_std": 0.5,
    "zero_crossing_rate": 0.12,
    "zero_crossing_rate_std": 0.08
  }'
```

**Response JSON**:
```json
{
  "emotion": "Happy",
  "confidence": 0.87,
  "probabilities": {
    "Happy": 0.87,
    "Angry": 0.08,
    "Sad": 0.03,
    "Relax": 0.02
  },
  "model_version": "production_model_v2",
  "timestamp": "2024-11-12T10:30:45.123Z"
}
```

### Health Check: GET /api/v1/health

```bash
curl http://localhost:8000/api/v1/health
```

**Response**:
```json
{
  "status": "healthy",
  "model_loaded": true,
  "s3_connection": true,
  "mlflow_connection": true,
  "timestamp": "2024-11-12T10:30:00Z"
}
```

### Ubicaci√≥n del C√≥digo

```
app/
‚îú‚îÄ‚îÄ main.py           <- Entry point, lifespan, docs
‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ main.py       <- APIRouter con todos los endpoints
‚îÇ   ‚îú‚îÄ‚îÄ endpoints.py  <- Funciones de cada endpoint
‚îÇ   ‚îî‚îÄ‚îÄ schemas.py    <- Pydantic models (request/response)
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îú‚îÄ‚îÄ config.py     <- Configuraci√≥n API (host, port, etc)
‚îÇ   ‚îî‚îÄ‚îÄ logger.py     <- Setup logging
‚îî‚îÄ‚îÄ services/
    ‚îî‚îÄ‚îÄ model_service.py <- L√≥gica de predicci√≥n y modelo
```

### Schemas Pydantic (Validaci√≥n Autom√°tica)

- `PredictionRequest`: 50+ features ac√∫sticos (validados)
- `PredictionResponse`: Estructura estandardizada respuesta
- `HealthResponse`: Status checks sistema

```bash
# Ver schemas JSON schema
curl http://localhost:8000/openapi.json | grep -A 50 "components"
```

---

## üîç Data Drift Detection & Monitoring

### Ejecutar Drift Detection

```bash
# Modo normal
python -m drift.run_drift

# Con par√°metros
python -m drift.run_drift --threshold 0.05 --output reports/drift/

# Modo test (con synthetic drift data)
python -m drift.run_drift --test-mode
```

### Qu√© Detecta

**Statistical Drift** (Evidently):
- Cambios en distribuci√≥n de features ac√∫sticos
- Comparaci√≥n train data vs inference data
- KL divergence > 0.3 = alerta

**Performance Degradation**:
- Ca√≠da en accuracy > 5% = ‚ö†Ô∏è warning
- Degradaci√≥n por clase (precision/recall)
- Matriz de confusi√≥n comparativa

### Thresholds y Alertas

| M√©trica | Threshold | Acci√≥n |
|---------|-----------|--------|
| Accuracy Drop | > 5% | ‚ö†Ô∏è Warning - Review model |
| Feature Shift | KL divergence > 0.3 | üî¥ Alert - Check data source |
| Class Imbalance | Ratio > 10:1 | üî¥ Critical - Retrain required |

### Output: drift_report.json

**Ubicaci√≥n**: `reports/drift/drift_report.json`

```json
{
  "timestamp": "2024-11-12T10:30:00Z",
  "drift_detected": false,
  "accuracy_drop_percent": -1.11,
  "features_shifted": 3,
  "critical_features": [
    "mfcc_1",
    "chroma_stft",
    "zero_crossing_rate"
  ],
  "recommendation": "Monitor - No action required",
  "performance_metrics": {
    "train_accuracy": 0.8017,
    "inference_accuracy": 0.7906,
    "diff": -0.0111,
    "train_precision": 0.78,
    "inference_precision": 0.77
  }
}
```

### Demo: Drift Real

**Sin drift**:
```
‚úÖ Accuracy: 80.17% ‚Üí 79.06% (diff: -1.11%)
‚úÖ Status: HEALTHY
```

**Con synthetic drift** (`generate_drift_data.py`):
```
üî¥ Accuracy: 80.17% ‚Üí 17.28% (diff: -62.89%)
üî¥ Status: CRITICAL - Retrain required
```

### Archivos y Scripts

```
drift/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ run_drift.py         <- Main execution script
‚îú‚îÄ‚îÄ drift_detector.py    <- Statistical analysis (Evidently)
‚îî‚îÄ‚îÄ comparators.py       <- Feature comparators

scripts/data/
‚îî‚îÄ‚îÄ generate_drift_data.py  <- Genera synthetic drift data para testing
```

### Generar y Probar Drift

```bash
# Generar synthetic drift data
python scripts/data/generate_drift_data.py

# Ejecutar drift detection
python -m drift.run_drift --test-mode

# Ver reporte
cat reports/drift/drift_report.json | jq .
```

---

## üê≥ Docker & Containerization

### Build Imagen

```bash
# Build imagen b√°sica
docker build -t mlops-team24:latest .

# Build con tag de versi√≥n
docker build -t mlops-team24:v1.0 -t mlops-team24:latest .

# Verificar imagen
docker images | grep mlops-team24
```

### Run Local (Standalone FastAPI)

```bash
# Run simple
docker run -p 8000:8000 mlops-team24:latest

# Con mount de c√≥digo (desarrollo)
docker run -it -p 8000:8000 \
  -v $(pwd):/app \
  mlops-team24:latest /bin/bash

# Con variables de entorno
docker run -p 8000:8000 \
  -e AWS_ACCESS_KEY_ID=$AWS_KEY \
  -e AWS_SECRET_ACCESS_KEY=$AWS_SECRET \
  mlops-team24:latest
```

**Verificar que funciona**:
```bash
curl http://localhost:8000/api/v1/health
```

### Docker Compose Stack

**Archivo**: `docker-compose.yml`

```bash
# Iniciar todo el stack
docker compose up

# Modo detached (background)
docker compose up -d

# Ver logs
docker compose logs -f api

# Ver status
docker compose ps

# Detener todo
docker compose down

# Limpiar vol√∫menes (reset total)
docker compose down -v
```

**Services que se levantan**:

| Service | Puerto | Descripci√≥n |
|---------|--------|-------------|
| `api` | `8000` | FastAPI application (uvicorn) |
| `mlflow` | `5001` | MLflow tracking server |
| `minio` | `9000` | S3-compatible storage (opcional) |

**Acceso**:
```
FastAPI Docs:  http://127.0.0.1:8000/docs
MLflow UI:     http://127.0.0.1:5001
MinIO:         http://127.0.0.1:9000
```

### Configuraci√≥n: config.env

**‚ö†Ô∏è IMPORTANTE**: `config.env` NO est√° versionado (`.gitignore`)

```bash
# 1. Copiar template
cp config.env.example config.env

# 2. Llenar con credenciales reales
cat config.env
```

**Contenido de config.env**:
```env
# AWS S3
AWS_ACCESS_KEY_ID=tu_access_key_aqui
AWS_SECRET_ACCESS_KEY=tu_secret_key_aqui
AWS_REGION=us-east-1
AWS_S3_BUCKET=mlops24-haowei-bucket

# MLflow
MLFLOW_BACKEND_STORE_URI=sqlite:///mlflow.db
MLFLOW_DEFAULT_ARTIFACT_ROOT=s3://mlops24-haowei-bucket/mlflow

# DVC
DVC_REMOTE_URL=s3://mlops24-haowei-bucket/dvc-storage
```

### Dockerfile

```dockerfile
FROM python:3.12-slim

WORKDIR /app

# Instalar dependencias del sistema
RUN apt-get update && apt-get install -y --no-install-recommends \
    git \
    && rm -rf /var/lib/apt/lists/*

# Copiar requirements
COPY requirements-prod.txt .

# Instalar Python deps
RUN pip install --no-cache-dir -r requirements-prod.txt

# Copiar c√≥digo
COPY . .

# Exponer puerto
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
  CMD python -c "import requests; requests.get('http://localhost:8000/api/v1/health', timeout=5)"

# Comando por defecto
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### Backend Storage

**Desarrollo** (docker-compose):
- SQLite: `mlflow.db` (local)
- Artifacts: Directorio `mlflow_artifacts/`

**Producci√≥n**:
- Backend: PostgreSQL o RDS
- Artifacts: AWS S3 (`mlops24-haowei-bucket`)

---

## üöÄ Publicaci√≥n en DockerHub

### ¬øQu√© es DockerHub y por qu√© se publica?

**DockerHub** es el registro central de im√°genes Docker. Al publicar nuestra imagen aqu√≠, permite que:

- ‚úÖ Cualquier persona descargue y ejecute el modelo sin necesidad de compilar
- ‚úÖ El equipo acceda a versiones consistentes desde cualquier m√°quina
- ‚úÖ CI/CD pipelines descarguen autom√°ticamente la versi√≥n correcta
- ‚úÖ Usuarios ejecuten el servicio con un simple comando: `docker run javirebull/ml-service:v3.0.0`
- ‚úÖ Se cree un historial de versiones documentadas

**Imagen**: `javirebull/ml-service:v3.0.0`

### 1. Autenticaci√≥n en DockerHub

Primero, logu√©ate en DockerHub desde tu m√°quina:

```bash
# Login interactivo
docker login

# Te pedir√°:
# Username: javirebull
# Password: (tu token o contrase√±a de DockerHub)
```

Para mayor seguridad, es recomendable usar **Personal Access Tokens** en lugar de contrase√±a:

```bash
# En DockerHub: Account Settings ‚Üí Security ‚Üí New Access Token
# Copia el token y √∫salo aqu√≠
docker login --username javirebull --password-stdin <<< "tu_personal_access_token"
```

**Verificar que est√°s loguado**:
```bash
cat ~/.docker/config.json  # Ver√° la autenticaci√≥n almacenada
```

### 2. Etiquetar la Imagen (Tag)

Antes de publicar, debes etiquetar la imagen local con el nombre correcto:

```bash
# Primero, construir la imagen (si no existe)
docker build -t mlops-team24:latest .

# Etiquetar para DockerHub
# Formato: docker tag <imagen_local> <usuario_dockerhub>/<nombre_repo>:<version>
docker tag mlops-team24:latest javirebull/ml-service:v3.0.0

# Tambi√©n etiquetar como latest
docker tag mlops-team24:latest javirebull/ml-service:latest

# Verificar tags
docker images | grep ml-service
```

**Esperado**:
```
REPOSITORY                 TAG       IMAGE ID       CREATED        SIZE
javirebull/ml-service      v3.0.0    abc123def456   5 minutes ago  1.2GB
javirebull/ml-service      latest    abc123def456   5 minutes ago  1.2GB
mlops-team24               latest    abc123def456   5 minutes ago  1.2GB
```

### 3. Publicar la Imagen (Push)

Ahora sube la imagen a DockerHub:

```bash
# Push versi√≥n espec√≠fica
docker push javirebull/ml-service:v3.0.0

# Push tag latest
docker push javirebull/ml-service:latest

# Verificar progreso
# Ver√°s: Pushing [==================================================>]
```

**Durante el push, ver√°s algo como**:
```
The push refers to repository [docker.io/javirebull/ml-service]
a1b2c3d4e5f6: Pushed
7g8h9i0j1k2l: Pushed
v3.0.0: digest: sha256:abc123... size: 4587
latest: digest: sha256:abc123... size: 4587
```

### 4. Verificar en DockerHub

Despu√©s del push, verifica que la imagen est√° disponible:

```bash
# Opci√≥n 1: Desde l√≠nea de comandos
docker pull javirebull/ml-service:v3.0.0

# Deber√≠a decir: Status: Downloaded newer image

# Opci√≥n 2: En navegador (recomendado)
# Visita: https://hub.docker.com/r/javirebull/ml-service
# Ver√°s:
# - Tags disponibles: v3.0.0, latest
# - Size de la imagen
# - Pull count
# - Fecha de √∫ltima actualizaci√≥n
```

### 5. Descargar y Ejecutar desde Cualquier M√°quina

Una vez publicada, cualquiera puede ejecutar el modelo con un solo comando:

```bash
# Descargar y ejecutar la imagen v3.0.0
docker run -p 8000:8000 javirebull/ml-service:v3.0.0

# Con variables de entorno (si es necesario)
docker run -p 8000:8000 \
  -e AWS_ACCESS_KEY_ID=$AWS_KEY \
  -e AWS_SECRET_ACCESS_KEY=$AWS_SECRET \
  javirebull/ml-service:v3.0.0

# Con datos persistentes
docker run -p 8000:8000 \
  -v $(pwd)/data:/app/data \
  javirebull/ml-service:v3.0.0

# Con nombre personalizado
docker run -p 8000:8000 \
  --name ml-service-prod \
  javirebull/ml-service:v3.0.0
```

**Verificar que est√° funcionando**:
```bash
# En otra terminal
curl http://localhost:8000/api/v1/health

# Respuesta esperada
# {"status": "healthy", "timestamp": "2024-11-12T..."}
```

### 6. Workflow Completo (Copy-Paste Ready)

Para publicar una nueva versi√≥n, sigue este flujo completo:

```bash
# ========== PASO 1: Build ==========
# Aseg√∫rate de que los cambios est√°n en main
git status  # working tree clean

# Construir imagen
docker build -t mlops-team24:latest .

# ========== PASO 2: Tag ==========
# Etiquetar para DockerHub
docker tag mlops-team24:latest javirebull/ml-service:v3.0.0
docker tag mlops-team24:latest javirebull/ml-service:latest

# Verificar
docker images | grep ml-service

# ========== PASO 3: Login ==========
# Loguete en DockerHub (si no est√° loguado)
docker login

# ========== PASO 4: Push ==========
# Publicar ambas tags
docker push javirebull/ml-service:v3.0.0
docker push javirebull/ml-service:latest

# Esperar a que termine (puede tomar 2-5 minutos)

# ========== PASO 5: Verificar ==========
# Test: Descargar imagen fresca
docker rmi javirebull/ml-service:v3.0.0  # Elimina local
docker pull javirebull/ml-service:v3.0.0  # Descarga desde Hub

# Ejecutar test
docker run -p 8000:8000 javirebull/ml-service:v3.0.0 &
sleep 3
curl http://localhost:8000/api/v1/health
```

### 7. Notas sobre Autenticaci√≥n y Usuario

‚ö†Ô∏è **IMPORTANTE - Usuario Correcto**:

| Campo | Valor |
|-------|-------|
| **Docker Hub Username** | `javirebull` |
| **Repository** | `javirebull/ml-service` |
| **Full Image** | `javirebull/ml-service:v3.0.0` |
| **Access** | P√∫blico (cualquiera puede descargar) |

**Verificar credenciales**:
```bash
# Ver usuario actualmente loguado
cat ~/.docker/config.json | grep -A2 "docker.io"

# Si cambio de usuario, hacer logout
docker logout

# Luego login con el usuario correcto
docker login --username javirebull
```

**Si tienes errores de autenticaci√≥n**:
```bash
# Error: "denied: requested access to the resource is denied"
# Soluci√≥n:
docker logout
docker login --username javirebull  # Con espacios, no flags
# Ingresa token/contrase√±a cuando se pida
```

### Versioning Strategy

Recomendaci√≥n de tags para futuras versiones:

```bash
# Versi√≥n patch (bug fixes)
docker tag mlops-team24:latest javirebull/ml-service:v3.0.1

# Versi√≥n minor (nuevas features)
docker tag mlops-team24:latest javirebull/ml-service:v3.1.0

# Versi√≥n major (cambios significativos)
docker tag mlops-team24:latest javirebull/ml-service:v4.0.0

# Siempre actualizar latest
docker tag mlops-team24:latest javirebull/ml-service:latest

# Push todas
docker push javirebull/ml-service:v3.0.1
docker push javirebull/ml-service:v3.1.0
docker push javirebull/ml-service:v4.0.0
docker push javirebull/ml-service:latest
```

---

## üîÑ Reproducibility & Seeds

### Seeds Configurados

**Archivo**: `acoustic_ml/__init__.py` y `acoustic_ml/config.py`

```python
import numpy as np
from sklearn.utils import check_random_state

RANDOM_SEED = 42
np.random.seed(RANDOM_SEED)

# En sklearn pipelines
RandomForestClassifier(random_state=RANDOM_SEED)
train_test_split(X, y, random_state=RANDOM_SEED)
```

**Todos los modelos usan**:
- `random_seed=42`
- `numpy seed=42`
- `sklearn seed=42`
- `pytorch seed=42` (si aplica)

### Requirements Fijado

**Archivo**: `requirements-prod.txt` (pip freeze)

```
scikit-learn==1.3.2
pandas==2.1.3
numpy==1.24.3
mlflow==2.10.0
fastapi==0.104.1
uvicorn==0.24.0
pydantic==2.4.2
```

**Generar nuevo freeze**:
```bash
pip freeze > requirements-prod.txt
```

### DVC Data Versioning

**Versionado**:
- ‚úÖ `data/processed/` ‚Üí `data.dvc`
- ‚úÖ `models/optimized/` ‚Üí `models/optimized.dvc`
- ‚úÖ Tracked en S3: `mlops24-haowei-bucket`

**Pull datos antes de ejecutar**:
```bash
dvc pull
```

### Reproducir Pipeline Completo

```bash
# Opci√≥n 1: Pull datos + Drift validation
dvc pull && python -m drift.run_drift

# Opci√≥n 2: Full train + predict pipeline
dvc pull && python acoustic_ml/modeling/train.py

# Opci√≥n 3: Verificar sincronizaci√≥n
make verify-sync && pytest tests/ -q
```

### Validar Reproducibilidad

```bash
# 1. Ejecutar pipeline en m√°quina A
dvc pull
python acoustic_ml/modeling/train.py
# ‚Üí Genera modelo con accuracy 80.17%

# 2. Ejecutar pipeline en m√°quina B (mismo c√≥digo)
dvc pull
python acoustic_ml/modeling/train.py
# ‚Üí DEBE generar exactamente el mismo modelo con accuracy 80.17%

# 3. Verificar hashes
md5sum models/optimized/production_model.pkl
# Deben coincidir entre m√°quinas
```

### Checklist Reproducibilidad

- ‚úÖ Seeds configurados (numpy, sklearn, random)
- ‚úÖ Requirements fijado con pip freeze
- ‚úÖ DVC data versioning activo
- ‚úÖ Docker containerizaci√≥n
- ‚úÖ 33 tests pasando
- ‚úÖ Git history limpio (conventional commits)
- ‚úÖ Pipeline determin√≠stico end-to-end

---

## ‚úÖ Phase 3 Requirements Checklist

**Todos los requisitos de Fase 3 implementados y validados**:

| Requisito | Implementaci√≥n | Status |
|-----------|---|--------|
| **1. Pruebas Unitarias/Integraci√≥n** | 33 tests (pytest) en `tests/` - Unitarios, Integraci√≥n, API, Full Pipeline | ‚úÖ COMPLETO |
| **2. FastAPI Serving** | 5 endpoints en `app/` - /health, /predict, /train, /models, / | ‚úÖ COMPLETO |
| **3. Reproducibilidad** | Seeds, requirements-prod.txt, DVC, Docker - dvc pull && python -m drift.run_drift | ‚úÖ COMPLETO |
| **4. Docker Containerizaci√≥n** | docker-compose.yml con FastAPI + MLflow - docker compose up | ‚úÖ COMPLETO |
| **5. Data Drift Detection** | Evidently + statistical monitoring - python -m drift.run_drift | ‚úÖ COMPLETO |

### Verificaci√≥n R√°pida

```bash
# 1. Tests
pytest tests/ -q  # ‚úÖ 33 passed

# 2. API
uvicorn app.main:app --reload
curl http://localhost:8000/api/v1/health  # ‚úÖ healthy

# 3. Reproducibilidad
dvc pull && python -m drift.run_drift  # ‚úÖ consistent results

# 4. Docker
docker compose up -d  # ‚úÖ all services running

# 5. Drift
python -m drift.run_drift --test-mode  # ‚úÖ drift_report.json generated
```

---

## üóÇÔ∏è Project Structure

**Estructura completa orientada a Fase 3**:

```
MLOps_Team24/
‚îÇ
‚îú‚îÄ‚îÄ üìÑ Configuraci√≥n (Ra√≠z)
‚îÇ   ‚îú‚îÄ‚îÄ README.md                    ‚Üê Este archivo
‚îÇ   ‚îú‚îÄ‚îÄ Makefile                     ‚Üê Comandos: make test, make train, etc
‚îÇ   ‚îú‚îÄ‚îÄ requirements-prod.txt        ‚Üê Dependencies fijadas (pip freeze)
‚îÇ   ‚îú‚îÄ‚îÄ requirements-dev.txt         ‚Üê Dev dependencies (pytest, etc)
‚îÇ   ‚îú‚îÄ‚îÄ pyproject.toml               ‚Üê Proyecto Python config
‚îÇ   ‚îú‚îÄ‚îÄ params.yaml                  ‚Üê Par√°metros DVC pipeline
‚îÇ   ‚îú‚îÄ‚îÄ dvc.yaml                     ‚Üê Pipeline stages
‚îÇ   ‚îú‚îÄ‚îÄ docker-compose.yml           ‚Üê FastAPI + MLflow + MinIO stack
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile                   ‚Üê Container image
‚îÇ   ‚îú‚îÄ‚îÄ config.env.example           ‚Üê Template variables (AWS, MLflow)
‚îÇ   ‚îú‚îÄ‚îÄ .gitignore                   ‚Üê config.env, .env, datos, modelos
‚îÇ   ‚îî‚îÄ‚îÄ .dvc/                        ‚Üê DVC configuraci√≥n
‚îÇ
‚îú‚îÄ‚îÄ üì¶ acoustic_ml/                  ‚Üê M√≥dulo Python principal
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ config.py                    ‚Üê Global config (RANDOM_SEED=42)
‚îÇ   ‚îú‚îÄ‚îÄ dataset.py                   ‚Üê DatasetManager (Singleton)
‚îÇ   ‚îú‚îÄ‚îÄ features.py                  ‚Üê Feature engineering
‚îÇ   ‚îú‚îÄ‚îÄ plots.py                     ‚Üê Visualizaciones
‚îÇ   ‚îî‚îÄ‚îÄ modeling/
‚îÇ       ‚îú‚îÄ‚îÄ train.py                 ‚Üê Training logic
‚îÇ       ‚îú‚îÄ‚îÄ predict.py               ‚Üê Inference
‚îÇ       ‚îú‚îÄ‚îÄ evaluate.py              ‚Üê Metrics
‚îÇ       ‚îú‚îÄ‚îÄ pipeline.py              ‚Üê MLOps pipeline
‚îÇ       ‚îî‚îÄ‚îÄ sklearn_pipeline.py      ‚Üê Production pipeline
‚îÇ
‚îú‚îÄ‚îÄ üåê app/                          ‚Üê FastAPI Application
‚îÇ   ‚îú‚îÄ‚îÄ main.py                      ‚Üê Entry point (uvicorn)
‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py                  ‚Üê APIRouter endpoints
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ endpoints.py             ‚Üê Endpoint functions
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ schemas.py               ‚Üê Pydantic models
‚îÇ   ‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.py                ‚Üê API config
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ logger.py                ‚Üê Logging setup
‚îÇ   ‚îî‚îÄ‚îÄ services/
‚îÇ       ‚îî‚îÄ‚îÄ model_service.py         ‚Üê Model predictions
‚îÇ
‚îú‚îÄ‚îÄ üîç drift/                        ‚Üê Drift Detection System
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ run_drift.py                 ‚Üê Main drift detection
‚îÇ   ‚îú‚îÄ‚îÄ drift_detector.py            ‚Üê Evidently analysis
‚îÇ   ‚îî‚îÄ‚îÄ comparators.py               ‚Üê Feature comparators
‚îÇ
‚îú‚îÄ‚îÄ üìä data/                         ‚Üê Datos (versionados DVC)
‚îÇ   ‚îú‚îÄ‚îÄ raw/                         ‚Üê Datos originales
‚îÇ   ‚îú‚îÄ‚îÄ interim/                     ‚Üê Transformaciones intermedias
‚îÇ   ‚îú‚îÄ‚îÄ processed/                   ‚Üê Datos finales
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ turkish_music_emotion_v2_cleaned_full.csv (400+ filas)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ X_train.csv, X_test.csv
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ y_train.csv, y_test.csv
‚îÇ   ‚îú‚îÄ‚îÄ data.dvc                     ‚Üê DVC tracking
‚îÇ   ‚îî‚îÄ‚îÄ .gitignore                   ‚Üê Ignorar archivos grandes
‚îÇ
‚îú‚îÄ‚îÄ üíæ models/                       ‚Üê Modelos (versionados)
‚îÇ   ‚îú‚îÄ‚îÄ optimized/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ production_model.pkl     ‚Üê Modelo actual (80.17%)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ production_model_metadata.json
‚îÇ   ‚îî‚îÄ‚îÄ optimized.dvc                ‚Üê DVC tracking
‚îÇ
‚îú‚îÄ‚îÄ üìà mlflow_artifacts/             ‚Üê MLflow experiments
‚îÇ   ‚îú‚îÄ‚îÄ exp_01_Random_Forest_Current_Best/
‚îÇ   ‚îú‚îÄ‚îÄ experiments_summary.csv
‚îÇ   ‚îî‚îÄ‚îÄ experiments_report.txt
‚îÇ
‚îú‚îÄ‚îÄ üìì notebooks/                    ‚Üê Jupyter notebooks
‚îÇ   ‚îú‚îÄ‚îÄ 1.0-team-eda-turkish-music.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 2.0-team-preprocessing.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 3.0-team-modeling-evaluation.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ archive/
‚îÇ
‚îú‚îÄ‚îÄ üìà reports/                      ‚Üê An√°lisis y reportes
‚îÇ   ‚îú‚îÄ‚îÄ figures/                     ‚Üê Visualizaciones
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ confusion_matrices_top3.png
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ final_confusion_matrix.png
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ *.png
‚îÇ   ‚îú‚îÄ‚îÄ drift/                       ‚Üê Drift reports
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ drift_report.json        ‚Üê Salida drift detection
‚îÇ   ‚îî‚îÄ‚îÄ metrics.json
‚îÇ
‚îú‚îÄ‚îÄ üß™ tests/                        ‚Üê Test Suite (33 tests)
‚îÇ   ‚îú‚îÄ‚îÄ test_dataset_equivalence.py  ‚Üê Dataset tests
‚îÇ   ‚îú‚îÄ‚îÄ test_sklearn_pipeline.py     ‚Üê Pipeline tests
‚îÇ   ‚îú‚îÄ‚îÄ test_full_integration.py     ‚Üê Integration tests
‚îÇ   ‚îú‚îÄ‚îÄ test_api_endpoints.py        ‚Üê API tests (TestClient)
‚îÇ   ‚îú‚îÄ‚îÄ validate_cookiecutter.py     ‚Üê Structure validation
‚îÇ   ‚îú‚îÄ‚îÄ validate_dataset.py
‚îÇ   ‚îú‚îÄ‚îÄ validate_features.py
‚îÇ   ‚îî‚îÄ‚îÄ validate_plots.py
‚îÇ
‚îú‚îÄ‚îÄ üìö scripts/                      ‚Üê Scripts automatizados
‚îÇ   ‚îú‚îÄ‚îÄ training/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train_baseline.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ run_mlflow_experiments.py
‚îÇ   ‚îú‚îÄ‚îÄ analysis/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ analyze_outliers.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ compare_scalers.py
‚îÇ   ‚îú‚îÄ‚îÄ validation/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ verify_sync.py
‚îÇ   ‚îî‚îÄ‚îÄ data/
‚îÇ       ‚îî‚îÄ‚îÄ generate_drift_data.py   ‚Üê Synthetic drift generation
‚îÇ
‚îú‚îÄ‚îÄ üìä monitoring/                   ‚Üê Monitoring & Dashboards
‚îÇ   ‚îú‚îÄ‚îÄ dashboard/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ streamlit_dashboard.py   ‚Üê Cookiecutter validation dashboard
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îÇ
‚îî‚îÄ‚îÄ üìö references/                   ‚Üê Documentaci√≥n externa
    ‚îú‚îÄ‚îÄ Diccionario_Variables_Musica_Turca.xlsx
    ‚îú‚îÄ‚îÄ Fase1_Equipo24.pdf
    ‚îú‚îÄ‚îÄ Fase2_Equipo24.pdf
    ‚îî‚îÄ‚îÄ Team24_Machine_Learning_Canvas.pdf
```

**Cookiecutter Data Science Compliance**: ‚úÖ 95.2%

**Referencia**: [Cookiecutter Data Science](https://drivendata.github.io/cookiecutter-data-science/)

---
## üéµ Streamlit App - Production Demo

### üåê Aplicaci√≥n Web Desplegada

Hemos desarrollado una **aplicaci√≥n web interactiva** para demostrar las capacidades del sistema de reconocimiento de emociones musicales en producci√≥n.

**üîó URL de Acceso**: **[tu-url-de-streamlit].streamlit.app**

**üì± Compatibilidad**: Desktop, Tablet, Mobile

---

### ‚ú® Caracter√≠sticas Principales

#### üéº 1. An√°lisis de M√∫sica en Tiempo Real

- **Predicci√≥n instant√°nea** de emociones en canciones turcas
- **4 emociones detectadas**: Angry üò°, Happy üòä, Relax üòå, Sad üò¢
- **Confianza de predicci√≥n**: Probabilidades por clase
- **Modelo**: Random Forest (76.9% accuracy)

#### üìÅ 2. Upload de Archivos

- **Formatos soportados**: `.mp3`, `.wav`, `.ogg`
- **Procesamiento autom√°tico**: Extracci√≥n de features ac√∫sticas
- **An√°lisis inmediato**: Resultados en segundos
- **L√≠mite de tama√±o**: 200MB por archivo

#### üìä 3. Visualizaciones Interactivas

**Waveform (Forma de Onda)**:
- Visualizaci√≥n temporal de la se√±al de audio
- Amplitud vs. tiempo
- Identificaci√≥n de patrones r√≠tmicos

**Spectrogram (Espectrograma)**:
- Representaci√≥n tiempo-frecuencia
- Intensidad de frecuencias a lo largo del tiempo
- Identificaci√≥n de caracter√≠sticas tonales

**Feature Importance**:
- Top 20 caracter√≠sticas m√°s relevantes
- Impacto de cada feature en la predicci√≥n
- An√°lisis de MFCC, spectral features, temporal features

#### üéØ 4. Predicci√≥n con Audios de Muestra

- **Biblioteca de ejemplos**: Canciones turcas pre-cargadas
- **Cada emoci√≥n representada**: 1-2 ejemplos por clase
- **Testing r√°pido**: Probar el modelo sin subir archivos
- **Comparaci√≥n**: Ver diferentes emociones musicales

#### üîÑ 5. Batch Analysis

- **An√°lisis m√∫ltiple**: Subir y procesar varias canciones
- **Resultados agregados**: Estad√≠sticas del conjunto
- **Exportar CSV**: Descargar predicciones completas
- **Comparaci√≥n entre canciones**: An√°lisis comparativo

#### üéöÔ∏è 6. Selector de Modelos (Local)

Si ejecutas la app localmente, puedes cambiar entre modelos:
- Random Forest (default) - 76.9% accuracy
- Gradient Boosting - 77.8% accuracy
- XGBoost - experimental

---

### üöÄ C√≥mo Usar la App

#### Opci√≥n 1: App en la Nube (Recomendado)

1. **Acceder**: Ir a [tu-url-de-streamlit].streamlit.app
2. **Elegir modo**:
   - üìÅ **Upload**: Subir tu propio audio
   - üéµ **Samples**: Usar audios de ejemplo
3. **Analizar**: La app procesar√° autom√°ticamente
4. **Ver resultados**:
   - Emoci√≥n predicha con confianza
   - Visualizaciones (waveform, spectrogram)
   - Feature importance
5. **Experimentar**: Probar con diferentes canciones

#### Opci√≥n 2: Ejecutar Localmente

```bash
# 1. Navegar al directorio de la app
cd streamlit_app/  # o donde est√© tu app de Streamlit

# 2. Instalar dependencias
pip install -r requirements.txt

# 3. Ejecutar app
streamlit run app.py

# 4. Abrir en navegador
# Autom√°ticamente abre en: http://localhost:8501
```

---

### üõ†Ô∏è Tecnolog√≠as Utilizadas

**Backend**:
- **Streamlit**: Framework de la aplicaci√≥n
- **scikit-learn**: Modelo de ML (Random Forest)
- **librosa**: Procesamiento de audio y feature extraction
- **pandas/numpy**: Manipulaci√≥n de datos

**Visualizaci√≥n**:
- **matplotlib**: Gr√°ficas est√°ticas
- **plotly**: Visualizaciones interactivas
- **seaborn**: Styling de gr√°ficas

**Deployment**:
- **Streamlit Cloud**: Hosting gratuito
- **GitHub Integration**: Deploy autom√°tico desde main branch
- **Secrets Management**: Configuraci√≥n segura

---

### üìÅ Estructura de la App

```
streamlit_app/
‚îú‚îÄ‚îÄ app.py                      <- Main application file
‚îú‚îÄ‚îÄ requirements.txt            <- Dependencies
‚îú‚îÄ‚îÄ .streamlit/
‚îÇ   ‚îî‚îÄ‚îÄ config.toml             <- Streamlit configuration
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ baseline_model.pkl      <- Pre-trained model
‚îú‚îÄ‚îÄ sample_audios/              <- Sample Turkish music files
‚îÇ   ‚îú‚îÄ‚îÄ angry_example.mp3
‚îÇ   ‚îú‚îÄ‚îÄ happy_example.mp3
‚îÇ   ‚îú‚îÄ‚îÄ relax_example.mp3
‚îÇ   ‚îî‚îÄ‚îÄ sad_example.mp3
‚îî‚îÄ‚îÄ utils/
    ‚îú‚îÄ‚îÄ audio_processor.py      <- Audio feature extraction
    ‚îú‚îÄ‚îÄ model_loader.py         <- Model loading utilities
    ‚îî‚îÄ‚îÄ visualizations.py       <- Plot generation functions
```

---

### üîß Configuraci√≥n y Personalizaci√≥n

#### Variables de Entorno

Si ejecutas localmente, puedes configurar:

```toml
# .streamlit/secrets.toml
[model]
default_model = "random_forest"
confidence_threshold = 0.5

[audio]
max_file_size = 200  # MB
allowed_formats = [".mp3", ".wav", ".ogg"]
sample_rate = 22050

[features]
n_mfcc = 13
n_fft = 2048
hop_length = 512
```

#### Personalizar Tema

```toml
# .streamlit/config.toml
[theme]
primaryColor = "#667eea"
backgroundColor = "#0e1117"
secondaryBackgroundColor = "#262730"
textColor = "#fafafa"
font = "sans serif"
```

---

### üìä Ejemplos de Uso

#### Ejemplo 1: An√°lisis de Audio Subido

```
1. Usuario sube: "turkish_song.mp3"
2. App extrae 50+ features ac√∫sticas
3. Modelo predice: "Happy" (confianza: 87.3%)
4. Visualizaciones generadas:
   - Waveform: Muestra patrones r√≠tmicos alegres
   - Spectrogram: Frecuencias altas prominentes
   - Features: MFCC_3 y Spectral_Centroid destacados
```

#### Ejemplo 2: Comparaci√≥n de Emociones

```
Usuario selecciona 4 samples (uno por emoci√≥n):
- Angry:  Predicci√≥n correcta (92.1%)
- Happy:  Predicci√≥n correcta (87.3%)
- Relax:  Predicci√≥n correcta (81.5%)
- Sad:    Predicci√≥n correcta (79.8%)

Resultado: 100% accuracy en samples
```

#### Ejemplo 3: Batch Analysis

```
Usuario sube 10 canciones:
- 7 predicciones correctas
- 3 con confusi√≥n Relax ‚Üî Sad
- Accuracy batch: 70%
- Confianza promedio: 78.4%
```

---

### üéØ Casos de Uso

#### üéµ Para M√∫sicos y Productores

- **Validar la emoci√≥n** que transmite una composici√≥n
- **Comparar versiones** de la misma canci√≥n
- **Analizar el "mood"** de un √°lbum completo

#### üîç Para Investigadores

- **Estudiar caracter√≠sticas** de m√∫sica emocional turca
- **Comparar con otros datasets** musicales
- **Validar modelos** de emoci√≥n musical

#### üìö Para Educaci√≥n

- **Demostrar ML aplicado** en an√°lisis de audio
- **Ense√±ar feature engineering** en m√∫sica
- **Mostrar pipeline MLOps** completo

#### üéß Para Oyentes

- **Descubrir canciones** con emociones espec√≠ficas
- **Entender por qu√©** una canci√≥n suena "triste" o "alegre"
- **Explorar m√∫sica turca** por emoci√≥n

---

### üêõ Troubleshooting

#### Error: "Model not found"
```bash
# Verificar que el modelo existe
ls models/baseline_model.pkl

# Re-descargar desde DVC
dvc pull models/baseline.dvc
```

#### Error: "Audio file too large"
```python
# Comprimir audio antes de subir
from pydub import AudioSegment
audio = AudioSegment.from_mp3("large_file.mp3")
audio.export("compressed.mp3", format="mp3", bitrate="128k")
```

#### Error: "Feature extraction failed"
```python
# Verificar formato de audio
import librosa
y, sr = librosa.load("audio.mp3", sr=22050)
print(f"Duration: {len(y)/sr:.2f}s, Sample rate: {sr}Hz")
```

---

### üöÄ Roadmap de la App

**Fase Actual (Phase 2)** ‚úÖ:
- ‚úÖ Predicci√≥n b√°sica con modelo Random Forest
- ‚úÖ Upload de archivos de audio
- ‚úÖ Visualizaciones (waveform, spectrogram)
- ‚úÖ An√°lisis de feature importance
- ‚úÖ Deploy en Streamlit Cloud

**Pr√≥ximas Mejoras (Phase 3)**:
- üîÑ Multi-model comparison en tiempo real
- üîÑ A/B testing entre modelos
- üîÑ Export de reportes PDF
- üîÑ Integraci√≥n con API REST
- üîÑ User authentication
- üîÑ Historial de predicciones

**Futuro (Phase 4+)**:
- üí° Recomendaciones de canciones similares
- üí° An√°lisis de playlists completas
- üí° Integraci√≥n con Spotify API
- üí° Mobile app (React Native)
- üí° Real-time audio recording y an√°lisis

---

### üì∏ Screenshots

> **Nota**: Agregar screenshots reales de la app cuando est√© desplegada:

```markdown
![Home Page](docs/images/app_home.png)
*P√°gina principal con opciones de an√°lisis*

![Prediction Results](docs/images/app_prediction.png)
*Resultados de predicci√≥n con visualizaciones*

![Feature Importance](docs/images/app_features.png)
*An√°lisis de caracter√≠sticas m√°s relevantes*
```

---

### üîó Links Relacionados

- **App en Producci√≥n**: [tu-url-de-streamlit].streamlit.app
- **Dashboard Cookiecutter**: [https://mlopsteam24-cookiecutter.streamlit.app](https://mlopsteam24-cookiecutter.streamlit.app)
- **Repositorio GitHub**: [tu-repo-url]
- **MLflow UI**: http://localhost:5001 (local)
- **Documentaci√≥n de Streamlit**: https://docs.streamlit.io

---

## üìä Monitoring y Validaci√≥n

### Dashboard Streamlit

**URL**: [https://mlopsteam24-cookiecutter.streamlit.app](https://mlopsteam24-cookiecutter.streamlit.app)

**Caracter√≠sticas**:
- ‚úÖ Validaci√≥n estructura Cookiecutter (95.2%)
- ‚úÖ Verificaci√≥n de directorios cr√≠ticos
- ‚úÖ Validaci√≥n de archivos configuraci√≥n
- ‚úÖ Estado de sincronizaci√≥n DVC
- ‚úÖ M√©tricas de cumplimiento

**Local**:
```bash
cd monitoring/dashboard
streamlit run streamlit_dashboard.py
```

### Verificaci√≥n de Sincronizaci√≥n

**Script**: `scripts/validation/verify_sync.py`

Verifica:
1. ‚úÖ DVC status (sin cambios pendientes)
2. ‚úÖ Git status (working tree clean)
3. ‚úÖ S3 sync (archivos en sync)
4. ‚úÖ Environment consistency

```bash
make verify-sync
# o
python scripts/validation/verify_sync.py
```

**Output Esperado**:
```
‚úÖ DVC Status: Clean
‚úÖ Git Status: Clean
‚úÖ S3 Sync: OK
‚úÖ Environment: Consistent
```


## üîÑ Workflows y Contribuci√≥n

### Workflow Est√°ndar

#### 1. Antes de Comenzar

```bash
# Activar entorno
conda activate acoustic_ml

# Verificar sincronizaci√≥n
make verify-sync

# Actualizar datos
dvc pull
git pull
```

#### 2. Crear Branch

```bash
git checkout -b feat/nueva-funcionalidad
```

#### 3. Hacer Cambios

**Si modificas c√≥digo**:
```bash
# Editar archivos
vim acoustic_ml/features.py

# Ejecutar tests
python tests/validate_features.py

# Los cambios est√°n disponibles inmediatamente (instalaci√≥n -e)
```

**Si modificas datos**:
```bash
# DVC tracking
dvc add data
git add data.dvc data/.gitignore
dvc push
```

**Si instalas paquetes**:
```bash
pip install nuevo-paquete
make freeze
git add requirements.txt
```

#### 4. Commit Changes

```bash
git add .
git commit -m "feat: descripci√≥n clara"
```

Seguir [Conventional Commits](https://www.conventionalcommits.org/):
- `feat:` nueva funcionalidad
- `fix:` correcci√≥n de bug
- `docs:` documentaci√≥n
- `refactor:` refactorizaci√≥n
- `test:` tests
- `chore:` mantenimiento

#### 5. Push Changes

```bash
git push origin feat/nueva-funcionalidad
dvc push  # Si modificaste datos
```

#### 6. Pull Request

Crear PR a `main` con descripci√≥n clara.

### Buenas Pr√°cticas

#### ‚úÖ DO

- ‚úÖ Ejecutar `make verify-sync` antes de comenzar
- ‚úÖ Usar `DatasetManager` para gestionar datos
- ‚úÖ Usar `create_sklearn_pipeline()` para producci√≥n
- ‚úÖ Ejecutar tests antes de commit
- ‚úÖ Documentar experimentos en MLflow
- ‚úÖ Mantener notebooks limpios (sin outputs)
- ‚úÖ Usar `RobustScaler` para outliers
- ‚úÖ Escribir docstrings completos
- ‚úÖ Seguir Conventional Commits
- ‚úÖ Hacer `dvc push` despu√©s de modificar datos

#### ‚ùå DON'T

- ‚ùå Modificar datos sin DVC tracking
- ‚ùå Commitear archivos temporales
- ‚ùå Usar c√≥digo legacy sin revisar
- ‚ùå Hacer commits sin tests
- ‚ùå Push sin `dvc push` (si hay datos nuevos)
- ‚ùå Commitear notebooks con outputs
- ‚ùå Modificar `requirements.txt` manualmente
- ‚ùå Ignorar warnings de validaci√≥n

### Code Review Checklist

Antes de aprobar PR:
- [ ] Tests pasan
- [ ] Documentaci√≥n actualizada
- [ ] No hay archivos temporales
- [ ] DVC en sync (si aplica)
- [ ] C√≥digo sigue est√°ndares del proyecto
- [ ] Commit messages son claros

---

## üë• Equipo de Desarrollo

<div align="center">

<table style="width:100%; border:none;">
  <tr>
    <td align="center" style="border:none; padding:20px 10px;">
      <img src="https://iili.io/Kw90kmB.png" alt="David Cruz Beltr√°n" width="160" style="border-radius: 50%; border: 5px solid #667eea; box-shadow: 0 8px 16px rgba(102, 126, 234, 0.4);"/>
      <h3>David Cruz Beltr√°n</h3>
      <img src="https://img.shields.io/badge/ID-A01360416-667eea?style=for-the-badge" alt="Matr√≠cula"/>
      <p><strong>üîß Software Engineer</strong><br/>
      <em>Pipeline Architecture & Code Quality</em></p>
    </td>
    <td align="center" style="border:none; padding:20px 10px;">
      <img src="https://iili.io/KuvsGKx.png" alt="Javier Augusto Rebull Saucedo" width="160" style="border-radius: 50%; border: 5px solid #764ba2; box-shadow: 0 8px 16px rgba(118, 75, 162, 0.4);"/>
      <h3>Javier Augusto Rebull Saucedo</h3>
      <img src="https://img.shields.io/badge/ID-A01795838-764ba2?style=for-the-badge" alt="Matr√≠cula"/>
      <p><strong>‚öôÔ∏è SRE / Data Engineer</strong><br/>
      <em>DevOps, Infrastructure & Data Versioning</em></p>
    </td>
    <td align="center" style="border:none; padding:20px 10px;">
      <img src="https://iili.io/Kw91d74.png" alt="Sandra Luz Cervantes Espinoza" width="160" style="border-radius: 50%; border: 5px solid #f093fb; box-shadow: 0 8px 16px rgba(240, 147, 251, 0.4);"/>
      <h3>Sandra Luz Cervantes Espinoza</h3>
      <img src="https://img.shields.io/badge/ID-A01796937-f093fb?style=for-the-badge" alt="Matr√≠cula"/>
      <p><strong>ü§ñ ML Engineer / Data Scientist</strong><br/>
      <em>Model Development & Experimentation</em></p>
    </td>
  </tr>
</table>

</div>

---

## üìö Recursos Adicionales

### Documentaci√≥n

- [Cookiecutter Data Science](https://drivendata.github.io/cookiecutter-data-science/)
- [DVC Documentation](https://dvc.org/doc)
- [MLflow Documentation](https://mlflow.org/docs/latest/index.html)
- [Scikit-learn Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)

### Referencias del Proyecto

- `references/Diccionario_Variables_Musica_Turca.xlsx`: Diccionario de variables
- `references/Fase 1_Equipo24.pdf`: Entrega Fase 1
- `references/Fase 2_Equipo24.pdf`: Entrega Fase 2
- `references/Team24_Machine Learning Canvas v1.0.pdf`: ML Canvas

---

<div align="center">

**‚≠ê Si este proyecto te resulta √∫til, considera darle una estrella ‚≠ê**

---

**Desarrollado con ‚ù§Ô∏è por MLOps Team 24**

üèóÔ∏è **Arquitectura Profesional** | üß™ **Testing Comprehensivo** | üéØ **Production-Ready**

üìä **95.2% Cookiecutter Compliance** | ‚òÅÔ∏è **Cloud-Native** | üîÑ **Fully Reproducible**

---

*√öltima actualizaci√≥n: Noviembre 2024 - Phase 3 Production Deployment*

**Estructura basada en**: [Cookiecutter Data Science](https://drivendata.github.io/cookiecutter-data-science/)

</div>

---

## üìä Data Drift Detection Dashboard

**Dashboard en Vivo:**
üîó [Turkish Drift MLOps - Streamlit Cloud](https://turskishdriftmlops.streamlit.app)

### üéØ Descripci√≥n

Dashboard interactivo para monitoreo de Data Drift en el modelo de reconocimiento de emociones en m√∫sica turca. Implementado con Streamlit + Plotly con paleta de colores profesional.

### üì± Secciones del Dashboard

#### 1Ô∏è‚É£ **Resumen Ejecutivo** (Executive Summary)
- **M√©trica Baseline:** Valor de referencia de predicci√≥n promedio
- **Mayor Impacto:** Escenario con mayor % de drift detectado
- **Escenarios Cr√≠ticos:** Conteo de escenarios que requieren atenci√≥n

**Visualizaciones:**
- Gr√°fico de cambio de media de predicciones por escenario
- Distribuci√≥n de clases de emoci√≥n (Angry üò†, Happy üòä, Relax üòå, Sad üò¢)
- Tabla de recomendaciones por escenario
- Alertas contextuales (INFO, WARNING, CRITICAL)

#### 2Ô∏è‚É£ **An√°lisis Detallado** (Detailed Analysis)
Selecciona un escenario individual para inspeccionar:
- **M√©tricas por escenario:** Total muestras, media de predicci√≥n, clases √∫nicas, timestamp
- **Distribuci√≥n de emociones:** Gr√°fico de barras con porcentajes
- **Histograma de predicciones:** Frecuencia de cada clase predicha

#### 3Ô∏è‚É£ **Comparaci√≥n de Escenarios** (Scenario Comparison)
Comparaci√≥n lado a lado de todos los escenarios:
- Baseline (sin drift)
- Mean Shift (+30% en todas las medias)
- Variance Change (√ó1.5 varianza)
- Combined Drift (Mean +20% + Var √ó1.3 + outliers)

**Tabla resumen** con media de predicci√≥n y total de muestras.

#### 4Ô∏è‚É£ **Metadatos** (Metadata)
- **Informaci√≥n del entrenamiento:** Muestras, features, fecha generaci√≥n, ruta datos
- **Escenarios de drift:** Descripci√≥n, impacto, causa de cada escenario
- **Visualizaci√≥n JSON crudo:** Para debugging y validaci√≥n

### üé® Paleta de Colores
Dise√±o profesional con colores teal/verde vividos para m√°xima legibilidad en light y dark mode:
- Primary: `#17A2A2` (Teal vivido)
- Background: `#F0FFFE` (Blanco suave)
- Surface: `#B3E5E1` (Tarjetas verde pastel)

### üîß Stack Tecnol√≥gico
- **Framework:** Streamlit 1.32.0
- **Visualizaci√≥n:** Plotly 5.18.0
- **Data:** Pandas 2.1.3, NumPy 1.24.4
- **Deployment:** Streamlit Cloud

### üìÇ Estructura
```
drift/
‚îú‚îÄ‚îÄ drift_streamlit_dashboard.py    # C√≥digo principal
‚îú‚îÄ‚îÄ requirements.txt                # Dependencias
‚îú‚îÄ‚îÄ drift_baseline.json
‚îú‚îÄ‚îÄ drift_mean_shift.json
‚îú‚îÄ‚îÄ drift_variance_change.json
‚îú‚îÄ‚îÄ drift_combined_drift.json
‚îú‚îÄ‚îÄ drift_executive_summary.json
‚îî‚îÄ‚îÄ drift_scenarios_metadata.json
```

### ‚ö° Interpretaci√≥n de Resultados

| Impacto | Rango | Acci√≥n |
|---------|-------|--------|
| LOW | < 1% | Monitor |
| MEDIUM | 1-3% | Investigate |
| HIGH | 3-5% | Investigate |
| CRITICAL | > 5% | Retrain Model |

### üöÄ Ejecutar Localmente
```bash
cd drift/
bash run_dashboard.sh
```

Abrir√° en `http://localhost:8501`

### üìä Hallazgos Clave
- ‚úÖ **Mean Shift Robusto (0% impacto):** El modelo es resiliente a desplazamientos sistem√°ticos
- ‚ö†Ô∏è **Variance Change Vulnerable (3.37% impacto):** Necesita atenci√≥n a cambios de ruido
- üî¥ **Combined Drift Cr√≠tico (4.33% impacto):** Requiere re-entrenamiento

---

