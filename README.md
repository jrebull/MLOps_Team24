# ğŸµ Acoustic ML - Music Emotion Recognition

<div align="center">

**MLOps Team 24 - Proyecto de reconocimiento de emociones musicales**

[![Python](https://img.shields.io/badge/Python-3.12-blue.svg)](https://www.python.org/downloads/)
[![MLflow](https://img.shields.io/badge/MLflow-Tracking-0194E2?logo=mlflow)](https://mlflow.org/)
[![DVC](https://img.shields.io/badge/DVC-Data%20Versioning-945DD6?logo=dvc)](https://dvc.org/)
[![AWS S3](https://img.shields.io/badge/AWS-S3-FF9900?logo=amazon-aws)](https://aws.amazon.com/s3/)

<!-- Badges -->
[![verify-sync](https://img.shields.io/badge/verify--sync-make-blue?logo=gnu&logoColor=white)](#verificaciÃ³n-rÃ¡pida-antes-de-trabajar)
[![dependencies](https://img.shields.io/badge/deps-requirements.txt-informational?logo=python&logoColor=white)](#reproducibilidad-de-entornos)
[![notebooks](https://img.shields.io/badge/notebooks-clean%20outputs-success?logo=jupyter&logoColor=white)](#buenas-prÃ¡cticas-con-notebooks)
[![Tests](https://img.shields.io/badge/tests-37%2F37_passing-success?logo=pytest&logoColor=white)](#-testing-y-validaciÃ³n)
[![Code Quality](https://img.shields.io/badge/code%20quality-production--ready-brightgreen?logo=python&logoColor=white)](#-arquitectura-del-cÃ³digo)

</div>

---

## ğŸ“‹ Tabla de Contenidos

- [Sobre el Proyecto](#-sobre-el-proyecto)
- [InformaciÃ³n AcadÃ©mica](#-informaciÃ³n-acadÃ©mica)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [ğŸ†• Arquitectura del CÃ³digo](#-arquitectura-del-cÃ³digo)
  - [MÃ³dulos Refactorizados](#mÃ³dulos-refactorizados)
  - [Design Patterns Implementados](#design-patterns-implementados)
  - [MÃ©tricas de RefactorizaciÃ³n](#-mÃ©tricas-de-refactorizaciÃ³n)
- [ğŸ†• GuÃ­a de Uso de MÃ³dulos](#-guÃ­a-de-uso-de-mÃ³dulos)
- [ğŸ†• Testing y ValidaciÃ³n](#-testing-y-validaciÃ³n)
- [Datasets Disponibles](#-datasets-disponibles)
- [Requisitos Previos](#-requisitos-previos)
- [InstalaciÃ³n](#-instalaciÃ³n)
- [GestiÃ³n de Datos (DVC + S3)](#-gestiÃ³n-de-datos-dvc--s3)
- [Uso](#-uso--usage)
- [VerificaciÃ³n RÃ¡pida antes de Trabajar](#-verificaciÃ³n-rÃ¡pida-antes-de-trabajar)
- [Docker Compose](#-docker-compose)
- [Limpieza Local](#-limpieza-local)
- [Arquitectura del Pipeline](#-arquitectura-del-pipeline)
- [ContribuciÃ³n](#-contribuciÃ³n)
- [Equipo](#-equipo)

---

## ğŸ¯ Sobre el Proyecto

Este repositorio contiene la implementaciÃ³n completa de un sistema MLOps para reconocimiento de emociones en mÃºsica, siguiendo las mejores prÃ¡cticas de la industria con la estructura **Cookiecutter Data Science**. El proyecto integra:

- ğŸ“Š **Versionado de datos** con DVC
- ğŸ”„ **Pipelines reproducibles** automatizados
- ğŸ“ˆ **Tracking de experimentos** con MLflow
- â˜ï¸ **Almacenamiento en la nube** (AWS S3)
- ğŸ¤– **Modelos de Machine Learning** versionados
- ğŸ—‚ï¸ **Estructura modular** siguiendo estÃ¡ndares de la industria
- ğŸ—ï¸ **Arquitectura OOP** con SOLID principles
- ğŸ§ª **Testing comprehensivo** (37/37 tests passing)

---

## ğŸ“˜ InformaciÃ³n AcadÃ©mica

**Instituto TecnolÃ³gico y de Estudios Superiores de Monterrey**  
*MaestrÃ­a en Inteligencia Artificial Aplicada (MNA)*

- **Curso:** Operaciones de Aprendizaje AutomÃ¡tico
- **Periodo:** Septiembre â€“ Diciembre 2025
- **Equipo:** NÂ° 24

### ğŸ‘¨â€ğŸ« Profesores

| Rol | Nombre |
|-----|--------|
| Titular | Dr. Gerardo RodrÃ­guez HernÃ¡ndez |
| Titular | Mtro. Ricardo Valdez HernÃ¡ndez |
| Asistente | Mtra. MarÃ­a Mylen TreviÃ±o Elizondo |
| Tutor | JosÃ© Ãngel MartÃ­nez Navarro |

---

## ğŸ—‚ï¸ Estructura del Proyecto

Organizado siguiendo **Cookiecutter Data Science** para mÃ¡xima reproducibilidad y claridad:

```
â”œâ”€â”€ LICENSE                 <- Licencia del proyecto
â”œâ”€â”€ Makefile               <- Comandos Ãºtiles (make data, make train, etc.)
â”œâ”€â”€ README.md              <- Este archivo
â”œâ”€â”€ pyproject.toml         <- ConfiguraciÃ³n del proyecto y dependencias
â”‚
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ external           <- Datos de fuentes externas
â”‚   â”œâ”€â”€ interim            <- Datos intermedios transformados
â”‚   â”œâ”€â”€ processed          <- Datasets finales para modelado
â”‚   â”‚   â”œâ”€â”€ turkish_music_emotion_cleaned.csv              (Limpieza inicial)
â”‚   â”‚   â”œâ”€â”€ turkish_music_emotion_v1_original.csv          (400 filas - Baseline)
â”‚   â”‚   â”œâ”€â”€ turkish_music_emotion_v2_cleaned_aligned.csv   (400 filas - ComparaciÃ³n)
â”‚   â”‚   â””â”€â”€ turkish_music_emotion_v2_cleaned_full.csv      (408 filas) â­ RECOMENDADO
â”‚   â””â”€â”€ raw                <- Datos originales inmutables (versionados con DVC)
â”‚       â”œâ”€â”€ turkis_music_emotion_original.csv      (125 KB)
â”‚       â”œâ”€â”€ turkish_music_emotion_modified.csv     (130 KB)
â”‚       â””â”€â”€ .gitignore                             (Git ignora los CSV)
â”‚
â”œâ”€â”€ models                 <- Modelos entrenados y serializados
â”‚   â””â”€â”€ baseline_model.pkl
â”‚
â”œâ”€â”€ notebooks              <- Jupyter notebooks para exploraciÃ³n
â”‚   â”œâ”€â”€ Fase1_equipo24.ipynb
â”‚   â””â”€â”€ NoteBook Testing.ipynb
â”‚   
â”‚   ConvenciÃ³n de nombres: nÃºmero-iniciales-descripciÃ³n
â”‚   Ej: 1.0-hw-exploratory-analysis.ipynb
â”‚
â”œâ”€â”€ reports                <- AnÃ¡lisis generados (HTML, PDF, etc.)
â”‚   â””â”€â”€ figures            <- GrÃ¡ficas y figuras para reportes
â”‚
â”œâ”€â”€ references             <- Diccionarios de datos, manuales, etc.
â”‚
â”œâ”€â”€ requirements.txt       <- Dependencias del proyecto (pip freeze)
â”‚
â”œâ”€â”€ scripts                <- Scripts auxiliares
â”‚   â”œâ”€â”€ train_baseline.py
â”‚   â”œâ”€â”€ validate_plots.py      <- ValidaciÃ³n de mÃ³dulo plots
â”‚   â”œâ”€â”€ validate_features.py   <- ValidaciÃ³n de mÃ³dulo features
â”‚   â””â”€â”€ validate_dataset.py    <- ValidaciÃ³n de mÃ³dulo dataset
â”‚
â”œâ”€â”€ acoustic_ml            <- CÃ³digo fuente del proyecto (mÃ³dulo Python) â­ REFACTORIZADO
â”‚   â”œâ”€â”€ __init__.py        <- Hace de acoustic_ml un mÃ³dulo Python
â”‚   â”œâ”€â”€ config.py          <- ConfiguraciÃ³n y variables globales
â”‚   â”œâ”€â”€ dataset.py         <- GestiÃ³n de datos (650 lÃ­neas, 16 tests) âœ¨ NUEVO
â”‚   â”œâ”€â”€ features.py        <- Feature engineering (930 lÃ­neas, 13 tests) âœ¨ NUEVO
â”‚   â”œâ”€â”€ plots.py           <- Visualizaciones (370 lÃ­neas, 8 tests) âœ¨ NUEVO
â”‚   â””â”€â”€ modeling           <- MÃ³dulos de modelado
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ train.py       <- Entrenamiento de modelos (122 lÃ­neas)
â”‚       â”œâ”€â”€ predict.py     <- Inferencia con modelos (189 lÃ­neas)
â”‚       â”œâ”€â”€ evaluate.py    <- EvaluaciÃ³n de modelos (311 lÃ­neas)
â”‚       â””â”€â”€ pipeline.py    <- Pipeline completo (370 lÃ­neas)
â”‚
â”œâ”€â”€ metrics                <- MÃ©tricas del pipeline DVC
â”‚   â””â”€â”€ metrics.json
â”‚
â”œâ”€â”€ mlruns                 <- Experimentos de MLflow
â”œâ”€â”€ mlartifacts            <- Artifacts de MLflow
â”œâ”€â”€ dvcstore               <- Almacenamiento local de DVC
â”‚
â”œâ”€â”€ docs                   <- Detailed information for the project
â”œâ”€â”€ .dvc                   <- ConfiguraciÃ³n de DVC
â”œâ”€â”€ dvc.yaml               <- DefiniciÃ³n del pipeline DVC
â”œâ”€â”€ dvc.lock               <- Lock file del pipeline
â”œâ”€â”€ data.dvc               <- Metadatos de tracking (versionado en Git)
â”‚
â”œâ”€â”€ .git                   <- Control de versiones Git
â””â”€â”€ .venv                  <- Entorno virtual de Python
```

---

## ğŸ—ï¸ Arquitectura del CÃ³digo

### ğŸ“Š Resumen Ejecutivo

En la **Fase 2 del proyecto**, realizamos una **refactorizaciÃ³n masiva** del mÃ³dulo `acoustic_ml/` transformÃ¡ndolo de scripts funcionales simples a una **arquitectura MLOps profesional** basada en **OOP** y **SOLID principles**.

**Resultado:**
- **+1,718 lÃ­neas** de cÃ³digo profesional (+740% de crecimiento)
- **15 clases principales** con responsabilidades claras
- **37 tests** comprehensivos (100% passing)
- **100% type hints** y documentaciÃ³n en espaÃ±ol
- **Design patterns** de la industria implementados

---

### MÃ³dulos Refactorizados

#### ğŸ¨ **1. acoustic_ml/plots.py** - Sistema de VisualizaciÃ³n

**TransformaciÃ³n:** 49 â†’ 370 lÃ­neas (+321 lÃ­neas, +655%)

```python
PlotManager
â”œâ”€â”€ GestiÃ³n centralizada de figuras y estilos
â”œâ”€â”€ ConfiguraciÃ³n automÃ¡tica de seaborn
â”œâ”€â”€ MÃ©todo save_figure() robusto con validaciÃ³n
â””â”€â”€ create_subplot_grid() para layouts complejos

BasePlotter (ABC)
â”œâ”€â”€ Clase base abstracta para todos los plotters
â”œâ”€â”€ Interfaz comÃºn estandarizada
â”œâ”€â”€ ValidaciÃ³n de datos automÃ¡tica
â””â”€â”€ PatrÃ³n Template Method

FeatureImportancePlotter
â”œâ”€â”€ Hereda de BasePlotter
â”œâ”€â”€ VisualizaciÃ³n especializada de feature importance
â”œâ”€â”€ PersonalizaciÃ³n completa (colores, tamaÃ±os, top_n)
â””â”€â”€ MÃ©todo plot_and_save() conveniente
```

**CaracterÃ­sticas destacadas:**
- âœ… SOLID principles implementados
- âœ… Python `DeprecationWarnings` oficiales para funciones legacy
- âœ… DocumentaciÃ³n completa con ejemplos
- âœ… **8/8 tests pasados**

**Ejemplo de uso:**
```python
from acoustic_ml.plots import FeatureImportancePlotter

# Crear plotter
plotter = FeatureImportancePlotter(
    importance_values=feature_importances,
    feature_names=feature_names,
    title="Feature Importance - Random Forest"
)

# Generar y guardar visualizaciÃ³n
plotter.plot_and_save("reports/figures/feature_importance.png")
```

---

#### ğŸ”§ **2. acoustic_ml/features.py** - Feature Engineering Pipeline

**TransformaciÃ³n:** 88 â†’ 930 lÃ­neas (+842 lÃ­neas, +956%)

```python
FeatureTransformer (Base abstracta)
â”œâ”€â”€ ValidaciÃ³n automÃ¡tica de datos
â”œâ”€â”€ Logging integrado en todas las operaciones
â”œâ”€â”€ PreservaciÃ³n de formato (DataFrame/array)
â””â”€â”€ get_feature_names_out() para inspecciÃ³n

7 TRANSFORMERS ESPECIALIZADOS:
â”œâ”€â”€ NumericFeatureSelector      â†’ SelecciÃ³n inteligente de columnas numÃ©ricas
â”œâ”€â”€ PowerFeatureTransformer     â†’ Yeo-Johnson / Box-Cox normalization
â”œâ”€â”€ OutlierRemover              â†’ DetecciÃ³n y remociÃ³n IQR
â”œâ”€â”€ FeatureScaler               â†’ Standard / MinMax / Robust scaling
â”œâ”€â”€ CorrelationFilter           â†’ EliminaciÃ³n de multicolinealidad
â”œâ”€â”€ VarianceThresholdSelector   â†’ Filtrado por varianza mÃ­nima
â””â”€â”€ [Todos sklearn-compatible: BaseEstimator + TransformerMixin]

FeaturePipelineBuilder
â”œâ”€â”€ Builder Pattern con fluent interface
â”œâ”€â”€ MÃ©todos encadenables (.add_xxx().build())
â””â”€â”€ ValidaciÃ³n de steps en tiempo de construcciÃ³n

3 FACTORY FUNCTIONS:
â”œâ”€â”€ create_preprocessing_pipeline()      â†’ Pipeline de preprocesamiento
â”œâ”€â”€ create_feature_selection_pipeline()  â†’ Pipeline de selecciÃ³n
â””â”€â”€ create_full_pipeline()              â†’ Pipeline completo end-to-end
```

**CaracterÃ­sticas destacadas:**
- âœ… 100% compatible con scikit-learn pipelines
- âœ… ValidaciÃ³n robusta en todos los transformers
- âœ… Logging comprehensivo de operaciones
- âœ… **13/13 tests pasados**

**Ejemplo de uso:**
```python
from acoustic_ml.features import FeaturePipelineBuilder, create_full_pipeline

# OpciÃ³n 1: Builder Pattern (control granular)
pipeline = (FeaturePipelineBuilder()
    .add_numeric_selector()
    .add_power_transformer(method='yeo-johnson')
    .add_outlier_remover(threshold=1.5)
    .add_scaler(strategy='standard')
    .add_correlation_filter(threshold=0.95)
    .add_variance_selector(threshold=0.01)
    .build())

# OpciÃ³n 2: Factory function (configuraciÃ³n rÃ¡pida)
pipeline = create_full_pipeline(
    scaler_strategy='robust',
    correlation_threshold=0.9,
    variance_threshold=0.01
)

# Usar pipeline
X_transformed = pipeline.fit_transform(X_train)
X_test_transformed = pipeline.transform(X_test)
```

---

#### ğŸ’¾ **3. acoustic_ml/dataset.py** - GestiÃ³n de Datos

**TransformaciÃ³n:** 95 â†’ 650 lÃ­neas (+555 lÃ­neas, +584%)

```python
DatasetConfig
â”œâ”€â”€ ConfiguraciÃ³n centralizada de paths
â”œâ”€â”€ validate_directories() para verificar estructura
â”œâ”€â”€ get_all_available_files() para descubrimiento
â””â”€â”€ get_config_summary() para debugging

SingletonMeta
â”œâ”€â”€ Thread-safe Singleton implementation
â””â”€â”€ Double-checked locking pattern

DatasetValidator (NUEVO)
â”œâ”€â”€ validate_dataframe()           â†’ ValidaciÃ³n de estructura
â”œâ”€â”€ validate_required_columns()    â†’ VerificaciÃ³n de columnas
â”œâ”€â”€ validate_target_variable()     â†’ ValidaciÃ³n de target
â””â”€â”€ validate_train_test_split()    â†’ VerificaciÃ³n de splits

DatasetStatistics (NUEVO)
â”œâ”€â”€ get_summary()                  â†’ Resumen general
â”œâ”€â”€ get_numeric_stats()            â†’ EstadÃ­sticas descriptivas
â”œâ”€â”€ get_correlation_matrix()       â†’ Matriz de correlaciÃ³n
â””â”€â”€ detect_outliers()              â†’ DetecciÃ³n IQR/Z-score

DatasetManager (Singleton thread-safe)
â”œâ”€â”€ Load/Save con validaciÃ³n automÃ¡tica
â”œâ”€â”€ Context managers para operaciones seguras
â”œâ”€â”€ Train/test split management
â”œâ”€â”€ Backup automÃ¡tico en saves
â””â”€â”€ MÃ©todos de anÃ¡lisis integrados
```

**CaracterÃ­sticas destacadas:**
- âœ… SeparaciÃ³n de responsabilidades clara (SRP)
- âœ… ValidaciÃ³n comprehensiva de datos
- âœ… AnÃ¡lisis estadÃ­stico robusto integrado
- âœ… **16/16 tests pasados**

**Ejemplo de uso:**
```python
from acoustic_ml.dataset import DatasetManager

# Obtener instancia Singleton
manager = DatasetManager()

# Cargar datos con validaciÃ³n automÃ¡tica
df = manager.load_data("turkish_music_emotion_cleaned.csv")

# Realizar train/test split
X_train, X_test, y_train, y_test = manager.split_data(
    test_size=0.2,
    random_state=42
)

# Obtener estadÃ­sticas
stats = manager.get_statistics()
print(stats.get_summary())

# Detectar outliers
outliers = stats.detect_outliers(method='iqr')

# Context manager para operaciones seguras
with manager.load_context("processed_data.csv") as df:
    # Procesar datos
    processed_df = preprocess(df)
    # Guardar automÃ¡ticamente al salir del context
```

---

### Design Patterns Implementados

#### ğŸ¯ **SOLID Principles**

| Principio | ImplementaciÃ³n |
|-----------|----------------|
| **S**ingle Responsibility | Cada clase tiene una responsabilidad Ãºnica y bien definida |
| **O**pen/Closed | Extensible por herencia, cerrado a modificaciÃ³n |
| **L**iskov Substitution | Clases derivadas intercambiables con sus bases |
| **I**nterface Segregation | Interfaces mÃ­nimas y especÃ­ficas |
| **D**ependency Inversion | Dependencias de abstracciones, no implementaciones |

#### ğŸ›ï¸ **Design Patterns de la Industria**

| Pattern | DÃ³nde | PropÃ³sito |
|---------|-------|-----------|
| **Singleton** | `DatasetManager` | Ãšnica instancia thread-safe con double-checked locking |
| **Builder** | `FeaturePipelineBuilder` | ConstrucciÃ³n fluida de pipelines complejos |
| **Factory** | `create_*_pipeline()` | CreaciÃ³n estandarizada de pipelines |
| **Template Method** | `BasePlotter`, `FeatureTransformer` | Definir estructura, permitir customizaciÃ³n |
| **Strategy** | MÃºltiples scalers/mÃ©todos | Algoritmos intercambiables en runtime |

#### ğŸ”’ **Best Practices**

- âœ… **Type hints** completos (100% coverage)
- âœ… **Docstrings** en espaÃ±ol con ejemplos
- âœ… **Logging** descriptivo en todas las operaciones
- âœ… **ValidaciÃ³n robusta** de datos y estados
- âœ… **Error handling** profesional con mensajes claros
- âœ… **Context managers** para operaciones seguras
- âœ… **Backward compatibility** con `DeprecationWarnings` oficiales

---

### ğŸ“Š MÃ©tricas de RefactorizaciÃ³n

```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    RESUMEN GLOBAL DE REFACTORIZACIÃ“N
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
LÃ­neas de cÃ³digo:      232 â†’ 1,950 lÃ­neas
Crecimiento:           +1,718 lÃ­neas (+740%)
Clases creadas:        15 clases principales
Tests creados:         37 tests comprehensivos
Tasa de Ã©xito:         100% (37/37 passing)
DocumentaciÃ³n:         100% docstrings en espaÃ±ol
Type hints:            100% coverage
Design patterns:       5 patterns implementados
SOLID principles:      5/5 implementados
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

                     DESGLOSE POR MÃ“DULO
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
plots.py           49 â†’  370 lÃ­neas  (+321, +655%)   8 tests  âœ…
features.py        88 â†’  930 lÃ­neas  (+842, +956%)  13 tests  âœ…
dataset.py         95 â†’  650 lÃ­neas  (+555, +584%)  16 tests  âœ…
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## ğŸš€ GuÃ­a de Uso de MÃ³dulos

### ğŸ“Š Ejemplo Completo: Pipeline End-to-End

```python
"""
Ejemplo completo de uso de los mÃ³dulos refactorizados
para entrenar un modelo de clasificaciÃ³n de emociones.
"""

# 1ï¸âƒ£ GESTIÃ“N DE DATOS
from acoustic_ml.dataset import DatasetManager

# Obtener manager (Singleton)
manager = DatasetManager()

# Cargar datos con validaciÃ³n automÃ¡tica
df = manager.load_data("turkish_music_emotion_cleaned.csv")

# Realizar split
X_train, X_test, y_train, y_test = manager.split_data(
    test_size=0.2,
    random_state=42,
    stratify=True
)

# Obtener estadÃ­sticas
stats = manager.get_statistics()
print("ğŸ“Š Resumen del dataset:")
print(stats.get_summary())

# 2ï¸âƒ£ FEATURE ENGINEERING
from acoustic_ml.features import create_full_pipeline

# Crear pipeline completo
feature_pipeline = create_full_pipeline(
    scaler_strategy='robust',
    correlation_threshold=0.9,
    variance_threshold=0.01
)

# Transformar datos
X_train_transformed = feature_pipeline.fit_transform(X_train)
X_test_transformed = feature_pipeline.transform(X_test)

print(f"âœ¨ Features originales: {X_train.shape[1]}")
print(f"âœ¨ Features despuÃ©s de pipeline: {X_train_transformed.shape[1]}")

# 3ï¸âƒ£ ENTRENAMIENTO
from acoustic_ml.modeling.train import train_model

model = train_model(
    X_train_transformed, 
    y_train,
    model_type='random_forest'
)

# 4ï¸âƒ£ EVALUACIÃ“N
from acoustic_ml.modeling.evaluate import evaluate_model

metrics = evaluate_model(model, X_test_transformed, y_test)
print(f"ğŸ¯ Accuracy: {metrics['accuracy']:.2%}")

# 5ï¸âƒ£ VISUALIZACIÃ“N
from acoustic_ml.plots import FeatureImportancePlotter

# Obtener feature importances
importances = model.feature_importances_
feature_names = feature_pipeline.get_feature_names_out()

# Crear visualizaciÃ³n
plotter = FeatureImportancePlotter(
    importance_values=importances,
    feature_names=feature_names,
    title="Feature Importance - Turkish Music Emotions",
    top_n=15
)

plotter.plot_and_save("reports/figures/feature_importance.png")
print("ğŸ’¾ VisualizaciÃ³n guardada en reports/figures/")
```

### ğŸ”§ Ejemplos EspecÃ­ficos por MÃ³dulo

#### Dataset Management

```python
from acoustic_ml.dataset import DatasetManager, DatasetValidator

manager = DatasetManager()

# Cargar y validar
df = manager.load_data("data.csv")
validator = DatasetValidator()

# Validaciones
is_valid = validator.validate_dataframe(
    df, 
    required_columns=['tempo', 'energy', 'emotion'],
    check_nulls=True
)

# EstadÃ­sticas
stats = manager.get_statistics()
outliers = stats.detect_outliers(method='iqr', threshold=1.5)
print(f"Outliers detectados: {len(outliers)}")

# Context manager para operaciones seguras
with manager.load_context("data.csv") as df:
    df['new_feature'] = df['energy'] * df['tempo']
    # Auto-save al salir
```

#### Feature Engineering Avanzado

```python
from acoustic_ml.features import (
    FeaturePipelineBuilder,
    PowerFeatureTransformer,
    CorrelationFilter
)

# Builder Pattern - Control total
pipeline = (FeaturePipelineBuilder()
    .add_numeric_selector()
    .add_power_transformer(method='yeo-johnson')
    .add_outlier_remover(threshold=1.5)
    .add_scaler(strategy='robust')
    .add_correlation_filter(threshold=0.95)
    .add_variance_selector(threshold=0.01)
    .build())

# Transformar
X_processed = pipeline.fit_transform(X_train)

# Inspeccionar features
print(f"Features finales: {pipeline.get_feature_names_out()}")

# Usar transformers individuales
power_transformer = PowerFeatureTransformer(method='box-cox')
X_normalized = power_transformer.fit_transform(X_positive)

corr_filter = CorrelationFilter(threshold=0.9)
X_uncorrelated = corr_filter.fit_transform(X_normalized)
```

#### Visualizaciones Profesionales

```python
from acoustic_ml.plots import PlotManager, FeatureImportancePlotter

# Manager centralizado
plot_manager = PlotManager(style='whitegrid', context='notebook')

# Crear mÃºltiples figuras con layout
fig, axes = plot_manager.create_subplot_grid(2, 2, figsize=(12, 10))

# Feature importance plotter
importance_plotter = FeatureImportancePlotter(
    importance_values=importances,
    feature_names=features,
    title="Top 20 Features",
    top_n=20,
    color='viridis'
)

# Generar en un subplot especÃ­fico
importance_plotter.plot(ax=axes[0, 0])

# Guardar con alta calidad
plot_manager.save_figure(
    fig,
    "reports/figures/analysis.png",
    dpi=300,
    bbox_inches='tight'
)
```

---

## ğŸ§ª Testing y ValidaciÃ³n

### ğŸ“ Scripts de ValidaciÃ³n

Creamos **3 scripts comprehensivos** para validar cada mÃ³dulo refactorizado:

```bash
scripts/
â”œâ”€â”€ validate_plots.py       # 8 tests para plots.py
â”œâ”€â”€ validate_features.py    # 13 tests para features.py
â””â”€â”€ validate_dataset.py     # 16 tests para dataset.py
```

### â–¶ï¸ Ejecutar Tests

```bash
# Ejecutar todos los tests
python scripts/validate_plots.py
python scripts/validate_features.py
python scripts/validate_dataset.py

# O ejecutar todos de una vez
for script in scripts/validate_*.py; do
    echo "Ejecutando: $script"
    python "$script"
done
```

### âœ… Cobertura de Testing

| MÃ³dulo | Tests | Status | Cobertura |
|--------|-------|--------|-----------|
| `plots.py` | 8 | âœ… 8/8 passing | Completa |
| `features.py` | 13 | âœ… 13/13 passing | Completa |
| `dataset.py` | 16 | âœ… 16/16 passing | Completa |
| **TOTAL** | **37** | **âœ… 37/37 passing** | **100%** |

### ğŸ” QuÃ© Validan los Tests

**validate_plots.py:**
- âœ… Imports correctos
- âœ… PlotManager functionality
- âœ… Plotters especializados
- âœ… Save/load de figuras
- âœ… Funciones legacy con DeprecationWarnings

**validate_features.py:**
- âœ… Todos los transformers individuales
- âœ… Builder pattern functionality
- âœ… Factory functions
- âœ… Compatibilidad DataFrame/array
- âœ… Error handling robusto
- âœ… get_feature_names_out()

**validate_dataset.py:**
- âœ… Singleton behavior thread-safe
- âœ… ValidaciÃ³n comprehensiva de datos
- âœ… EstadÃ­sticas descriptivas
- âœ… Save/load operations
- âœ… Train/test split validation
- âœ… Context managers
- âœ… DetecciÃ³n de outliers

### ğŸ“Š Ejemplo de Output de Tests

```bash
$ python scripts/validate_features.py

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ§ª VALIDACIÃ“N DEL MÃ“DULO acoustic_ml/features.py
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Test 1/13: ValidaciÃ³n de imports...                     âœ… PASADO
Test 2/13: NumericFeatureSelector...                    âœ… PASADO
Test 3/13: PowerFeatureTransformer...                   âœ… PASADO
Test 4/13: OutlierRemover...                            âœ… PASADO
Test 5/13: FeatureScaler...                             âœ… PASADO
Test 6/13: CorrelationFilter...                         âœ… PASADO
Test 7/13: VarianceThresholdSelector...                 âœ… PASADO
Test 8/13: FeaturePipelineBuilder...                    âœ… PASADO
Test 9/13: create_preprocessing_pipeline...             âœ… PASADO
Test 10/13: create_feature_selection_pipeline...        âœ… PASADO
Test 11/13: create_full_pipeline...                     âœ… PASADO
Test 12/13: Compatibilidad DataFrame/array...           âœ… PASADO
Test 13/13: Error handling...                           âœ… PASADO

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… RESULTADO: 13/13 tests pasados (100.0%)
âœ¨ MÃ³dulo features.py: PRODUCCIÃ“N READY
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## ğŸ“Š Datasets Disponibles

### Turkish Music Emotion Dataset

Contamos con **4 versiones versionadas con DVC** del dataset de emociones musicales turcas. Cada versiÃ³n representa una etapa evolutiva en nuestro proceso de limpieza y preparaciÃ³n de datos:

---

#### ğŸ”µ VersiÃ³n 0: Limpieza Inicial (turkish_music_emotion_cleaned.csv)

```
ğŸ“ UbicaciÃ³n: data/interim/turkish_music_emotion_cleaned.csv
ğŸ“ Dimensiones: Variable
ğŸ¯ Uso: VersiÃ³n intermedia del primer notebook de limpieza
ğŸ”– Estado: HistÃ³rico (desarrollo temprano)
```

**CaracterÃ­sticas:**
- Primera iteraciÃ³n de limpieza de datos
- Producto del notebook inicial de exploraciÃ³n
- Base para las versiones posteriores mÃ¡s refinadas
- Contiene limpieza bÃ¡sica sin optimizaciones avanzadas

**CuÃ¡ndo usar:**
- ğŸ“š Referencia histÃ³rica del proceso de limpieza
- ğŸ” AuditorÃ­a de evoluciÃ³n del pipeline
- âŒ NO recomendado para entrenar modelos
- âŒ NO recomendado para anÃ¡lisis de producciÃ³n

---


### ğŸ”„ Flujo Evolutivo de Datos

```
ğŸ“¥ Datos Raw (original)
    â†“
ğŸ”§ acoustic_features.csv
    â†“ (Primera limpieza - notebook inicial)
ğŸ“¦ turkish_music_emotion_cleaned.csv (400 filas)
    â†“ (Dataset para entrenamiento)
ğŸ”„ X_train.csv 
ğŸ”„ Y_train.csv 
    â†“ (Dataset para pruebas)
â­ X_test.csv 
â­ Y_test.csv 
    â†“ (Limpieza completa - optimizaciÃ³n para ML)
ğŸ¤– Modelos de ProducciÃ³n
```

---

### ğŸ“ RecomendaciÃ³n del Equipo

> **Para nuevos experimentos y modelos:** Usa **turkish_music_emotion_cleaned**  
> Esta versiÃ³n representa nuestro mejor trabajo de ingenierÃ­a de datos y maximiza tanto la cantidad como la calidad de informaciÃ³n disponible para tus modelos.

**Flujo de trabajo recomendado:**

```python
# 1ï¸âƒ£ Carga la versiÃ³n recomendada usando DatasetManager
from acoustic_ml.dataset import DatasetManager

manager = DatasetManager()
df = manager.load_data("turkish_music_emotion_cleaned.csv")

# 2ï¸âƒ£ Split automÃ¡tico con validaciÃ³n
X_train, X_test, y_train, y_test = manager.split_data(
    test_size=0.2,
    random_state=42,
    stratify=True
)

# 3ï¸âƒ£ Feature engineering con pipeline
from acoustic_ml.features import create_full_pipeline

pipeline = create_full_pipeline()
X_train_transformed = pipeline.fit_transform(X_train)
X_test_transformed = pipeline.transform(X_test)

# 4ï¸âƒ£ Entrena tu modelo
from acoustic_ml.modeling.train import train_model
model = train_model(X_train_transformed, y_train)

# 5ï¸âƒ£ EvalÃºa resultados
from acoustic_ml.modeling.evaluate import evaluate_model
metrics = evaluate_model(model, X_test_transformed, y_test)

# 6ï¸âƒ£ Visualiza feature importance
from acoustic_ml.plots import FeatureImportancePlotter

plotter = FeatureImportancePlotter(
    importance_values=model.feature_importances_,
    feature_names=pipeline.get_feature_names_out()
)
plotter.plot_and_save("reports/figures/importance.png")
```

---


### ğŸ“¦ GestiÃ³n de Versiones con DVC

Todas las versiones estÃ¡n trackeadas con DVC y disponibles en S3:

```bash
# Descargar todas las versiones desde S3
dvc pull data

# Verificar versiones disponibles localmente
ls -lh data

# Output esperado:
# data/external
# data/interim/"X_train.csv"
# data/interim/"Y_train.csv"
# data/processed/"X_test.csv"
# data/processed/"Y_test.csv"
```

---

### ğŸš¨ Advertencias Importantes

âš ï¸ **NO mezcles versiones en el mismo experimento**
```python
# âŒ MAL: Entrenar con una versiÃ³n y evaluar con otra
model.fit(X_train_v2a, y_train_v2a)
score = model.score(X_test_v3, y_test_v3)  # Â¡Datos incompatibles!

# âœ… BIEN: Usa DatasetManager para consistencia
manager = DatasetManager()
X_train, X_test, y_train, y_test = manager.split_data()
model.fit(X_train, y_train)
score = model.score(X_test, y_test)
```

âš ï¸ **Documenta la versiÃ³n en tus experimentos MLflow**
```python
import mlflow

mlflow.set_tag("dataset_version", "turkish_music_emotion_cleaned")
mlflow.set_tag("feature_pipeline", "create_full_pipeline")
mlflow.set_tag("preprocessing", "robust_scaler+correlation_filter")
```

---

## ğŸ”§ Requisitos Previos

- Python 3.12 o superior
- Git y DVC instalados
- Acceso a AWS S3 (credenciales configuradas)
- pip y virtualenv

---

## ğŸ“¦ InstalaciÃ³n

### 1. Clonar el repositorio

```bash
git clone https://github.com/jrebull/MLOps_Team24.git
cd MLOps_Team24
```

### 2. Crear y activar entorno virtual

```bash
python -m venv .venv

# En Linux/Mac:
source .venv/bin/activate

# En Windows:
.venv\Scripts\activate
```

### 3. Instalar dependencias

```bash
pip install -r requirements.txt

# Instalar acoustic_ml en modo desarrollo
pip install -e .
```

### 4. Configurar DVC

```bash
# Verificar configuraciÃ³n de remote
dvc remote list

# DeberÃ­a mostrar:
# mlops-s3-remote	s3://mlops24-haowei-bucket/dvcstore
```

### 5. Descargar datos desde S3

```bash
dvc pull
```

### 6. Verificar instalaciÃ³n

```bash
# Ejecutar tests de validaciÃ³n
python scripts/validate_plots.py
python scripts/validate_features.py
python scripts/validate_dataset.py

# Todos deberÃ­an mostrar: âœ… XX/XX tests pasados
```

---

## â˜ï¸ GestiÃ³n de Datos (DVC + S3)

### Comandos esenciales

```bash
# Descargar datos desde S3
dvc pull

# Subir datos a S3
dvc push

# Ver estado de sincronizaciÃ³n
dvc status

# Agregar nuevos datos al tracking
dvc add data/new_file.csv
git add data/new_file.csv.dvc data/.gitignore
```

### Verificar archivos locales

```bash
# Listar archivos en data/
ls -lh data/processed/
```


### ğŸ“‹ Comandos de referencia rÃ¡pida

```bash
# Descargar datos desde S3
dvc pull          # Usando DVC
make pull         # Usando Makefile

# Subir datos a S3
dvc push          # Usando DVC
make push         # Usando Makefile

# Ver estado de sincronizaciÃ³n
dvc status        # Estado actual
make status       # Usando Makefile

# Verificar configuraciÃ³n
dvc remote list   # Lista remotes configurados
dvc config --list # ConfiguraciÃ³n completa de DVC
```

---


## âœ… VerificaciÃ³n RÃ¡pida antes de Trabajar

Usa el `Makefile` para confirmar que tu repo estÃ¡ **limpio**, **sincronizado** y listo:

```bash
make verify-sync
```

**QuÃ© valida:**
- âœ” Ãrbol de trabajo limpio (sin cambios sin commit)
- âœ” HEAD == origin/<rama> (sin ahead/behind)
- âœ” Datos sincronizados con S3

---

## ğŸ”„ Reproducibilidad de Entornos

Exporta dependencias despuÃ©s de instalar paquetes nuevos:

```bash
make freeze
# luego:
git add requirements.txt
git commit -m "chore: update dependencies"
git push
```

ReconstrucciÃ³n rÃ¡pida en cualquier mÃ¡quina:

```bash
python -m venv .venv
source .venv/bin/activate   # Windows: .venv\Scripts\activate
pip install -r requirements.txt
pip install -e .  # Instalar mÃ³dulo acoustic_ml
```

---

## ğŸ³ Docker Compose

```
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ config.env
â”œâ”€â”€ mlartifacts/           # Almacena los artefactos de MLflow 
â”œâ”€â”€ ml_pipeline.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ acoustic_ml/           # MÃ³dulo del proyecto
â””â”€â”€ .venv/                 # Entorno virtual local
```

### âš™ï¸ Archivos requeridos
âœ… config.env

### âš™ï¸ Comandos de uso

**ğŸ”§ Levantar servicios**

```bash
docker-compose --env-file config.env up -d --build
```

MinIO (Consola): http://localhost:9001

**ğŸ›‘ Detener los servicios**
```bash
docker-compose down
```

**ğŸ”„ Reiniciar**
```bash
docker-compose --env-file config.env up -d --build
```

---

## ğŸ§¹ Limpieza Local

Si necesitas borrar cachÃ©s locales (sin afectar Git):

```bash
make clean-caches
```

Limpieza completa (incluye artefactos de MLflow/DVC):
```bash
make clean
```

---

## ğŸ— Arquitectura del Pipeline

```mermaid
flowchart TD
    A[ğŸ“‚ data/raw/*.csv] -->|limpieza inicial| B[ğŸ”µ turkish_music_emotion_cleaned.csv]
    B -->|formalizaciÃ³n| C[ğŸ“¦ v1_original.csv - 400 filas]
    C -->|limpieza alineada| D[ğŸ”„ v2_cleaned_aligned.csv - 400 filas]
    C -->|limpieza completa| E[â­ v2_cleaned_full.csv - 408 filas]
    
    E -->|DVC tracking| F[â˜ï¸ AWS S3]
    E -->|DatasetManager| G[ğŸ”§ acoustic_ml/dataset.py]
    G -->|feature engineering| H[âš™ï¸ acoustic_ml/features.py]
    H -->|entrenamiento| I[ğŸ¤– acoustic_ml/modeling/train.py]
    I --> J[ğŸ’¾ models/baseline_model.pkl]
    I --> K[ğŸ“ˆ metrics/metrics.json]
    J -->|log_model| L[MLflow Tracking]
    K -->|log_metrics| L
    L --> M[ğŸ–¥ MLflow UI :5001]
    
    style E fill:#90EE90,stroke:#228B22,stroke-width:3px
    style A fill:#e1f5ff
    style F fill:#fff4e1
    style J fill:#e8f5e9
    style M fill:#f3e5f5
    style G fill:#ffe4e1
    style H fill:#e6f3ff
```

**Flujo de trabajo refactorizado:**

1. ğŸ“¥ Datos crudos en `data/raw/` (versionados con DVC)
2. ğŸ”§ Primera limpieza â†’ `turkish_music_emotion_cleaned.csv` (histÃ³rico)
3. ğŸ“¦ FormalizaciÃ³n â†’ `v1_original.csv` (400 filas, baseline)
4. ğŸ”„ Limpieza alineada â†’ `v2_cleaned_aligned.csv` (400 filas, comparaciÃ³n)
5. â­ Limpieza completa â†’ `v2_cleaned_full.csv` (408 filas, **PRODUCCIÃ“N**)
6. â˜ï¸ Almacenamiento en S3 para colaboraciÃ³n
7. ğŸ”§ **NUEVO:** `DatasetManager` (Singleton thread-safe) gestiona carga/validaciÃ³n
8. âš™ï¸ **NUEVO:** `FeaturePipeline` transforma datos con 7 transformers especializados
9. ğŸ¤– `acoustic_ml/modeling/train.py` entrena modelos con datos procesados
10. ğŸ’¾ Modelos entrenados se guardan en `models/`
11. ğŸ“ˆ Experimentos y artefactos se registran en MLflow
12. ğŸ“Š MÃ©tricas se trackean con DVC
13. âœ… Todo es reproducible, versionado y testado (37 tests)

---

## ğŸ¤ ContribuciÃ³n

### Flujo de trabajo

1. **Verificar sincronizaciÃ³n:**
   ```bash
   make verify-sync
   ```

2. **Crear una nueva rama:**
   ```bash
   git checkout -b feat/nombre-descriptivo
   ```

3. **Realizar cambios:**
   
   **Si modificas cÃ³digo Python:**
   ```bash
   # Edita archivos en acoustic_ml/
   vim acoustic_ml/features.py
   
   # Los cambios estÃ¡n disponibles inmediatamente (instalaciÃ³n en modo -e)
   
   # Ejecutar tests relevantes
   python scripts/validate_features.py
   ```

   **Si modificas datos:**
   ```bash
   dvc add data
   git add data.dvc data/.gitignore
   dvc push
   ```

   **Si instalaste paquetes:**
   ```bash
   make freeze
   git add requirements.txt
   ```

4. **Commitear cambios:**
   ```bash
   git add .
   git commit -m "feat: descripciÃ³n clara del cambio"
   ```

5. **Subir cambios:**
   ```bash
   git push origin feat/nombre-descriptivo
   dvc push  # o: make push
   ```

6. **Crear Pull Request** a la rama `main`

### Buenas prÃ¡cticas

- âœ… Ejecuta `make verify-sync` antes de comenzar a trabajar
- âœ… **SIEMPRE usa `DatasetManager` para gestionar datos**
- âœ… **Usa `FeaturePipelineBuilder` o factory functions para feature engineering**
- âœ… **Ejecuta tests de validaciÃ³n antes de commit** (`validate_*.py`)
- âœ… Documenta la versiÃ³n de dataset en MLflow tags
- âœ… Ejecuta `dvc status` para verificar estado de datos
- âœ… Ejecuta `make reproduce` antes de hacer commit
- âœ… Documenta tus experimentos en MLflow
- âœ… Escribe mensajes de commit descriptivos ([Conventional Commits](https://www.conventionalcommits.org/))
- âœ… MantÃ©n el cÃ³digo limpio y con docstrings
- âœ… Usa `make nb-hooks` para configurar hooks de notebooks
- âœ… Escribe cÃ³digo en el mÃ³dulo `acoustic_ml/`, no en notebooks
- âœ… Siempre haz `dvc push` despuÃ©s de modificar datos
- âœ… **MantÃ©n los tests actualizados** cuando agregues funcionalidades

---

## ğŸ‘¥ **Equipo de Desarrollo**

<div align="center">

<table style="width:100%; border:none;">
  <tr>
    <td align="center" style="border:none; padding:20px 10px;">
      <img src="https://iili.io/Kw90kmB.png" alt="David Cruz BeltrÃ¡n" width="160" style="border-radius: 50%; border: 5px solid #667eea; box-shadow: 0 8px 16px rgba(102, 126, 234, 0.4);"/>
      <h3>David Cruz BeltrÃ¡n</h3>
      <img src="https://img.shields.io/badge/ID-A01360416-667eea?style=for-the-badge" alt="MatrÃ­cula"/>
      <p><strong>ğŸ”§ Software Engineer</strong><br/>
      <em>Data Pipeline & Versioning</em></p>
    </td>
    <td align="center" style="border:none; padding:20px 10px;">
      <img src="https://iili.io/KuvsGKx.png" alt="Javier Augusto Rebull Saucedo" width="160" style="border-radius: 50%; border: 5px solid #764ba2; box-shadow: 0 8px 16px rgba(118, 75, 162, 0.4);"/>
      <h3>Javier Augusto Rebull Saucedo</h3>
      <img src="https://img.shields.io/badge/ID-A01795838-764ba2?style=for-the-badge" alt="MatrÃ­cula"/>
      <p><strong>âš™ï¸ SRE / Data Engineer</strong><br/>
      <em>DevOps & Infrastructure</em></p>
    </td>
    <td align="center" style="border:none; padding:20px 10px;">
      <img src="https://iili.io/Kw91d74.png" alt="Sandra Luz Cervantes Espinoza" width="160" style="border-radius: 50%; border: 5px solid #f093fb; box-shadow: 0 8px 16px rgba(240, 147, 251, 0.4);"/>
      <h3>Sandra Luz Cervantes Espinoza</h3>
      <img src="https://img.shields.io/badge/ID-A01796937-f093fb?style=for-the-badge" alt="MatrÃ­cula"/>
      <p><strong>ğŸ¤– ML Engineer / Data Scientist</strong><br/>
      <em>Model Development & Analysis</em></p>
    </td>
  </tr>
</table>

</div>

---

<div align="center">

**â­ Si este proyecto te resulta Ãºtil, considera darle una estrella**

Desarrollado con â¤ï¸ por el Equipo 24 | Estructura basada en [Cookiecutter Data Science](https://drivendata.github.io/cookiecutter-data-science/)

**ğŸ—ï¸ Refactorizado con SOLID Principles & Design Patterns** | **ğŸ§ª 100% Tested (37/37 passing)**

</div>
