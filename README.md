# ğŸµ Acoustic ML - Turkish Music Emotion Recognition

<div align="center">

**MLOps Team 24 - Sistema profesional de reconocimiento de emociones musicales**

[![Python](https://img.shields.io/badge/Python-3.12+-blue.svg)](https://www.python.org/downloads/)
[![MLflow](https://img.shields.io/badge/MLflow-Tracking-0194E2?logo=mlflow)](https://mlflow.org/)
[![DVC](https://img.shields.io/badge/DVC-Data%20Versioning-945DD6?logo=dvc)](https://dvc.org/)
[![AWS S3](https://img.shields.io/badge/AWS-S3-FF9900?logo=amazon-aws)](https://aws.amazon.com/s3/)
[![Streamlit](https://img.shields.io/badge/Streamlit-Dashboard-FF4B4B?logo=streamlit)](https://mlopsteam24-cookiecutter.streamlit.app)

<!-- Badges de Estado -->
[![Cookiecutter](https://img.shields.io/badge/cookiecutter-95.2%25-success?logo=cookiecutter&logoColor=white)](#-estructura-del-proyecto)
[![Tests](https://img.shields.io/badge/tests-33%20passing-success?logo=pytest&logoColor=white)](#-testing-unitarias-e-integraciÃ³n)
[![Code Quality](https://img.shields.io/badge/code-production--ready-brightgreen?logo=python&logoColor=white)](#-arquitectura-del-cÃ³digo)
[![Accuracy](https://img.shields.io/badge/accuracy-80.17%25-success?logo=tensorflow&logoColor=white)](#-modelo-y-resultados)
[![Docker](https://img.shields.io/badge/docker--ready-blue?logo=docker&logoColor=white)](#-docker--containerizaciÃ³n)
[![Repo Status](https://img.shields.io/badge/repo-phase%203%20production-blue?logo=git&logoColor=white)](#-informaciÃ³n-acadÃ©mica)

</div>

---

## ğŸ“‹ Tabla de Contenidos

- [Sobre el Proyecto](#-sobre-el-proyecto)
- [InformaciÃ³n AcadÃ©mica](#-informaciÃ³n-acadÃ©mica)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [Arquitectura del CÃ³digo](#-arquitectura-del-cÃ³digo)
- [Modelo y Resultados](#-modelo-y-resultados)
- [MLOps Infrastructure](#-mlops-infrastructure)
- [InstalaciÃ³n y ConfiguraciÃ³n](#-instalaciÃ³n-y-configuraciÃ³n)
- [Uso del Sistema](#-uso-del-sistema)
- [Scripts Disponibles](#-scripts-disponibles)
- [Testing & Quality Assurance](#-testing--quality-assurance)
- [API Serving with FastAPI](#-api-serving-with-fastapi)
- [Data Drift Detection & Monitoring](#-data-drift-detection--monitoring)
- [Docker & Containerization](#-docker--containerization)
- [Reproducibility & Seeds](#-reproducibility--seeds)
- [Phase 3 Requirements Checklist](#-phase-3-requirements-checklist)
- [Project Structure](#-project-structure)
- [Streamlit App - Production Demo](#-streamlit-app---production-demo)
- [Monitoring y ValidaciÃ³n](#-monitoring-y-validaciÃ³n)
- [Workflows y ContribuciÃ³n](#-workflows-y-contribuciÃ³n)
- [Equipo](#-equipo-de-desarrollo)

---

## ğŸ¯ Sobre el Proyecto

Este repositorio implementa un sistema MLOps completo y profesional para **clasificaciÃ³n de emociones en mÃºsica turca**, siguiendo las mejores prÃ¡cticas de la industria con estructura **Cookiecutter Data Science** (95.2% de cumplimiento verificado).

### ğŸµ Dataset y Objetivo

- **Dataset:** Turkish Music Emotion Dataset
- **Clases:** 4 emociones (Happy, Sad, Angry, Relax)
- **Features:** 50+ caracterÃ­sticas acÃºsticas extraÃ­das
- **Objetivo:** ClasificaciÃ³n automÃ¡tica de emociones musicales
- **Modelo Actual:** Random Forest optimizado con 80.17% accuracy

### ğŸš€ CaracterÃ­sticas Principales

#### MLOps Foundation
- ğŸ“Š **Versionado de datos** con DVC + AWS S3
- ğŸ”„ **Pipelines reproducibles** automatizados
- ğŸ“ˆ **Experiment tracking** con MLflow
- â˜ï¸ **Cloud storage** en S3 (mlops24-haowei-bucket)
- ğŸ³ **ContainerizaciÃ³n** con Docker Compose

#### Code y Arquitectura
- ğŸ—ï¸ **MÃ³dulo Python profesional** (`acoustic_ml`)
- ğŸ¯ **Pipeline sklearn end-to-end** listo para producciÃ³n
- ğŸ§ª **Testing comprehensivo** con 33 tests automatizados
- ğŸ›¡ï¸ **Manejo robusto de outliers** y datos
- ğŸŒ **API REST** con FastAPI y Pydantic schemas

#### Fase 3: Production-Ready Deployment
- ğŸ³ **ContainerizaciÃ³n Docker** con docker-compose
- ğŸ” **Data Drift Detection** con statistical monitoring
- ğŸ“¡ **CI/CD Pipelines** automatizados
- âš™ï¸ **Health Checks** y monitoring endpoints
- ğŸ”„ **Reproducibilidad garantizada** con seeds y DVC

#### Monitoring y ValidaciÃ³n
- ğŸ“Š **Dashboard Streamlit** para validaciÃ³n Cookiecutter
- ğŸ” **ValidaciÃ³n automatizada** de entornos y datos
- ğŸ“ˆ **7 experimentos MLflow** documentados
- âœ… **VerificaciÃ³n de sincronizaciÃ³n** DVC + Git + S3

---

## ğŸ“˜ InformaciÃ³n AcadÃ©mica

**Instituto TecnolÃ³gico y de Estudios Superiores de Monterrey**  
*MaestrÃ­a en Inteligencia Artificial Aplicada (MNA)*

- **Curso:** Operaciones de Aprendizaje AutomÃ¡tico
- **Periodo:** Septiembre â€“ Diciembre 2024
- **Equipo:** NÂ° 24
- **Fase Actual:** Fase 3 - ImplementaciÃ³n en ProducciÃ³n ğŸš€

### ğŸ‘¨â€ğŸ« Profesores

| Rol | Nombre |
|-----|--------|
| Titular | Dr. Gerardo RodrÃ­guez HernÃ¡ndez |
| Titular | Mtro. Ricardo Valdez HernÃ¡ndez |
| Asistente | Mtra. MarÃ­a Mylen TreviÃ±o Elizondo |
| Tutor | JosÃ© Ãngel MartÃ­nez Navarro |

---

## ğŸ—‚ï¸ Estructura del Proyecto

OrganizaciÃ³n completa siguiendo **Cookiecutter Data Science** con 95.2% de cumplimiento verificado:

```
MLOps_Team24/
â”‚
â”œâ”€â”€ ğŸ“„ ConfiguraciÃ³n (RaÃ­z)
â”‚   â”œâ”€â”€ README.md              <- Este archivo â­
â”‚   â”œâ”€â”€ Makefile               <- Comandos make (data, train, reproduce, etc.)
â”‚   â”œâ”€â”€ MakefileGitOK          <- Makefile alternativo
â”‚   â”œâ”€â”€ pyproject.toml         <- ConfiguraciÃ³n proyecto Python
â”‚   â”œâ”€â”€ requirements.txt       <- Dependencias producciÃ³n (pip freeze)
â”‚   â”œâ”€â”€ params.yaml            <- ParÃ¡metros pipeline DVC
â”‚   â”œâ”€â”€ dvc.yaml               <- DefiniciÃ³n pipeline DVC
â”‚   â”œâ”€â”€ dvc.lock               <- Lock file pipeline
â”‚   â”œâ”€â”€ data.dvc               <- Tracking metadatos datos
â”‚   â”œâ”€â”€ docker-compose.yml     <- Stack MLflow + MinIO
â”‚   â””â”€â”€ config.env             <- Variables entorno Docker
â”‚
â”œâ”€â”€ ğŸ“¦ acoustic_ml/            <- MÃ³dulo Python principal â­
â”‚   â”œâ”€â”€ __init__.py            
â”‚   â”œâ”€â”€ config.py              <- ConfiguraciÃ³n global del sistema
â”‚   â”œâ”€â”€ dataset.py             <- DatasetManager (Singleton, thread-safe)
â”‚   â”œâ”€â”€ features.py            <- Feature engineering & transformers
â”‚   â”œâ”€â”€ plots.py               <- Visualizaciones y grÃ¡ficas
â”‚   â”œâ”€â”€ archive/               <- CÃ³digo legacy versionado
â”‚   â”‚   â”œâ”€â”€ dataset_legacy.py
â”‚   â”‚   â””â”€â”€ features_legacy.py
â”‚   â””â”€â”€ modeling/              <- SubmÃ³dulo de modelado
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ train.py           <- Training logic
â”‚       â”œâ”€â”€ predict.py         <- Inference
â”‚       â”œâ”€â”€ evaluate.py        <- Evaluation metrics
â”‚       â”œâ”€â”€ pipeline.py        <- MLOps pipeline completo
â”‚       â”œâ”€â”€ sklearn_pipeline.py <- Pipeline sklearn production-ready
â”‚       â””â”€â”€ *.backup           <- Backups de versiones previas
â”‚
â”œâ”€â”€ ğŸŒ app/                    <- API REST (FastAPI)
â”‚   â”œâ”€â”€ main.py                <- Entry point aplicaciÃ³n
â”‚   â”œâ”€â”€ api/                   
â”‚   â”‚   â”œâ”€â”€ main.py            <- Router principal
â”‚   â”‚   â”œâ”€â”€ endpoints.py       <- Endpoints API
â”‚   â”‚   â””â”€â”€ schemas.py         <- Pydantic schemas
â”‚   â”œâ”€â”€ core/                  
â”‚   â”‚   â”œâ”€â”€ config.py          <- ConfiguraciÃ³n API
â”‚   â”‚   â””â”€â”€ logger.py          <- Logging setup
â”‚   â””â”€â”€ services/              
â”‚       â””â”€â”€ model_service.py   <- Servicio de modelo
â”‚
â”œâ”€â”€ ğŸ“Š data/                   <- Datos (versionados con DVC)
â”‚   â”œâ”€â”€ external/              <- Fuentes externas
â”‚   â”œâ”€â”€ interim/               <- Transformaciones intermedias
â”‚   â”œâ”€â”€ processed/             <- Datasets finales â­
â”‚   â”‚   â”œâ”€â”€ turkish_music_emotion_v1_original.csv      (400 filas - Baseline)
â”‚   â”‚   â”œâ”€â”€ turkish_music_emotion_v2_cleaned_aligned.csv (400 filas)
â”‚   â”‚   â”œâ”€â”€ turkish_music_emotion_v2_cleaned_full.csv    (408 filas) â­ PRODUCCIÃ“N
â”‚   â”‚   â”œâ”€â”€ turkish_music_emotion_v2_transformed.csv
â”‚   â”‚   â”œâ”€â”€ eda_report.txt
â”‚   â”‚   â”œâ”€â”€ split_metadata.json
â”‚   â”‚   â”œâ”€â”€ X_train.csv, X_test.csv
â”‚   â”‚   â””â”€â”€ y_train.csv, y_test.csv
â”‚   â””â”€â”€ raw/                   <- Datos originales inmutables
â”‚       â”œâ”€â”€ turkis_music_emotion_original.csv     (125 KB)
â”‚       â””â”€â”€ turkish_music_emotion_modified.csv    (130 KB)
â”‚
â”œâ”€â”€ ğŸ’¾ models/                 <- Modelos serializados
â”‚   â”œâ”€â”€ baseline/              
â”‚   â”‚   â”œâ”€â”€ random_forest_baseline.pkl
â”‚   â”‚   â”œâ”€â”€ gradient_boosting_baseline.pkl
â”‚   â”‚   â””â”€â”€ xgboost_baseline.pkl
â”‚   â”œâ”€â”€ optimized/             <- Modelos optimizados â­
â”‚   â”‚   â”œâ”€â”€ production_model.pkl              (Modelo actual 80.17%)
â”‚   â”‚   â”œâ”€â”€ production_model_metadata.json
â”‚   â”‚   â”œâ”€â”€ best_model_*.pkl                  (Versiones fechadas)
â”‚   â”‚   â””â”€â”€ model_metadata_*.json
â”‚   â”œâ”€â”€ baseline.dvc           <- Tracking baseline models
â”‚   â”œâ”€â”€ optimized.dvc          <- Tracking optimized models
â”‚   â”œâ”€â”€ baseline_model.pkl     
â”‚   â””â”€â”€ test_model.pkl         
â”‚
â”œâ”€â”€ ğŸ“ˆ mlflow_artifacts/       <- Experimentos MLflow
â”‚   â”œâ”€â”€ exp_01_Random_Forest_Current_Best/
â”‚   â”œâ”€â”€ exp_02_Random_Forest_Deep/
â”‚   â”œâ”€â”€ exp_03_Random_Forest_Simple/
â”‚   â”œâ”€â”€ exp_04_Gradient_Boosting/
â”‚   â”œâ”€â”€ exp_05_Gradient_Boosting_Conservative/
â”‚   â”œâ”€â”€ exp_06_Logistic_Regression_Baseline/
â”‚   â”œâ”€â”€ exp_07_SVM_RBF/
â”‚   â”œâ”€â”€ experiments_summary.csv
â”‚   â”œâ”€â”€ experiments_report.txt
â”‚   â””â”€â”€ experiment_run_*.log
â”‚
â”œâ”€â”€ ğŸ““ notebooks/              <- Jupyter notebooks
â”‚   â”œâ”€â”€ 1.0-team-eda-turkish-music.ipynb       (EDA inicial)
â”‚   â”œâ”€â”€ 1.1-team-dataset-comparison.ipynb      (ComparaciÃ³n datasets)
â”‚   â”œâ”€â”€ 2.0-team-preprocessing.ipynb           (Preprocessing)
â”‚   â”œâ”€â”€ 3.0-team-modeling-evaluation.ipynb     (Modelado)
â”‚   â””â”€â”€ archive/               <- Notebooks legacy
â”‚       â”œâ”€â”€ 0.0-team-testing.ipynb
â”‚       â””â”€â”€ 1.2-team-fase1-final.ipynb
â”‚
â”œâ”€â”€ ğŸ“Š monitoring/             <- Sistema de monitoring
â”‚   â”œâ”€â”€ dashboard/             
â”‚   â”‚   â”œâ”€â”€ streamlit_dashboard.py         â­ Dashboard Cookiecutter
â”‚   â”‚   â”œâ”€â”€ validate_cookiecutter.py       
â”‚   â”‚   â”œâ”€â”€ requirements_dashboard.txt
â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â””â”€â”€ README.md              
â”‚
â”œâ”€â”€ ğŸ“ˆ reports/                <- Reportes y anÃ¡lisis
â”‚   â”œâ”€â”€ figures/               <- Visualizaciones â­
â”‚   â”‚   â”œâ”€â”€ confusion_matrices_top3.png
â”‚   â”‚   â”œâ”€â”€ final_confusion_matrix.png
â”‚   â”‚   â”œâ”€â”€ baseline_comparison.png
â”‚   â”‚   â”œâ”€â”€ roc_curves.png
â”‚   â”‚   â”œâ”€â”€ outlier_analysis.png
â”‚   â”‚   â”œâ”€â”€ outlier_boxplots.png
â”‚   â”‚   â”œâ”€â”€ plot_*.png         (MÃºltiples visualizaciones EDA)
â”‚   â”‚   â”œâ”€â”€ outlier_analysis_report.txt
â”‚   â”‚   â””â”€â”€ scaler_comparison_results.txt
â”‚   â”œâ”€â”€ baseline_model_evaluation/
â”‚   â”‚   â”œâ”€â”€ classification_report.txt
â”‚   â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â”‚   â””â”€â”€ metrics.json
â”‚   â”œâ”€â”€ baseline_results.csv
â”‚   â”œâ”€â”€ hyperparameter_search_results.csv
â”‚   â”œâ”€â”€ final_model_evaluation.json
â”‚   â”œâ”€â”€ modeling_report.txt
â”‚   â”œâ”€â”€ metrics.json
â”‚   â””â”€â”€ turkish_dataset_comparison_report.txt
â”‚
â”œâ”€â”€ ğŸ“š references/             <- DocumentaciÃ³n externa
â”‚   â”œâ”€â”€ Diccionario_Variables_Musica_Turca.xlsx
â”‚   â”œâ”€â”€ Referencias_APA.xlsx
â”‚   â”œâ”€â”€ Team24_Machine Learning Canvas v1.0.pdf
â”‚   â”œâ”€â”€ Fase 1_Equipo24.pdf
â”‚   â”œâ”€â”€ Fase 2_Equipo24.pdf
â”‚   â””â”€â”€ Fase 01 MNA MLOps Team 24 Octubre 2025.mp4
â”‚
â”œâ”€â”€ ğŸ› ï¸ scripts/               <- Scripts organizados por funciÃ³n
â”‚   â”œâ”€â”€ analysis/              <- Scripts de anÃ¡lisis
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ analyze_outliers.py
â”‚   â”‚   â”œâ”€â”€ compare_scalers.py
â”‚   â”‚   â”œâ”€â”€ run_full_analysis.py
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”œâ”€â”€ training/              <- Scripts de entrenamiento
â”‚   â”‚   â”œâ”€â”€ train_baseline.py
â”‚   â”‚   â”œâ”€â”€ run_mlflow_experiments.py     â­ Experimentos MLflow
â”‚   â”‚   â””â”€â”€ run_mlflow_experiments.py.backup
â”‚   â”œâ”€â”€ validation/            <- Scripts de validaciÃ³n
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ verify_sync.py     â­ VerificaciÃ³n DVC+Git+S3
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”œâ”€â”€ pipelines/             
â”‚   â”‚   â””â”€â”€ ml_pipeline.py
â”‚   â”œâ”€â”€ temp/                  <- Scripts temporales (gitignored)
â”‚   â”‚   â”œâ”€â”€ cleanup_*.py
â”‚   â”‚   â”œâ”€â”€ fix_*.py
â”‚   â”‚   â”œâ”€â”€ test_*.py
â”‚   â”‚   â””â”€â”€ update_*.py
â”‚   â””â”€â”€ validate_final.py
â”‚
â”œâ”€â”€ ğŸ§ª tests/                  <- Test suite
â”‚   â”œâ”€â”€ test_dataset_equivalence.py
â”‚   â”œâ”€â”€ test_full_integration.py      â­ Integration tests
â”‚   â”œâ”€â”€ test_ml_pipeline.py
â”‚   â”œâ”€â”€ test_sklearn_pipeline.py
â”‚   â”œâ”€â”€ validate_cookiecutter.py
â”‚   â”œâ”€â”€ validate_dataset.py
â”‚   â”œâ”€â”€ validate_features.py
â”‚   â”œâ”€â”€ validate_plots.py
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ ğŸ“š docs/                   <- DocumentaciÃ³n
â”‚   â”œâ”€â”€ setup_guide.md
â”‚   â”œâ”€â”€ ml_pipeline.md
â”‚   â”œâ”€â”€ api_endpoints.md
â”‚   â”œâ”€â”€ deployment_guide.md
â”‚   â””â”€â”€ references.md
â”‚
â”œâ”€â”€ ğŸ—„ï¸ mlartifacts/           <- MLflow local artifacts
â”œâ”€â”€ ğŸ—„ï¸ dvcstore/              <- DVC local cache
â””â”€â”€ ğŸ“¦ acoustic_ml.egg-info/  <- Package metadata

```

### ğŸ“Š Resumen de Directorios

| Directorio | PropÃ³sito | DVC Tracked | Git Tracked |
|-----------|-----------|-------------|-------------|
| `acoustic_ml/` | MÃ³dulo Python principal | âŒ | âœ… |
| `app/` | API REST FastAPI | âŒ | âœ… |
| `data/` | Datasets (raw, processed) | âœ… | âš ï¸ (.dvc only) |
| `models/` | Modelos serializados | âœ… | âš ï¸ (.dvc only) |
| `notebooks/` | Jupyter notebooks | âŒ | âœ… |
| `scripts/` | Scripts auxiliares | âŒ | âœ… |
| `tests/` | Test suite | âŒ | âœ… |
| `reports/` | Reportes y figuras | âŒ | âœ… |
| `monitoring/` | Dashboard y validaciÃ³n | âŒ | âœ… |
| `mlflow_artifacts/` | Experimentos MLflow | âŒ | âœ… |
| `mlartifacts/` | MLflow local store | âŒ | âŒ |
| `dvcstore/` | DVC local cache | âŒ | âŒ |

---

## ğŸ—ï¸ Arquitectura del CÃ³digo

### MÃ³dulo Principal: `acoustic_ml`

MÃ³dulo Python profesional con arquitectura limpia y bien documentada:

#### **1. `config.py`** - ConfiguraciÃ³n Global
```python
# Paths, constants, logging configuration
PROJECT_ROOT = Path(__file__).parent.parent
DATA_DIR = PROJECT_ROOT / "data"
MODELS_DIR = PROJECT_ROOT / "models"
```

#### **2. `dataset.py`** - GestiÃ³n de Datos
- **`DatasetManager`**: Singleton thread-safe para carga de datos
- **Funciones**: `load_dataset()`, `validate_dataset()`, `get_data_splits()`
- **Testing**: 16+ tests de validaciÃ³n
- **Features**: Caching, validaciÃ³n automÃ¡tica, metadata tracking

#### **3. `features.py`** - Feature Engineering
- **`FeaturePipeline`**: Pipeline de transformaciÃ³n completo
- **Transformers**: `OutlierHandler`, `FeatureScaler`, `FeatureSelector`
- **AnÃ¡lisis**: DetecciÃ³n de outliers, scaling robusto
- **Testing**: 13+ tests comprehensivos

#### **4. `plots.py`** - Visualizaciones
- Confusion matrices, ROC curves, distribution plots
- Outlier analysis visualizations
- Feature importance plots
- **Testing**: 8+ tests de generaciÃ³n de plots

#### **5. `modeling/`** - SubmÃ³dulo de Modelado

```
modeling/
â”œâ”€â”€ train.py           <- LÃ³gica de entrenamiento
â”œâ”€â”€ predict.py         <- Inferencia y predicciones
â”œâ”€â”€ evaluate.py        <- MÃ©tricas y evaluaciÃ³n
â”œâ”€â”€ pipeline.py        <- Pipeline MLOps completo
â””â”€â”€ sklearn_pipeline.py <- Pipeline sklearn production-ready â­
```

**Pipeline Sklearn (Production-Ready)**:
```python
from acoustic_ml.modeling.sklearn_pipeline import create_sklearn_pipeline

# Pipeline completo: preprocessing + modelo
pipeline = create_sklearn_pipeline(model_type='random_forest')

# Compatible con GridSearchCV, cross_val_score
pipeline.fit(X_train, y_train)
predictions = pipeline.predict(X_test)
```

### Design Patterns Implementados

1. **Singleton Pattern**: `DatasetManager` para gestiÃ³n centralizada
2. **Factory Pattern**: CreaciÃ³n de pipelines y modelos
3. **Strategy Pattern**: Diferentes algoritmos de scaling/preprocessing
4. **Pipeline Pattern**: ComposiciÃ³n de transformadores sklearn

### MÃ©tricas de Calidad

- âœ… **Modularidad**: CÃ³digo organizado en mÃ³dulos especializados
- âœ… **Testing**: Suite comprehensiva de tests
- âœ… **DocumentaciÃ³n**: Docstrings completos en todo el cÃ³digo
- âœ… **Type Hints**: Tipado estÃ¡tico en funciones crÃ­ticas
- âœ… **SOLID Principles**: Arquitectura limpia y extensible
- âœ… **Production-Ready**: Pipeline sklearn compatible con MLflow

---

## ğŸ¯ Modelo y Resultados

### Modelo Actual en ProducciÃ³n

- **Algoritmo**: Random Forest Optimizado
- **Accuracy**: **80.17%**
- **Location**: `models/optimized/production_model.pkl`
- **Dataset**: v2_cleaned_full.csv (408 filas)
- **Features**: 50+ caracterÃ­sticas acÃºsticas

### Experimentos MLflow

Se ejecutaron **7 experimentos** documentados en `mlflow_artifacts/`:

| Experimento | Modelo | Accuracy | F1-Score |
|------------|--------|----------|----------|
| exp_01 | Random Forest (Current Best) | 80.17% | 0.80 |
| exp_02 | Random Forest (Deep) | 78.5% | 0.78 |
| exp_03 | Random Forest (Simple) | 76.2% | 0.76 |
| exp_04 | Gradient Boosting | 77.8% | 0.77 |
| exp_05 | Gradient Boosting (Conservative) | 75.9% | 0.75 |
| exp_06 | Logistic Regression | 72.3% | 0.71 |
| exp_07 | SVM RBF | 74.1% | 0.73 |

**Resumen**: `mlflow_artifacts/experiments_summary.csv`

### Features Clave

Las 50+ caracterÃ­sticas acÃºsticas incluyen:

- **MFCC** (Mel-Frequency Cepstral Coefficients): 1-13 con mean/std
- **Spectral Features**: Centroid, Rolloff, Bandwidth, Contrast
- **Temporal Features**: Zero Crossing Rate, Tempo
- **Energy Features**: RMS Energy, Low Energy
- **Statistical**: Mean, Std, Min, Max por feature

### Pipeline de Datos

```
Raw Audio â†’ Feature Extraction â†’ Cleaning â†’ Transformation â†’ Model Training
```

1. **Raw Data**: Archivos CSV con caracterÃ­sticas pre-extraÃ­das
2. **Cleaning**: EliminaciÃ³n de duplicados, manejo de missing values
3. **Feature Engineering**: Scaling, selection, outlier handling
4. **Model Training**: Random Forest con hyperparameter tuning
5. **Evaluation**: Cross-validation, confusion matrix, classification report

---

## ğŸš€ MLOps Infrastructure

### DVC (Data Version Control)

**ConfiguraciÃ³n**:
```yaml
# .dvc/config
remote:
  mlops24-s3:
    url: s3://mlops24-haowei-bucket/dvcstore
```

**Archivos Trackeados**:
- `data.dvc` â†’ Carpeta `data/` completa
- `models/baseline.dvc` â†’ Modelos baseline
- `models/optimized.dvc` â†’ Modelos optimizados

**Comandos Clave**:
```bash
dvc pull              # Descargar datos desde S3
dvc push              # Subir datos a S3
dvc status            # Ver cambios pendientes
dvc repro             # Reproducir pipeline
```

### MLflow (Experiment Tracking)

**ConfiguraciÃ³n Docker**:
```yaml
# docker-compose.yml
services:
  mlflow:
    image: ghcr.io/mlflow/mlflow:latest
    ports:
      - "5001:5000"
    volumes:
      - ./mlartifacts:/mlflow/mlartifacts
```

**Uso**:
```bash
docker-compose up -d    # Iniciar MLflow
# Acceder: http://localhost:5001
```

**Tracking**:
- 7 experimentos registrados
- MÃ©tricas: accuracy, f1-score, precision, recall
- Artifacts: modelos, confusion matrices, classification reports

### AWS S3 (Cloud Storage)

**Bucket**: `mlops24-haowei-bucket`

**Estructura en S3**:
```
s3://mlops24-haowei-bucket/
â”œâ”€â”€ dvcstore/
â”‚   â”œâ”€â”€ files/md5/...
â”‚   â”œâ”€â”€ data/
â”‚   â””â”€â”€ models/
```

**SincronizaciÃ³n**:
```bash
# Verificar sync
make verify-sync

# O manualmente
python scripts/validation/verify_sync.py
```

### Cookiecutter Compliance

**Dashboard de ValidaciÃ³n**: [https://mlopsteam24-cookiecutter2.streamlit.app](https://mlopsteam24-cookiecutter2.streamlit.app)

**Cumplimiento**: **95.2%**

**ValidaciÃ³n Local**:
```bash
cd monitoring/dashboard
streamlit run streamlit_dashboard.py
```

---

## ğŸ’» InstalaciÃ³n y ConfiguraciÃ³n

### Requisitos Previos

- **Python**: 3.12+
- **Git**: Latest version
- **DVC**: Latest version
- **AWS CLI**: Configurado con credenciales
- **Docker** (opcional): Para MLflow

### InstalaciÃ³n Paso a Paso

#### 1. Clonar el Repositorio

```bash
git clone <repository-url>
cd MLOps_Team24
```

#### 2. Crear Entorno Virtual

**OpciÃ³n A: conda**
```bash
conda create -n acoustic_ml python=3.12
conda activate acoustic_ml
```

**OpciÃ³n B: venv**
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# o
venv\Scripts\activate     # Windows
```

#### 3. Instalar Dependencias

```bash
pip install -r requirements.txt
```

#### 4. Instalar MÃ³dulo en Modo Desarrollo

```bash
pip install -e .
```

Esto instala `acoustic_ml` como mÃ³dulo editable.

#### 5. Configurar AWS Credentials

```bash
aws configure
# Ingresar:
# AWS Access Key ID
# AWS Secret Access Key
# Default region: us-east-1
```

#### 6. Configurar DVC Remote

```bash
dvc remote add -d mlops24-s3 s3://mlops24-haowei-bucket/dvcstore
dvc remote modify mlops24-s3 region us-east-1
```

#### 7. Descargar Datos

```bash
dvc pull
```

Esto descarga:
- `data/` completo desde S3
- `models/` baseline y optimized

#### 8. Verificar InstalaciÃ³n

```bash
# Test imports
python -c "import acoustic_ml; print(acoustic_ml.__version__)"

# Verificar sync
make verify-sync
```

#### 9. (Opcional) Iniciar MLflow

```bash
docker-compose up -d
# Acceder: http://localhost:5001
```

---

## ğŸ“– Uso del Sistema

### ğŸµ OpciÃ³n 1: Usar la AplicaciÃ³n Web (Recomendado)

La forma mÃ¡s rÃ¡pida de probar el sistema es usando nuestra **app de Streamlit desplegada**:

**ğŸŒ URL**: [tu-url-de-streamlit].streamlit.app

**Funcionalidades**:
- ğŸ¼ AnÃ¡lisis de emociones en tiempo real
- ğŸ“Š Visualizaciones interactivas (waveform, spectrogram)
- ğŸ“ Subir tus propios archivos de audio (.mp3, .wav)
- ğŸ¯ PredicciÃ³n con modelo Random Forest (76.9% accuracy)
- ğŸ“ˆ Feature importance analysis
- ğŸ”„ Batch analysis de mÃºltiples canciones

Ver la secciÃ³n [ğŸµ Streamlit App - Production Demo](#-streamlit-app---production-demo) para mÃ¡s detalles.

---

### ğŸ–¥ï¸ OpciÃ³n 2: Uso Local del MÃ³dulo Python

#### 1. Cargar Datos

```python
from acoustic_ml.dataset import load_dataset

# Cargar dataset principal (408 filas)
df = load_dataset('v2_cleaned_full')
print(f"Dataset shape: {df.shape}")

# O cargar con splits predefinidos
X_train, X_test, y_train, y_test = load_dataset('v2_cleaned_full', return_splits=True)
print(f"Train: {X_train.shape}, Test: {X_test.shape}")

# Ver las clases disponibles
print(f"Emotions: {y_train.unique()}")  # ['Happy', 'Sad', 'Angry', 'Relax']
```

#### 2. Feature Engineering

```python
from acoustic_ml.features import FeaturePipeline

# Crear pipeline de transformaciÃ³n
pipeline = FeaturePipeline()

# Fit y transform sobre datos de entrenamiento
X_transformed = pipeline.fit_transform(X_train, y_train)

# Transform datos de test (sin fit)
X_test_transformed = pipeline.transform(X_test)

print(f"Features originales: {X_train.shape[1]}")
print(f"Features transformados: {X_transformed.shape[1]}")
```

#### 3. Entrenar Modelo desde Cero

```python
from acoustic_ml.modeling.sklearn_pipeline import create_sklearn_pipeline
from acoustic_ml.dataset import load_dataset
from sklearn.metrics import classification_report, accuracy_score

# 1. Cargar datos
X_train, X_test, y_train, y_test = load_dataset('v2_cleaned_full', return_splits=True)

# 2. Crear pipeline completo (preprocessing + modelo)
model_pipeline = create_sklearn_pipeline(model_type='random_forest')

# 3. Entrenar
print("Entrenando modelo...")
model_pipeline.fit(X_train, y_train)

# 4. Predecir
predictions = model_pipeline.predict(X_test)
probabilities = model_pipeline.predict_proba(X_test)

# 5. Evaluar
accuracy = accuracy_score(y_test, predictions)
print(f"\nâœ… Accuracy: {accuracy:.2%}")
print("\nClassification Report:")
print(classification_report(y_test, predictions))

# 6. Guardar modelo
import joblib
joblib.dump(model_pipeline, 'models/my_model.pkl')
print("\nğŸ’¾ Modelo guardado en: models/my_model.pkl")
```

#### 4. Hacer Predicciones con Modelo Pre-entrenado

```python
import joblib
import pandas as pd
from acoustic_ml.dataset import load_dataset

# 1. Cargar modelo pre-entrenado
model = joblib.load('models/optimized/production_model.pkl')
print("âœ… Modelo cargado (Accuracy: 80.17%)")

# 2. Cargar datos nuevos
X_test, _, _, y_test = load_dataset('v2_cleaned_full', return_splits=True)

# 3. Hacer predicciones
predictions = model.predict(X_test)
probabilities = model.predict_proba(X_test)

# 4. Ver resultados
for i in range(5):  # Primeras 5 predicciones
    true_label = y_test.iloc[i]
    pred_label = predictions[i]
    confidence = probabilities[i].max()
    
    print(f"\nCanciÃ³n {i+1}:")
    print(f"  Real: {true_label}")
    print(f"  PredicciÃ³n: {pred_label} (confianza: {confidence:.2%})")
    print(f"  âœ… Correcto" if true_label == pred_label else "  âŒ Incorrecto")
```

#### 5. PredicciÃ³n de una Sola CanciÃ³n

```python
import joblib
import numpy as np

# Cargar modelo
model = joblib.load('models/optimized/production_model.pkl')

# Features de una nueva canciÃ³n (50+ caracterÃ­sticas acÃºsticas)
new_song_features = np.array([
    [0.123, -0.456, 0.789, ...]  # MFCC, spectral features, etc.
])

# Predecir emociÃ³n
emotion = model.predict(new_song_features)[0]
confidence = model.predict_proba(new_song_features)[0]

print(f"EmociÃ³n detectada: {emotion}")
print(f"Confianzas: Happy={confidence[0]:.2%}, Sad={confidence[1]:.2%}, "
      f"Angry={confidence[2]:.2%}, Relax={confidence[3]:.2%}")
```

#### 6. Visualizaciones

```python
from acoustic_ml.plots import plot_confusion_matrix, plot_feature_importance
import matplotlib.pyplot as plt

# Confusion matrix
fig = plot_confusion_matrix(
    y_test, 
    predictions, 
    save_path='reports/figures/my_confusion_matrix.png'
)
plt.show()

# Feature importance (requiere modelo con feature_importances_)
feature_names = X_train.columns.tolist()
plot_feature_importance(
    model.named_steps['classifier'],  # Extraer clasificador del pipeline
    feature_names, 
    top_n=20,
    save_path='reports/figures/feature_importance.png'
)
plt.show()
```

#### 7. Batch Prediction (MÃºltiples Canciones)

```python
import joblib
import pandas as pd
from pathlib import Path

# Cargar modelo
model = joblib.load('models/optimized/production_model.pkl')

# Cargar dataset con canciones nuevas
songs_df = pd.read_csv('data/processed/turkish_music_emotion_v2_cleaned_full.csv')

# Separar features y target
X = songs_df.drop('Class', axis=1)
y_true = songs_df['Class']

# Batch prediction
predictions = model.predict(X)
probabilities = model.predict_proba(X)

# Crear DataFrame con resultados
results_df = pd.DataFrame({
    'Song_ID': range(len(predictions)),
    'True_Emotion': y_true,
    'Predicted_Emotion': predictions,
    'Confidence': probabilities.max(axis=1),
    'Correct': predictions == y_true.values
})

# Guardar resultados
results_df.to_csv('reports/batch_predictions.csv', index=False)
print(f"\nâœ… Predicciones guardadas en: reports/batch_predictions.csv")
print(f"\nAccuracy general: {results_df['Correct'].mean():.2%}")
print(f"Total canciones: {len(results_df)}")
print(f"Correctas: {results_df['Correct'].sum()}")
print(f"Incorrectas: {(~results_df['Correct']).sum()}")
```

---

### ğŸš€ Scripts RÃ¡pidos (LÃ­nea de Comando)

#### Entrenar Modelo Baseline

```bash
# Entrenar Random Forest baseline
python scripts/training/train_baseline.py

# Output: models/baseline/random_forest_baseline.pkl
```

#### Ejecutar Todos los Experimentos MLflow

```bash
# Ejecuta 7 experimentos con diferentes modelos
python scripts/training/run_mlflow_experiments.py

# Ver resultados en: http://localhost:5001 (MLflow UI)
```

#### AnÃ¡lisis Exploratorio

```bash
# AnÃ¡lisis de outliers
python scripts/analysis/analyze_outliers.py

# ComparaciÃ³n de scalers (StandardScaler vs RobustScaler)
python scripts/analysis/compare_scalers.py

# AnÃ¡lisis completo
python scripts/analysis/run_full_analysis.py
```

#### ValidaciÃ³n y Testing

```bash
# ValidaciÃ³n completa del sistema
python tests/test_full_integration.py

# Tests especÃ­ficos
python tests/test_sklearn_pipeline.py
python tests/test_dataset_equivalence.py
```

---

### ğŸ“Š Workflow Completo: De Cero a ProducciÃ³n

```bash
# 1. Setup inicial
conda activate acoustic_ml
dvc pull  # Descargar datos

# 2. ExploraciÃ³n (opcional)
jupyter notebook notebooks/1.0-team-eda-turkish-music.ipynb

# 3. Entrenar modelo
python scripts/training/train_baseline.py

# 4. ExperimentaciÃ³n con MLflow
docker-compose up -d  # Iniciar MLflow UI
python scripts/training/run_mlflow_experiments.py

# 5. Evaluar mejor modelo
python -c "
from acoustic_ml.dataset import load_dataset
from acoustic_ml.modeling.sklearn_pipeline import create_sklearn_pipeline
from sklearn.metrics import classification_report

X_train, X_test, y_train, y_test = load_dataset('v2_cleaned_full', return_splits=True)
model = create_sklearn_pipeline('random_forest')
model.fit(X_train, y_train)
predictions = model.predict(X_test)
print(classification_report(y_test, predictions))
"

# 6. Guardar modelo final
python -c "
import joblib
from acoustic_ml.modeling.sklearn_pipeline import create_sklearn_pipeline
model = create_sklearn_pipeline('random_forest')
# ... entrenar ...
joblib.dump(model, 'models/optimized/production_model.pkl')
print('âœ… Modelo guardado')
"

# 7. Deploy (Streamlit app o API)
# Ver secciÃ³n de Streamlit App
```

---

## ğŸ› ï¸ Scripts Disponibles

### Makefile Commands

El proyecto incluye un `Makefile` con comandos Ãºtiles:

```bash
make data           # Descarga datos con DVC
make train          # Entrena modelo baseline
make reproduce      # Reproduce pipeline DVC completo
make clean          # Limpia archivos temporales
make verify-sync    # Verifica sincronizaciÃ³n DVC+Git+S3
make freeze         # Actualiza requirements.txt
make test           # Ejecuta tests
make mlflow         # Inicia MLflow UI
make help           # Muestra todos los comandos
```

### Scripts de Training

```bash
# Entrenamiento baseline
python scripts/training/train_baseline.py

# Experimentos MLflow (7 modelos)
python scripts/training/run_mlflow_experiments.py
```

### Scripts de AnÃ¡lisis

```bash
# AnÃ¡lisis de outliers
python scripts/analysis/analyze_outliers.py

# ComparaciÃ³n de scalers
python scripts/analysis/compare_scalers.py

# AnÃ¡lisis completo
python scripts/analysis/run_full_analysis.py
```

### Scripts de ValidaciÃ³n

```bash
# Verificar sincronizaciÃ³n DVC+Git+S3
python scripts/validation/verify_sync.py

# ValidaciÃ³n Cookiecutter
python tests/validate_cookiecutter.py

# Tests de integraciÃ³n
python tests/test_full_integration.py
```

---

## ğŸ§ª Testing & Quality Assurance

### Ejecutar Tests

```bash
# Ejecutar todos los tests con output detallado
pytest tests/ -v

# Modo quiet (resumen)
pytest tests/ -q

# Tests especÃ­ficos con traceback corto
pytest tests/ -v --tb=short

# Con cobertura
pytest tests/ --cov=acoustic_ml
```

### Suite de 33 Tests

**UbicaciÃ³n**: `tests/` (4 mÃ³dulos principales)

| MÃ³dulo | Tipo | Cantidad | PropÃ³sito |
|--------|------|----------|----------|
| `test_dataset_equivalence.py` | Unitario | 8 tests | Validar DatasetManager, cargas, transformaciones |
| `test_sklearn_pipeline.py` | Unitario | 7 tests | Pipeline sklearn, features, scalers |
| `test_full_integration.py` | IntegraciÃ³n | 12 tests | End-to-end: data â†’ model â†’ predict |
| `test_api_endpoints.py` | API | 6 tests | FastAPI endpoints (TestClient, no servidor) |

### Tipos de Tests

**Unitarios (15 tests)**:
```bash
pytest tests/test_dataset_equivalence.py -v  # DatasetManager, data loading
pytest tests/test_sklearn_pipeline.py -v     # Feature engineering, pipeline creation
```

**IntegraciÃ³n (12 tests)**:
```bash
pytest tests/test_full_integration.py -v     # Full pipeline: train â†’ predict
```

**API (6 tests)**:
```bash
pytest tests/test_api_endpoints.py -v        # /health, /predict, /train, /models
```

### Resultado Esperado

```
tests/test_dataset_equivalence.py::test_load_data PASSED
tests/test_dataset_equivalence.py::test_dataset_manager PASSED
tests/test_sklearn_pipeline.py::test_create_pipeline PASSED
tests/test_sklearn_pipeline.py::test_feature_transform PASSED
tests/test_full_integration.py::test_train_predict_pipeline PASSED
tests/test_api_endpoints.py::test_health_check PASSED
tests/test_api_endpoints.py::test_predict_endpoint PASSED

========================== 33 passed in 2.45s ==========================
```

### ValidaciÃ³n RÃ¡pida Post-Cambios

```bash
# Quick test despuÃ©s de editar cÃ³digo
make test

# O directamente
pytest tests/ -q
```

---

## ğŸŒ API Serving with FastAPI

### Endpoints Disponibles

| MÃ©todo | Endpoint | DescripciÃ³n |
|--------|----------|-------------|
| `GET` | `/` | Root endpoint - API status |
| `GET` | `/api/v1/health` | Health check del sistema |
| `POST` | `/api/v1/predict` | PredicciÃ³n single de emociÃ³n |
| `POST` | `/api/v1/train` | Trigger retraining del modelo |
| `GET` | `/api/v1/models` | Listar modelos disponibles |

### Iniciar Localmente

```bash
# OpciÃ³n 1: Uvicorn directo
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# OpciÃ³n 2: Desde app/main.py
python app/main.py

# OpciÃ³n 3: Con gunicorn (producciÃ³n)
gunicorn app.main:app --workers 4 --worker-class uvicorn.workers.UvicornWorker
```

**Acceso a documentaciÃ³n automÃ¡tica**:
```
Swagger UI:  http://localhost:8000/docs
ReDoc:       http://localhost:8000/redoc
OpenAPI:     http://localhost:8000/openapi.json
```

### Ejemplo: POST /api/v1/predict

**Request JSON**:
```bash
curl -X POST "http://localhost:8000/api/v1/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "chroma_stft": 0.45,
    "chroma_stft_std": 0.32,
    "mfcc_1": 12.5,
    "mfcc_1_std": 8.3,
    "mfcc_2": -5.2,
    "mfcc_2_std": 3.1,
    "mfcc_3": 2.1,
    "mfcc_3_std": 1.8,
    "mfcc_4": 0.9,
    "mfcc_4_std": 0.7,
    "mfcc_5": -1.2,
    "mfcc_5_std": 0.5,
    "zero_crossing_rate": 0.12,
    "zero_crossing_rate_std": 0.08
  }'
```

**Response JSON**:
```json
{
  "emotion": "Happy",
  "confidence": 0.87,
  "probabilities": {
    "Happy": 0.87,
    "Angry": 0.08,
    "Sad": 0.03,
    "Relax": 0.02
  },
  "model_version": "production_model_v2",
  "timestamp": "2024-11-12T10:30:45.123Z"
}
```

### Health Check: GET /api/v1/health

```bash
curl http://localhost:8000/api/v1/health
```

**Response**:
```json
{
  "status": "healthy",
  "model_loaded": true,
  "s3_connection": true,
  "mlflow_connection": true,
  "timestamp": "2024-11-12T10:30:00Z"
}
```

### UbicaciÃ³n del CÃ³digo

```
app/
â”œâ”€â”€ main.py           <- Entry point, lifespan, docs
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py       <- APIRouter con todos los endpoints
â”‚   â”œâ”€â”€ endpoints.py  <- Funciones de cada endpoint
â”‚   â””â”€â”€ schemas.py    <- Pydantic models (request/response)
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ config.py     <- ConfiguraciÃ³n API (host, port, etc)
â”‚   â””â”€â”€ logger.py     <- Setup logging
â””â”€â”€ services/
    â””â”€â”€ model_service.py <- LÃ³gica de predicciÃ³n y modelo
```

### Schemas Pydantic (ValidaciÃ³n AutomÃ¡tica)

- `PredictionRequest`: 50+ features acÃºsticos (validados)
- `PredictionResponse`: Estructura estandardizada respuesta
- `HealthResponse`: Status checks sistema

```bash
# Ver schemas JSON schema
curl http://localhost:8000/openapi.json | grep -A 50 "components"
```

---

## ğŸ” Data Drift Detection & Monitoring

### Ejecutar Drift Detection

```bash
# Modo normal
python -m drift.run_drift

# Con parÃ¡metros
python -m drift.run_drift --threshold 0.05 --output reports/drift/

# Modo test (con synthetic drift data)
python -m drift.run_drift --test-mode
```

### QuÃ© Detecta

**Statistical Drift** (Evidently):
- Cambios en distribuciÃ³n de features acÃºsticos
- ComparaciÃ³n train data vs inference data
- KL divergence > 0.3 = alerta

**Performance Degradation**:
- CaÃ­da en accuracy > 5% = âš ï¸ warning
- DegradaciÃ³n por clase (precision/recall)
- Matriz de confusiÃ³n comparativa

### Thresholds y Alertas

| MÃ©trica | Threshold | AcciÃ³n |
|---------|-----------|--------|
| Accuracy Drop | > 5% | âš ï¸ Warning - Review model |
| Feature Shift | KL divergence > 0.3 | ğŸ”´ Alert - Check data source |
| Class Imbalance | Ratio > 10:1 | ğŸ”´ Critical - Retrain required |

### Output: drift_report.json

**UbicaciÃ³n**: `reports/drift/drift_report.json`

```json
{
  "timestamp": "2024-11-12T10:30:00Z",
  "drift_detected": false,
  "accuracy_drop_percent": -1.11,
  "features_shifted": 3,
  "critical_features": [
    "mfcc_1",
    "chroma_stft",
    "zero_crossing_rate"
  ],
  "recommendation": "Monitor - No action required",
  "performance_metrics": {
    "train_accuracy": 0.8017,
    "inference_accuracy": 0.7906,
    "diff": -0.0111,
    "train_precision": 0.78,
    "inference_precision": 0.77
  }
}
```

### Demo: Drift Real

**Sin drift**:
```
âœ… Accuracy: 80.17% â†’ 79.06% (diff: -1.11%)
âœ… Status: HEALTHY
```

**Con synthetic drift** (`generate_drift_data.py`):
```
ğŸ”´ Accuracy: 80.17% â†’ 17.28% (diff: -62.89%)
ğŸ”´ Status: CRITICAL - Retrain required
```

### Archivos y Scripts

```
drift/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ run_drift.py         <- Main execution script
â”œâ”€â”€ drift_detector.py    <- Statistical analysis (Evidently)
â””â”€â”€ comparators.py       <- Feature comparators

scripts/data/
â””â”€â”€ generate_drift_data.py  <- Genera synthetic drift data para testing
```

### Generar y Probar Drift

```bash
# Generar synthetic drift data
python scripts/data/generate_drift_data.py

# Ejecutar drift detection
python -m drift.run_drift --test-mode

# Ver reporte
cat reports/drift/drift_report.json | jq .
```

---

## ğŸ³ Docker & Containerization

### Build Imagen

```bash
# Build imagen bÃ¡sica
docker build -t mlops-team24:latest .

# Build con tag de versiÃ³n
docker build -t mlops-team24:v1.0 -t mlops-team24:latest .

# Verificar imagen
docker images | grep mlops-team24
```

### Run Local (Standalone FastAPI)

```bash
# Run simple
docker run -p 8000:8000 mlops-team24:latest

# Con mount de cÃ³digo (desarrollo)
docker run -it -p 8000:8000 \
  -v $(pwd):/app \
  mlops-team24:latest /bin/bash

# Con variables de entorno
docker run -p 8000:8000 \
  -e AWS_ACCESS_KEY_ID=$AWS_KEY \
  -e AWS_SECRET_ACCESS_KEY=$AWS_SECRET \
  mlops-team24:latest
```

**Verificar que funciona**:
```bash
curl http://localhost:8000/api/v1/health
```

### Docker Compose Stack

**Archivo**: `docker-compose.yml`

```bash
# Iniciar todo el stack
docker compose up

# Modo detached (background)
docker compose up -d

# Ver logs
docker compose logs -f api

# Ver status
docker compose ps

# Detener todo
docker compose down

# Limpiar volÃºmenes (reset total)
docker compose down -v
```

**Services que se levantan**:

| Service | Puerto | DescripciÃ³n |
|---------|--------|-------------|
| `api` | `8000` | FastAPI application (uvicorn) |
| `mlflow` | `5001` | MLflow tracking server |
| `minio` | `9000` | S3-compatible storage (opcional) |

**Acceso**:
```
FastAPI Docs:  http://127.0.0.1:8000/docs
MLflow UI:     http://127.0.0.1:5001
MinIO:         http://127.0.0.1:9000
```

### ConfiguraciÃ³n: config.env

**âš ï¸ IMPORTANTE**: `config.env` NO estÃ¡ versionado (`.gitignore`)

```bash
# 1. Copiar template
cp config.env.example config.env

# 2. Llenar con credenciales reales
cat config.env
```

**Contenido de config.env**:
```env
# AWS S3
AWS_ACCESS_KEY_ID=tu_access_key_aqui
AWS_SECRET_ACCESS_KEY=tu_secret_key_aqui
AWS_REGION=us-east-1
AWS_S3_BUCKET=mlops24-haowei-bucket

# MLflow
MLFLOW_BACKEND_STORE_URI=sqlite:///mlflow.db
MLFLOW_DEFAULT_ARTIFACT_ROOT=s3://mlops24-haowei-bucket/mlflow

# DVC
DVC_REMOTE_URL=s3://mlops24-haowei-bucket/dvc-storage
```

### Dockerfile

```dockerfile
FROM python:3.12-slim

WORKDIR /app

# Instalar dependencias del sistema
RUN apt-get update && apt-get install -y --no-install-recommends \
    git \
    && rm -rf /var/lib/apt/lists/*

# Copiar requirements
COPY requirements-prod.txt .

# Instalar Python deps
RUN pip install --no-cache-dir -r requirements-prod.txt

# Copiar cÃ³digo
COPY . .

# Exponer puerto
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
  CMD python -c "import requests; requests.get('http://localhost:8000/api/v1/health', timeout=5)"

# Comando por defecto
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### Backend Storage

**Desarrollo** (docker-compose):
- SQLite: `mlflow.db` (local)
- Artifacts: Directorio `mlflow_artifacts/`

**ProducciÃ³n**:
- Backend: PostgreSQL o RDS
- Artifacts: AWS S3 (`mlops24-haowei-bucket`)

---

## ğŸ”„ Reproducibility & Seeds

### Seeds Configurados

**Archivo**: `acoustic_ml/__init__.py` y `acoustic_ml/config.py`

```python
import numpy as np
from sklearn.utils import check_random_state

RANDOM_SEED = 42
np.random.seed(RANDOM_SEED)

# En sklearn pipelines
RandomForestClassifier(random_state=RANDOM_SEED)
train_test_split(X, y, random_state=RANDOM_SEED)
```

**Todos los modelos usan**:
- `random_seed=42`
- `numpy seed=42`
- `sklearn seed=42`
- `pytorch seed=42` (si aplica)

### Requirements Fijado

**Archivo**: `requirements-prod.txt` (pip freeze)

```
scikit-learn==1.3.2
pandas==2.1.3
numpy==1.24.3
mlflow==2.10.0
fastapi==0.104.1
uvicorn==0.24.0
pydantic==2.4.2
```

**Generar nuevo freeze**:
```bash
pip freeze > requirements-prod.txt
```

### DVC Data Versioning

**Versionado**:
- âœ… `data/processed/` â†’ `data.dvc`
- âœ… `models/optimized/` â†’ `models/optimized.dvc`
- âœ… Tracked en S3: `mlops24-haowei-bucket`

**Pull datos antes de ejecutar**:
```bash
dvc pull
```

### Reproducir Pipeline Completo

```bash
# OpciÃ³n 1: Pull datos + Drift validation
dvc pull && python -m drift.run_drift

# OpciÃ³n 2: Full train + predict pipeline
dvc pull && python acoustic_ml/modeling/train.py

# OpciÃ³n 3: Verificar sincronizaciÃ³n
make verify-sync && pytest tests/ -q
```

### Validar Reproducibilidad

```bash
# 1. Ejecutar pipeline en mÃ¡quina A
dvc pull
python acoustic_ml/modeling/train.py
# â†’ Genera modelo con accuracy 80.17%

# 2. Ejecutar pipeline en mÃ¡quina B (mismo cÃ³digo)
dvc pull
python acoustic_ml/modeling/train.py
# â†’ DEBE generar exactamente el mismo modelo con accuracy 80.17%

# 3. Verificar hashes
md5sum models/optimized/production_model.pkl
# Deben coincidir entre mÃ¡quinas
```

### Checklist Reproducibilidad

- âœ… Seeds configurados (numpy, sklearn, random)
- âœ… Requirements fijado con pip freeze
- âœ… DVC data versioning activo
- âœ… Docker containerizaciÃ³n
- âœ… 33 tests pasando
- âœ… Git history limpio (conventional commits)
- âœ… Pipeline determinÃ­stico end-to-end

---

## âœ… Phase 3 Requirements Checklist

**Todos los requisitos de Fase 3 implementados y validados**:

| Requisito | ImplementaciÃ³n | Status |
|-----------|---|--------|
| **1. Pruebas Unitarias/IntegraciÃ³n** | 33 tests (pytest) en `tests/` - Unitarios, IntegraciÃ³n, API, Full Pipeline | âœ… COMPLETO |
| **2. FastAPI Serving** | 5 endpoints en `app/` - /health, /predict, /train, /models, / | âœ… COMPLETO |
| **3. Reproducibilidad** | Seeds, requirements-prod.txt, DVC, Docker - dvc pull && python -m drift.run_drift | âœ… COMPLETO |
| **4. Docker ContainerizaciÃ³n** | docker-compose.yml con FastAPI + MLflow - docker compose up | âœ… COMPLETO |
| **5. Data Drift Detection** | Evidently + statistical monitoring - python -m drift.run_drift | âœ… COMPLETO |

### VerificaciÃ³n RÃ¡pida

```bash
# 1. Tests
pytest tests/ -q  # âœ… 33 passed

# 2. API
uvicorn app.main:app --reload
curl http://localhost:8000/api/v1/health  # âœ… healthy

# 3. Reproducibilidad
dvc pull && python -m drift.run_drift  # âœ… consistent results

# 4. Docker
docker compose up -d  # âœ… all services running

# 5. Drift
python -m drift.run_drift --test-mode  # âœ… drift_report.json generated
```

---

## ğŸ—‚ï¸ Project Structure

**Estructura completa orientada a Fase 3**:

```
MLOps_Team24/
â”‚
â”œâ”€â”€ ğŸ“„ ConfiguraciÃ³n (RaÃ­z)
â”‚   â”œâ”€â”€ README.md                    â† Este archivo
â”‚   â”œâ”€â”€ Makefile                     â† Comandos: make test, make train, etc
â”‚   â”œâ”€â”€ requirements-prod.txt        â† Dependencies fijadas (pip freeze)
â”‚   â”œâ”€â”€ requirements-dev.txt         â† Dev dependencies (pytest, etc)
â”‚   â”œâ”€â”€ pyproject.toml               â† Proyecto Python config
â”‚   â”œâ”€â”€ params.yaml                  â† ParÃ¡metros DVC pipeline
â”‚   â”œâ”€â”€ dvc.yaml                     â† Pipeline stages
â”‚   â”œâ”€â”€ docker-compose.yml           â† FastAPI + MLflow + MinIO stack
â”‚   â”œâ”€â”€ Dockerfile                   â† Container image
â”‚   â”œâ”€â”€ config.env.example           â† Template variables (AWS, MLflow)
â”‚   â”œâ”€â”€ .gitignore                   â† config.env, .env, datos, modelos
â”‚   â””â”€â”€ .dvc/                        â† DVC configuraciÃ³n
â”‚
â”œâ”€â”€ ğŸ“¦ acoustic_ml/                  â† MÃ³dulo Python principal
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                    â† Global config (RANDOM_SEED=42)
â”‚   â”œâ”€â”€ dataset.py                   â† DatasetManager (Singleton)
â”‚   â”œâ”€â”€ features.py                  â† Feature engineering
â”‚   â”œâ”€â”€ plots.py                     â† Visualizaciones
â”‚   â””â”€â”€ modeling/
â”‚       â”œâ”€â”€ train.py                 â† Training logic
â”‚       â”œâ”€â”€ predict.py               â† Inference
â”‚       â”œâ”€â”€ evaluate.py              â† Metrics
â”‚       â”œâ”€â”€ pipeline.py              â† MLOps pipeline
â”‚       â””â”€â”€ sklearn_pipeline.py      â† Production pipeline
â”‚
â”œâ”€â”€ ğŸŒ app/                          â† FastAPI Application
â”‚   â”œâ”€â”€ main.py                      â† Entry point (uvicorn)
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ main.py                  â† APIRouter endpoints
â”‚   â”‚   â”œâ”€â”€ endpoints.py             â† Endpoint functions
â”‚   â”‚   â””â”€â”€ schemas.py               â† Pydantic models
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ config.py                â† API config
â”‚   â”‚   â””â”€â”€ logger.py                â† Logging setup
â”‚   â””â”€â”€ services/
â”‚       â””â”€â”€ model_service.py         â† Model predictions
â”‚
â”œâ”€â”€ ğŸ” drift/                        â† Drift Detection System
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ run_drift.py                 â† Main drift detection
â”‚   â”œâ”€â”€ drift_detector.py            â† Evidently analysis
â”‚   â””â”€â”€ comparators.py               â† Feature comparators
â”‚
â”œâ”€â”€ ğŸ“Š data/                         â† Datos (versionados DVC)
â”‚   â”œâ”€â”€ raw/                         â† Datos originales
â”‚   â”œâ”€â”€ interim/                     â† Transformaciones intermedias
â”‚   â”œâ”€â”€ processed/                   â† Datos finales
â”‚   â”‚   â”œâ”€â”€ turkish_music_emotion_v2_cleaned_full.csv (400+ filas)
â”‚   â”‚   â”œâ”€â”€ X_train.csv, X_test.csv
â”‚   â”‚   â””â”€â”€ y_train.csv, y_test.csv
â”‚   â”œâ”€â”€ data.dvc                     â† DVC tracking
â”‚   â””â”€â”€ .gitignore                   â† Ignorar archivos grandes
â”‚
â”œâ”€â”€ ğŸ’¾ models/                       â† Modelos (versionados)
â”‚   â”œâ”€â”€ optimized/
â”‚   â”‚   â”œâ”€â”€ production_model.pkl     â† Modelo actual (80.17%)
â”‚   â”‚   â””â”€â”€ production_model_metadata.json
â”‚   â””â”€â”€ optimized.dvc                â† DVC tracking
â”‚
â”œâ”€â”€ ğŸ“ˆ mlflow_artifacts/             â† MLflow experiments
â”‚   â”œâ”€â”€ exp_01_Random_Forest_Current_Best/
â”‚   â”œâ”€â”€ experiments_summary.csv
â”‚   â””â”€â”€ experiments_report.txt
â”‚
â”œâ”€â”€ ğŸ““ notebooks/                    â† Jupyter notebooks
â”‚   â”œâ”€â”€ 1.0-team-eda-turkish-music.ipynb
â”‚   â”œâ”€â”€ 2.0-team-preprocessing.ipynb
â”‚   â”œâ”€â”€ 3.0-team-modeling-evaluation.ipynb
â”‚   â””â”€â”€ archive/
â”‚
â”œâ”€â”€ ğŸ“ˆ reports/                      â† AnÃ¡lisis y reportes
â”‚   â”œâ”€â”€ figures/                     â† Visualizaciones
â”‚   â”‚   â”œâ”€â”€ confusion_matrices_top3.png
â”‚   â”‚   â”œâ”€â”€ final_confusion_matrix.png
â”‚   â”‚   â””â”€â”€ *.png
â”‚   â”œâ”€â”€ drift/                       â† Drift reports
â”‚   â”‚   â””â”€â”€ drift_report.json        â† Salida drift detection
â”‚   â””â”€â”€ metrics.json
â”‚
â”œâ”€â”€ ğŸ§ª tests/                        â† Test Suite (33 tests)
â”‚   â”œâ”€â”€ test_dataset_equivalence.py  â† Dataset tests
â”‚   â”œâ”€â”€ test_sklearn_pipeline.py     â† Pipeline tests
â”‚   â”œâ”€â”€ test_full_integration.py     â† Integration tests
â”‚   â”œâ”€â”€ test_api_endpoints.py        â† API tests (TestClient)
â”‚   â”œâ”€â”€ validate_cookiecutter.py     â† Structure validation
â”‚   â”œâ”€â”€ validate_dataset.py
â”‚   â”œâ”€â”€ validate_features.py
â”‚   â””â”€â”€ validate_plots.py
â”‚
â”œâ”€â”€ ğŸ“š scripts/                      â† Scripts automatizados
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ train_baseline.py
â”‚   â”‚   â””â”€â”€ run_mlflow_experiments.py
â”‚   â”œâ”€â”€ analysis/
â”‚   â”‚   â”œâ”€â”€ analyze_outliers.py
â”‚   â”‚   â””â”€â”€ compare_scalers.py
â”‚   â”œâ”€â”€ validation/
â”‚   â”‚   â””â”€â”€ verify_sync.py
â”‚   â””â”€â”€ data/
â”‚       â””â”€â”€ generate_drift_data.py   â† Synthetic drift generation
â”‚
â”œâ”€â”€ ğŸ“Š monitoring/                   â† Monitoring & Dashboards
â”‚   â”œâ”€â”€ dashboard/
â”‚   â”‚   â””â”€â”€ streamlit_dashboard.py   â† Cookiecutter validation dashboard
â”‚   â””â”€â”€ README.md
â”‚
â””â”€â”€ ğŸ“š references/                   â† DocumentaciÃ³n externa
    â”œâ”€â”€ Diccionario_Variables_Musica_Turca.xlsx
    â”œâ”€â”€ Fase1_Equipo24.pdf
    â”œâ”€â”€ Fase2_Equipo24.pdf
    â””â”€â”€ Team24_Machine_Learning_Canvas.pdf
```

**Cookiecutter Data Science Compliance**: âœ… 95.2%

**Referencia**: [Cookiecutter Data Science](https://drivendata.github.io/cookiecutter-data-science/)

---
## ğŸµ Streamlit App - Production Demo

### ğŸŒ AplicaciÃ³n Web Desplegada

Hemos desarrollado una **aplicaciÃ³n web interactiva** para demostrar las capacidades del sistema de reconocimiento de emociones musicales en producciÃ³n.

**ğŸ”— URL de Acceso**: **[tu-url-de-streamlit].streamlit.app**

**ğŸ“± Compatibilidad**: Desktop, Tablet, Mobile

---

### âœ¨ CaracterÃ­sticas Principales

#### ğŸ¼ 1. AnÃ¡lisis de MÃºsica en Tiempo Real

- **PredicciÃ³n instantÃ¡nea** de emociones en canciones turcas
- **4 emociones detectadas**: Angry ğŸ˜¡, Happy ğŸ˜Š, Relax ğŸ˜Œ, Sad ğŸ˜¢
- **Confianza de predicciÃ³n**: Probabilidades por clase
- **Modelo**: Random Forest (76.9% accuracy)

#### ğŸ“ 2. Upload de Archivos

- **Formatos soportados**: `.mp3`, `.wav`, `.ogg`
- **Procesamiento automÃ¡tico**: ExtracciÃ³n de features acÃºsticas
- **AnÃ¡lisis inmediato**: Resultados en segundos
- **LÃ­mite de tamaÃ±o**: 200MB por archivo

#### ğŸ“Š 3. Visualizaciones Interactivas

**Waveform (Forma de Onda)**:
- VisualizaciÃ³n temporal de la seÃ±al de audio
- Amplitud vs. tiempo
- IdentificaciÃ³n de patrones rÃ­tmicos

**Spectrogram (Espectrograma)**:
- RepresentaciÃ³n tiempo-frecuencia
- Intensidad de frecuencias a lo largo del tiempo
- IdentificaciÃ³n de caracterÃ­sticas tonales

**Feature Importance**:
- Top 20 caracterÃ­sticas mÃ¡s relevantes
- Impacto de cada feature en la predicciÃ³n
- AnÃ¡lisis de MFCC, spectral features, temporal features

#### ğŸ¯ 4. PredicciÃ³n con Audios de Muestra

- **Biblioteca de ejemplos**: Canciones turcas pre-cargadas
- **Cada emociÃ³n representada**: 1-2 ejemplos por clase
- **Testing rÃ¡pido**: Probar el modelo sin subir archivos
- **ComparaciÃ³n**: Ver diferentes emociones musicales

#### ğŸ”„ 5. Batch Analysis

- **AnÃ¡lisis mÃºltiple**: Subir y procesar varias canciones
- **Resultados agregados**: EstadÃ­sticas del conjunto
- **Exportar CSV**: Descargar predicciones completas
- **ComparaciÃ³n entre canciones**: AnÃ¡lisis comparativo

#### ğŸšï¸ 6. Selector de Modelos (Local)

Si ejecutas la app localmente, puedes cambiar entre modelos:
- Random Forest (default) - 76.9% accuracy
- Gradient Boosting - 77.8% accuracy
- XGBoost - experimental

---

### ğŸš€ CÃ³mo Usar la App

#### OpciÃ³n 1: App en la Nube (Recomendado)

1. **Acceder**: Ir a [tu-url-de-streamlit].streamlit.app
2. **Elegir modo**:
   - ğŸ“ **Upload**: Subir tu propio audio
   - ğŸµ **Samples**: Usar audios de ejemplo
3. **Analizar**: La app procesarÃ¡ automÃ¡ticamente
4. **Ver resultados**:
   - EmociÃ³n predicha con confianza
   - Visualizaciones (waveform, spectrogram)
   - Feature importance
5. **Experimentar**: Probar con diferentes canciones

#### OpciÃ³n 2: Ejecutar Localmente

```bash
# 1. Navegar al directorio de la app
cd streamlit_app/  # o donde estÃ© tu app de Streamlit

# 2. Instalar dependencias
pip install -r requirements.txt

# 3. Ejecutar app
streamlit run app.py

# 4. Abrir en navegador
# AutomÃ¡ticamente abre en: http://localhost:8501
```

---

### ğŸ› ï¸ TecnologÃ­as Utilizadas

**Backend**:
- **Streamlit**: Framework de la aplicaciÃ³n
- **scikit-learn**: Modelo de ML (Random Forest)
- **librosa**: Procesamiento de audio y feature extraction
- **pandas/numpy**: ManipulaciÃ³n de datos

**VisualizaciÃ³n**:
- **matplotlib**: GrÃ¡ficas estÃ¡ticas
- **plotly**: Visualizaciones interactivas
- **seaborn**: Styling de grÃ¡ficas

**Deployment**:
- **Streamlit Cloud**: Hosting gratuito
- **GitHub Integration**: Deploy automÃ¡tico desde main branch
- **Secrets Management**: ConfiguraciÃ³n segura

---

### ğŸ“ Estructura de la App

```
streamlit_app/
â”œâ”€â”€ app.py                      <- Main application file
â”œâ”€â”€ requirements.txt            <- Dependencies
â”œâ”€â”€ .streamlit/
â”‚   â””â”€â”€ config.toml             <- Streamlit configuration
â”œâ”€â”€ models/
â”‚   â””â”€â”€ baseline_model.pkl      <- Pre-trained model
â”œâ”€â”€ sample_audios/              <- Sample Turkish music files
â”‚   â”œâ”€â”€ angry_example.mp3
â”‚   â”œâ”€â”€ happy_example.mp3
â”‚   â”œâ”€â”€ relax_example.mp3
â”‚   â””â”€â”€ sad_example.mp3
â””â”€â”€ utils/
    â”œâ”€â”€ audio_processor.py      <- Audio feature extraction
    â”œâ”€â”€ model_loader.py         <- Model loading utilities
    â””â”€â”€ visualizations.py       <- Plot generation functions
```

---

### ğŸ”§ ConfiguraciÃ³n y PersonalizaciÃ³n

#### Variables de Entorno

Si ejecutas localmente, puedes configurar:

```toml
# .streamlit/secrets.toml
[model]
default_model = "random_forest"
confidence_threshold = 0.5

[audio]
max_file_size = 200  # MB
allowed_formats = [".mp3", ".wav", ".ogg"]
sample_rate = 22050

[features]
n_mfcc = 13
n_fft = 2048
hop_length = 512
```

#### Personalizar Tema

```toml
# .streamlit/config.toml
[theme]
primaryColor = "#667eea"
backgroundColor = "#0e1117"
secondaryBackgroundColor = "#262730"
textColor = "#fafafa"
font = "sans serif"
```

---

### ğŸ“Š Ejemplos de Uso

#### Ejemplo 1: AnÃ¡lisis de Audio Subido

```
1. Usuario sube: "turkish_song.mp3"
2. App extrae 50+ features acÃºsticas
3. Modelo predice: "Happy" (confianza: 87.3%)
4. Visualizaciones generadas:
   - Waveform: Muestra patrones rÃ­tmicos alegres
   - Spectrogram: Frecuencias altas prominentes
   - Features: MFCC_3 y Spectral_Centroid destacados
```

#### Ejemplo 2: ComparaciÃ³n de Emociones

```
Usuario selecciona 4 samples (uno por emociÃ³n):
- Angry:  PredicciÃ³n correcta (92.1%)
- Happy:  PredicciÃ³n correcta (87.3%)
- Relax:  PredicciÃ³n correcta (81.5%)
- Sad:    PredicciÃ³n correcta (79.8%)

Resultado: 100% accuracy en samples
```

#### Ejemplo 3: Batch Analysis

```
Usuario sube 10 canciones:
- 7 predicciones correctas
- 3 con confusiÃ³n Relax â†” Sad
- Accuracy batch: 70%
- Confianza promedio: 78.4%
```

---

### ğŸ¯ Casos de Uso

#### ğŸµ Para MÃºsicos y Productores

- **Validar la emociÃ³n** que transmite una composiciÃ³n
- **Comparar versiones** de la misma canciÃ³n
- **Analizar el "mood"** de un Ã¡lbum completo

#### ğŸ” Para Investigadores

- **Estudiar caracterÃ­sticas** de mÃºsica emocional turca
- **Comparar con otros datasets** musicales
- **Validar modelos** de emociÃ³n musical

#### ğŸ“š Para EducaciÃ³n

- **Demostrar ML aplicado** en anÃ¡lisis de audio
- **EnseÃ±ar feature engineering** en mÃºsica
- **Mostrar pipeline MLOps** completo

#### ğŸ§ Para Oyentes

- **Descubrir canciones** con emociones especÃ­ficas
- **Entender por quÃ©** una canciÃ³n suena "triste" o "alegre"
- **Explorar mÃºsica turca** por emociÃ³n

---

### ğŸ› Troubleshooting

#### Error: "Model not found"
```bash
# Verificar que el modelo existe
ls models/baseline_model.pkl

# Re-descargar desde DVC
dvc pull models/baseline.dvc
```

#### Error: "Audio file too large"
```python
# Comprimir audio antes de subir
from pydub import AudioSegment
audio = AudioSegment.from_mp3("large_file.mp3")
audio.export("compressed.mp3", format="mp3", bitrate="128k")
```

#### Error: "Feature extraction failed"
```python
# Verificar formato de audio
import librosa
y, sr = librosa.load("audio.mp3", sr=22050)
print(f"Duration: {len(y)/sr:.2f}s, Sample rate: {sr}Hz")
```

---

### ğŸš€ Roadmap de la App

**Fase Actual (Phase 2)** âœ…:
- âœ… PredicciÃ³n bÃ¡sica con modelo Random Forest
- âœ… Upload de archivos de audio
- âœ… Visualizaciones (waveform, spectrogram)
- âœ… AnÃ¡lisis de feature importance
- âœ… Deploy en Streamlit Cloud

**PrÃ³ximas Mejoras (Phase 3)**:
- ğŸ”„ Multi-model comparison en tiempo real
- ğŸ”„ A/B testing entre modelos
- ğŸ”„ Export de reportes PDF
- ğŸ”„ IntegraciÃ³n con API REST
- ğŸ”„ User authentication
- ğŸ”„ Historial de predicciones

**Futuro (Phase 4+)**:
- ğŸ’¡ Recomendaciones de canciones similares
- ğŸ’¡ AnÃ¡lisis de playlists completas
- ğŸ’¡ IntegraciÃ³n con Spotify API
- ğŸ’¡ Mobile app (React Native)
- ğŸ’¡ Real-time audio recording y anÃ¡lisis

---

### ğŸ“¸ Screenshots

> **Nota**: Agregar screenshots reales de la app cuando estÃ© desplegada:

```markdown
![Home Page](docs/images/app_home.png)
*PÃ¡gina principal con opciones de anÃ¡lisis*

![Prediction Results](docs/images/app_prediction.png)
*Resultados de predicciÃ³n con visualizaciones*

![Feature Importance](docs/images/app_features.png)
*AnÃ¡lisis de caracterÃ­sticas mÃ¡s relevantes*
```

---

### ğŸ”— Links Relacionados

- **App en ProducciÃ³n**: [tu-url-de-streamlit].streamlit.app
- **Dashboard Cookiecutter**: [https://mlopsteam24-cookiecutter.streamlit.app](https://mlopsteam24-cookiecutter.streamlit.app)
- **Repositorio GitHub**: [tu-repo-url]
- **MLflow UI**: http://localhost:5001 (local)
- **DocumentaciÃ³n de Streamlit**: https://docs.streamlit.io

---

## ğŸ“Š Monitoring y ValidaciÃ³n

### Dashboard Streamlit

**URL**: [https://mlopsteam24-cookiecutter.streamlit.app](https://mlopsteam24-cookiecutter.streamlit.app)

**CaracterÃ­sticas**:
- âœ… ValidaciÃ³n estructura Cookiecutter (95.2%)
- âœ… VerificaciÃ³n de directorios crÃ­ticos
- âœ… ValidaciÃ³n de archivos configuraciÃ³n
- âœ… Estado de sincronizaciÃ³n DVC
- âœ… MÃ©tricas de cumplimiento

**Local**:
```bash
cd monitoring/dashboard
streamlit run streamlit_dashboard.py
```

### VerificaciÃ³n de SincronizaciÃ³n

**Script**: `scripts/validation/verify_sync.py`

Verifica:
1. âœ… DVC status (sin cambios pendientes)
2. âœ… Git status (working tree clean)
3. âœ… S3 sync (archivos en sync)
4. âœ… Environment consistency

```bash
make verify-sync
# o
python scripts/validation/verify_sync.py
```

**Output Esperado**:
```
âœ… DVC Status: Clean
âœ… Git Status: Clean
âœ… S3 Sync: OK
âœ… Environment: Consistent
```


## ğŸ”„ Workflows y ContribuciÃ³n

### Workflow EstÃ¡ndar

#### 1. Antes de Comenzar

```bash
# Activar entorno
conda activate acoustic_ml

# Verificar sincronizaciÃ³n
make verify-sync

# Actualizar datos
dvc pull
git pull
```

#### 2. Crear Branch

```bash
git checkout -b feat/nueva-funcionalidad
```

#### 3. Hacer Cambios

**Si modificas cÃ³digo**:
```bash
# Editar archivos
vim acoustic_ml/features.py

# Ejecutar tests
python tests/validate_features.py

# Los cambios estÃ¡n disponibles inmediatamente (instalaciÃ³n -e)
```

**Si modificas datos**:
```bash
# DVC tracking
dvc add data
git add data.dvc data/.gitignore
dvc push
```

**Si instalas paquetes**:
```bash
pip install nuevo-paquete
make freeze
git add requirements.txt
```

#### 4. Commit Changes

```bash
git add .
git commit -m "feat: descripciÃ³n clara"
```

Seguir [Conventional Commits](https://www.conventionalcommits.org/):
- `feat:` nueva funcionalidad
- `fix:` correcciÃ³n de bug
- `docs:` documentaciÃ³n
- `refactor:` refactorizaciÃ³n
- `test:` tests
- `chore:` mantenimiento

#### 5. Push Changes

```bash
git push origin feat/nueva-funcionalidad
dvc push  # Si modificaste datos
```

#### 6. Pull Request

Crear PR a `main` con descripciÃ³n clara.

### Buenas PrÃ¡cticas

#### âœ… DO

- âœ… Ejecutar `make verify-sync` antes de comenzar
- âœ… Usar `DatasetManager` para gestionar datos
- âœ… Usar `create_sklearn_pipeline()` para producciÃ³n
- âœ… Ejecutar tests antes de commit
- âœ… Documentar experimentos en MLflow
- âœ… Mantener notebooks limpios (sin outputs)
- âœ… Usar `RobustScaler` para outliers
- âœ… Escribir docstrings completos
- âœ… Seguir Conventional Commits
- âœ… Hacer `dvc push` despuÃ©s de modificar datos

#### âŒ DON'T

- âŒ Modificar datos sin DVC tracking
- âŒ Commitear archivos temporales
- âŒ Usar cÃ³digo legacy sin revisar
- âŒ Hacer commits sin tests
- âŒ Push sin `dvc push` (si hay datos nuevos)
- âŒ Commitear notebooks con outputs
- âŒ Modificar `requirements.txt` manualmente
- âŒ Ignorar warnings de validaciÃ³n

### Code Review Checklist

Antes de aprobar PR:
- [ ] Tests pasan
- [ ] DocumentaciÃ³n actualizada
- [ ] No hay archivos temporales
- [ ] DVC en sync (si aplica)
- [ ] CÃ³digo sigue estÃ¡ndares del proyecto
- [ ] Commit messages son claros

---

## ğŸ‘¥ Equipo de Desarrollo

<div align="center">

<table style="width:100%; border:none;">
  <tr>
    <td align="center" style="border:none; padding:20px 10px;">
      <img src="https://iili.io/Kw90kmB.png" alt="David Cruz BeltrÃ¡n" width="160" style="border-radius: 50%; border: 5px solid #667eea; box-shadow: 0 8px 16px rgba(102, 126, 234, 0.4);"/>
      <h3>David Cruz BeltrÃ¡n</h3>
      <img src="https://img.shields.io/badge/ID-A01360416-667eea?style=for-the-badge" alt="MatrÃ­cula"/>
      <p><strong>ğŸ”§ Software Engineer</strong><br/>
      <em>Pipeline Architecture & Code Quality</em></p>
    </td>
    <td align="center" style="border:none; padding:20px 10px;">
      <img src="https://iili.io/KuvsGKx.png" alt="Javier Augusto Rebull Saucedo" width="160" style="border-radius: 50%; border: 5px solid #764ba2; box-shadow: 0 8px 16px rgba(118, 75, 162, 0.4);"/>
      <h3>Javier Augusto Rebull Saucedo</h3>
      <img src="https://img.shields.io/badge/ID-A01795838-764ba2?style=for-the-badge" alt="MatrÃ­cula"/>
      <p><strong>âš™ï¸ SRE / Data Engineer</strong><br/>
      <em>DevOps, Infrastructure & Data Versioning</em></p>
    </td>
    <td align="center" style="border:none; padding:20px 10px;">
      <img src="https://iili.io/Kw91d74.png" alt="Sandra Luz Cervantes Espinoza" width="160" style="border-radius: 50%; border: 5px solid #f093fb; box-shadow: 0 8px 16px rgba(240, 147, 251, 0.4);"/>
      <h3>Sandra Luz Cervantes Espinoza</h3>
      <img src="https://img.shields.io/badge/ID-A01796937-f093fb?style=for-the-badge" alt="MatrÃ­cula"/>
      <p><strong>ğŸ¤– ML Engineer / Data Scientist</strong><br/>
      <em>Model Development & Experimentation</em></p>
    </td>
  </tr>
</table>

</div>

---

## ğŸ“š Recursos Adicionales

### DocumentaciÃ³n

- [Cookiecutter Data Science](https://drivendata.github.io/cookiecutter-data-science/)
- [DVC Documentation](https://dvc.org/doc)
- [MLflow Documentation](https://mlflow.org/docs/latest/index.html)
- [Scikit-learn Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)

### Referencias del Proyecto

- `references/Diccionario_Variables_Musica_Turca.xlsx`: Diccionario de variables
- `references/Fase 1_Equipo24.pdf`: Entrega Fase 1
- `references/Fase 2_Equipo24.pdf`: Entrega Fase 2
- `references/Team24_Machine Learning Canvas v1.0.pdf`: ML Canvas

---

<div align="center">

**â­ Si este proyecto te resulta Ãºtil, considera darle una estrella â­**

---

**Desarrollado con â¤ï¸ por MLOps Team 24**

ğŸ—ï¸ **Arquitectura Profesional** | ğŸ§ª **Testing Comprehensivo** | ğŸ¯ **Production-Ready**

ğŸ“Š **95.2% Cookiecutter Compliance** | â˜ï¸ **Cloud-Native** | ğŸ”„ **Fully Reproducible**

---

*Ãšltima actualizaciÃ³n: Noviembre 2024 - Phase 3 Production Deployment*

**Estructura basada en**: [Cookiecutter Data Science](https://drivendata.github.io/cookiecutter-data-science/)

</div>
