# ğŸµ Acoustic ML - Music Emotion Recognition

<div align="center">

**MLOps Team 24 - Proyecto de reconocimiento de emociones musicales**

[![Python](https://img.shields.io/badge/Python-3.12-blue.svg)](https://www.python.org/downloads/)
[![MLflow](https://img.shields.io/badge/MLflow-Tracking-0194E2?logo=mlflow)](https://mlflow.org/)
[![DVC](https://img.shields.io/badge/DVC-Data%20Versioning-945DD6?logo=dvc)](https://dvc.org/)
[![AWS S3](https://img.shields.io/badge/AWS-S3-FF9900?logo=amazon-aws)](https://aws.amazon.com/s3/)

<!-- Badges -->
[![verify-sync](https://img.shields.io/badge/verify--sync-make-blue?logo=gnu&logoColor=white)](#verificaciÃ³n-rÃ¡pida-antes-de-trabajar)
[![dependencies](https://img.shields.io/badge/deps-requirements.txt-informational?logo=python&logoColor=white)](#reproducibilidad-de-entornos)
[![notebooks](https://img.shields.io/badge/notebooks-clean%20outputs-success?logo=jupyter&logoColor=white)](#buenas-prÃ¡cticas-con-notebooks)

</div>

---

## ğŸ“‹ Tabla de Contenidos

- [Sobre el Proyecto](#-sobre-el-proyecto)
- [InformaciÃ³n AcadÃ©mica](#-informaciÃ³n-acadÃ©mica)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [Datasets Disponibles](#-datasets-disponibles)
- [Requisitos Previos](#-requisitos-previos)
- [InstalaciÃ³n](#-instalaciÃ³n)
- [GestiÃ³n de Datos (DVC + S3)](#-gestiÃ³n-de-datos-dvc--s3)
- [Uso](#-uso)
- [VerificaciÃ³n RÃ¡pida antes de Trabajar](#-verificaciÃ³n-rÃ¡pida-antes-de-trabajar)
- [Reproducibilidad de Entornos](#-reproducibilidad-de-entornos)
- [Buenas PrÃ¡cticas con Notebooks](#-buenas-prÃ¡cticas-con-notebooks)
- [Docker Compose](#-docker-compose)
- [Limpieza Local](#-limpieza-local)
- [Arquitectura del Pipeline](#-arquitectura-del-pipeline)
- [ContribuciÃ³n](#-contribuciÃ³n)
- [Equipo](#-equipo)

---

## ğŸ¯ Sobre el Proyecto

Este repositorio contiene la implementaciÃ³n completa de un sistema MLOps para reconocimiento de emociones en mÃºsica, siguiendo las mejores prÃ¡cticas de la industria con la estructura **Cookiecutter Data Science**. El proyecto integra:

- ğŸ“Š **Versionado de datos** con DVC
- ğŸ”„ **Pipelines reproducibles** automatizados
- ğŸ“ˆ **Tracking de experimentos** con MLflow
- â˜ï¸ **Almacenamiento en la nube** (AWS S3)
- ğŸ¤– **Modelos de Machine Learning** versionados
- ğŸ—‚ï¸ **Estructura modular** siguiendo estÃ¡ndares de la industria

---

## ğŸ“˜ InformaciÃ³n AcadÃ©mica

**Instituto TecnolÃ³gico y de Estudios Superiores de Monterrey**  
*MaestrÃ­a en Inteligencia Artificial Aplicada (MNA)*

- **Curso:** Operaciones de Aprendizaje AutomÃ¡tico
- **Periodo:** Septiembre â€“ Diciembre 2025
- **Equipo:** NÂ° 24

### ğŸ‘¨â€ğŸ« Profesores

| Rol | Nombre |
|-----|--------|
| Titular | Dr. Gerardo RodrÃ­guez HernÃ¡ndez |
| Titular | Mtro. Ricardo Valdez HernÃ¡ndez |
| Asistente | Mtra. MarÃ­a Mylen TreviÃ±o Elizondo |
| Tutor | JosÃ© Ãngel MartÃ­nez Navarro |

---

## ğŸ—‚ï¸ Estructura del Proyecto

Organizado siguiendo **Cookiecutter Data Science** para mÃ¡xima reproducibilidad y claridad:

```
â”œâ”€â”€ LICENSE                 <- Licencia del proyecto
â”œâ”€â”€ Makefile               <- Comandos Ãºtiles (make data, make train, etc.)
â”œâ”€â”€ README.md              <- Este archivo
â”œâ”€â”€ pyproject.toml         <- ConfiguraciÃ³n del proyecto y dependencias
â”‚
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ external           <- Datos de fuentes externas
â”‚   â”œâ”€â”€ interim            <- Datos intermedios transformados
â”‚   â”œâ”€â”€ processed          <- Datasets finales para modelado
â”‚   â”‚   â”œâ”€â”€ turkish_music_emotion_cleaned.csv              (Limpieza inicial)
â”‚   â”‚   â”œâ”€â”€ turkish_music_emotion_v1_original.csv          (400 filas - Baseline)
â”‚   â”‚   â”œâ”€â”€ turkish_music_emotion_v2_cleaned_aligned.csv   (400 filas - ComparaciÃ³n)
â”‚   â”‚   â””â”€â”€ turkish_music_emotion_v2_cleaned_full.csv      (408 filas) â­ RECOMENDADO
â”‚   â””â”€â”€ raw                <- Datos originales inmutables (versionados con DVC)
â”‚       â”œâ”€â”€ turkis_music_emotion_original.csv      (125 KB)
â”‚       â”œâ”€â”€ turkish_music_emotion_modified.csv     (130 KB)
â”‚       â””â”€â”€ .gitignore                             (Git ignora los CSV)
â”‚
â”œâ”€â”€ models                 <- Modelos entrenados y serializados
â”‚   â””â”€â”€ baseline_model.pkl
â”‚
â”œâ”€â”€ notebooks              <- Jupyter notebooks para exploraciÃ³n
â”‚   â”œâ”€â”€ Fase1_equipo24.ipynb
â”‚   â””â”€â”€ NoteBook Testing.ipynb
â”‚   
â”‚   ConvenciÃ³n de nombres: nÃºmero-iniciales-descripciÃ³n
â”‚   Ej: 1.0-hw-exploratory-analysis.ipynb
â”‚
â”œâ”€â”€ reports                <- AnÃ¡lisis generados (HTML, PDF, etc.)
â”‚   â””â”€â”€ figures            <- GrÃ¡ficas y figuras para reportes
â”‚
â”œâ”€â”€ references             <- Diccionarios de datos, manuales, etc.
â”‚
â”œâ”€â”€ requirements.txt       <- Dependencias del proyecto (pip freeze)
â”œâ”€â”€ requirements-optional.txt
â”‚
â”œâ”€â”€ scripts                <- Scripts auxiliares
â”‚   â””â”€â”€ train_baseline.py
â”‚
â”œâ”€â”€ acoustic_ml            <- CÃ³digo fuente del proyecto (mÃ³dulo Python)
â”‚   â”œâ”€â”€ __init__.py        <- Hace de acoustic_ml un mÃ³dulo Python
â”‚   â”œâ”€â”€ config.py          <- ConfiguraciÃ³n y variables globales
â”‚   â”œâ”€â”€ dataset.py         <- Scripts para cargar/generar datos
â”‚   â”œâ”€â”€ features.py        <- Feature engineering
â”‚   â”œâ”€â”€ plots.py           <- Visualizaciones
â”‚   â””â”€â”€ modeling           
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ train.py       <- Entrenamiento de modelos
â”‚       â””â”€â”€ predict.py     <- Inferencia con modelos
â”‚
â”œâ”€â”€ metrics                <- MÃ©tricas del pipeline DVC
â”‚   â””â”€â”€ metrics.json
â”‚
â”œâ”€â”€ mlruns                 <- Experimentos de MLflow
â”œâ”€â”€ mlartifacts            <- Artifacts de MLflow
â”œâ”€â”€ dvcstore               <- Almacenamiento local de DVC
â”‚
â”œâ”€â”€ .dvc                   <- ConfiguraciÃ³n de DVC
â”œâ”€â”€ dvc.yaml               <- DefiniciÃ³n del pipeline DVC
â”œâ”€â”€ dvc.lock               <- Lock file del pipeline
â”œâ”€â”€ data.dvc               <- Metadatos de tracking (versionado en Git)
â”‚
â”œâ”€â”€ .git                   <- Control de versiones Git
â””â”€â”€ .venv                  <- Entorno virtual de Python
```

---

## ğŸ“Š Datasets Disponibles

### Turkish Music Emotion Dataset

Contamos con **4 versiones versionadas con DVC** del dataset de emociones musicales turcas. Cada versiÃ³n representa una etapa evolutiva en nuestro proceso de limpieza y preparaciÃ³n de datos:

---

#### ğŸ”µ VersiÃ³n 0: Limpieza Inicial (turkish_music_emotion_cleaned.csv)

```
ğŸ“ UbicaciÃ³n: data/processed/turkish_music_emotion_cleaned.csv
ğŸ“ Dimensiones: Variable
ğŸ¯ Uso: VersiÃ³n intermedia del primer notebook de limpieza
ğŸ”– Estado: HistÃ³rico (desarrollo temprano)
```

**CaracterÃ­sticas:**
- Primera iteraciÃ³n de limpieza de datos
- Producto del notebook inicial de exploraciÃ³n
- Base para las versiones posteriores mÃ¡s refinadas
- Contiene limpieza bÃ¡sica sin optimizaciones avanzadas

**CuÃ¡ndo usar:**
- ğŸ“š Referencia histÃ³rica del proceso de limpieza
- ğŸ” AuditorÃ­a de evoluciÃ³n del pipeline
- âŒ NO recomendado para entrenar modelos
- âŒ NO recomendado para anÃ¡lisis de producciÃ³n

---

#### ğŸ“¦ VersiÃ³n 1: Original (v1_original)

```
ğŸ“ UbicaciÃ³n: data/processed/turkish_music_emotion_v1_original.csv
ğŸ“ Dimensiones: 400 filas Ã— 21 columnas
ğŸ¯ Uso: Baseline y comparaciones histÃ³ricas
ğŸ”– Estado: Referencia oficial (sin modificaciones)
```

**CaracterÃ­sticas:**
- Dataset crudo sin modificaciones post-descarga
- Incluye todas las inconsistencias originales del dataset fuente
- Punto de referencia oficial para todas las comparaciones
- Ãštil para reproducir anÃ¡lisis iniciales y validar mejoras

**Mejoras respecto a versiÃ³n 0:**
- âœ… Versionado formal con DVC
- âœ… DocumentaciÃ³n estructurada
- âœ… Punto de referencia estable

**CuÃ¡ndo usar:**
- âœ… Baseline para comparar todas las versiones posteriores
- âœ… ValidaciÃ³n de procesos de limpieza aplicados
- âœ… DocumentaciÃ³n de transformaciones histÃ³ricas
- âœ… ReproducciÃ³n de experimentos iniciales del proyecto
- âŒ NO recomendado para entrenar nuevos modelos

---

#### ğŸ”„ VersiÃ³n 2: Limpia Alineada (v2_cleaned_aligned)

```
ğŸ“ UbicaciÃ³n: data/processed/turkish_music_emotion_v2_cleaned_aligned.csv
ğŸ“ Dimensiones: 400 filas Ã— 21 columnas
ğŸ¯ Uso: Comparaciones directas fila por fila con v1
ğŸ”– Estado: ProducciÃ³n (anÃ¡lisis comparativos)
```

**CaracterÃ­sticas:**
- Dataset limpio manteniendo exactamente las 400 filas originales
- Mismo orden y estructura que v1_original para facilitar diffs
- Valores faltantes imputados con estrategias estadÃ­sticas
- Outliers corregidos sin eliminar filas
- Perfecta alineaciÃ³n 1:1 con v1 para anÃ¡lisis de impacto

**Mejoras respecto a v1:**
- âœ… Limpieza sistemÃ¡tica de valores faltantes
- âœ… CorrecciÃ³n de outliers estadÃ­sticos
- âœ… NormalizaciÃ³n de features numÃ©ricas
- âœ… ValidaciÃ³n de consistencia de datos
- âœ… PreservaciÃ³n de estructura original (400 filas)

**CuÃ¡ndo usar:**
- âœ… AnÃ¡lisis de impacto de limpieza (antes/despuÃ©s)
- âœ… ValidaciÃ³n de transformaciones especÃ­ficas fila por fila
- âœ… Reportes que comparan resultados con/sin limpieza
- âœ… AuditorÃ­a de cambios aplicados al dataset
- âš ï¸ Puede usarse para entrenar modelos, pero v2_cleaned_full es superior

---

#### â­ VersiÃ³n 3: Limpia Completa (v2_cleaned_full) **[RECOMENDADO]**

```
ğŸ“ UbicaciÃ³n: data/processed/turkish_music_emotion_v2_cleaned_full.csv
ğŸ“ Dimensiones: 408 filas Ã— 21 columnas
ğŸ¯ Uso: Entrenamiento de modelos de producciÃ³n
ğŸ”– Estado: ProducciÃ³n (versiÃ³n oficial para ML)
```

**CaracterÃ­sticas:**
- Dataset limpio mÃ¡s completo del proyecto (+8 filas adicionales)
- MÃ¡xima calidad y cantidad de datos para Machine Learning
- Duplicados inteligentemente consolidados sin pÃ©rdida de informaciÃ³n
- Outliers corregidos manteniendo variabilidad natural
- Features normalizadas y validadas para ML
- Estrategias avanzadas de imputaciÃ³n de valores faltantes

**Mejoras respecto a v2_aligned:**
- âœ… +8 filas adicionales recuperadas mediante anÃ¡lisis avanzado
- âœ… ConsolidaciÃ³n inteligente de duplicados (preservando informaciÃ³n Ãºnica)
- âœ… ImputaciÃ³n avanzada de valores faltantes (KNN, iterativa)
- âœ… DetecciÃ³n y correcciÃ³n robusta de outliers multivariados
- âœ… ValidaciÃ³n cruzada de consistencia en todas las features
- âœ… MÃ¡xima representatividad del espacio de caracterÃ­sticas

**CuÃ¡ndo usar:**
- âœ… **Entrenamiento de todos los modelos nuevos** (PRIMERA OPCIÃ“N)
- âœ… ExperimentaciÃ³n y bÃºsqueda de hiperparÃ¡metros
- âœ… EvaluaciÃ³n de performance de modelos
- âœ… Pipeline de producciÃ³n y despliegue
- âœ… Benchmarking y competiciones internas
- âœ… ValidaciÃ³n final de modelos antes de producciÃ³n

---

### ğŸ“‹ ComparaciÃ³n RÃ¡pida de Versiones

| VersiÃ³n | Archivo | Filas | Uso Principal | Estado | RecomendaciÃ³n |
|---------|---------|-------|---------------|--------|---------------|
| **v0** | `turkish_music_emotion_cleaned.csv` | Variable | HistÃ³rico (notebook inicial) | ğŸ“š Archivo | âŒ No usar |
| **v1** | `v1_original.csv` | 400 | Baseline sin modificar | ğŸ“– Referencia | Solo comparaciones |
| **v2a** | `v2_cleaned_aligned.csv` | 400 | ComparaciÃ³n directa con v1 | ğŸ”„ AnÃ¡lisis | AnÃ¡lisis de impacto |
| **v3** | `v2_cleaned_full.csv` | 408 | **Entrenamiento ML** | â­ ProducciÃ³n | **âœ… USAR ESTO** |

---

### ğŸ”„ Flujo Evolutivo de Datos

```
ğŸ“¥ Datos Raw (original)
    â†“
ğŸ”§ turkish_music_emotion_cleaned.csv
    â†“ (Primera limpieza - notebook inicial)
ğŸ“¦ v1_original.csv (400 filas)
    â†“ (FormalizaciÃ³n - sin cambios)
ğŸ”„ v2_cleaned_aligned.csv (400 filas)
    â†“ (Limpieza alineada - misma estructura)
â­ v2_cleaned_full.csv (408 filas)
    â†“ (Limpieza completa - optimizaciÃ³n para ML)
ğŸ¤– Modelos de ProducciÃ³n
```

---

### ğŸ“ RecomendaciÃ³n del Equipo

> **Para nuevos experimentos y modelos:** Usa **v2_cleaned_full**  
> Esta versiÃ³n representa nuestro mejor trabajo de ingenierÃ­a de datos y maximiza tanto la cantidad como la calidad de informaciÃ³n disponible para tus modelos.

**Flujo de trabajo recomendado:**

```python
# 1ï¸âƒ£ Carga la versiÃ³n recomendada
from acoustic_ml.dataset import load_processed_data
df = load_processed_data("turkish_music_emotion_v2_cleaned_full.csv")

# 2ï¸âƒ£ Entrena tu modelo
from acoustic_ml.modeling.train import train_model
model = train_model(X_train, y_train)

# 3ï¸âƒ£ EvalÃºa resultados
from acoustic_ml.modeling.evaluate import evaluate_model
metrics = evaluate_model(model, X_test, y_test)

# 4ï¸âƒ£ (Opcional) Compara con versiones anteriores
df_v1 = load_processed_data("turkish_music_emotion_v1_original.csv")
df_v2a = load_processed_data("turkish_music_emotion_v2_cleaned_aligned.csv")
# Analiza diferencias y mejoras obtenidas
```

---

### ğŸ”§ CÃ³mo usar cada versiÃ³n en cÃ³digo

#### Ejemplo 1: Cargar versiÃ³n recomendada

```python
from acoustic_ml.dataset import load_processed_data

# VersiÃ³n recomendada para ML
df_full = load_processed_data("turkish_music_emotion_v2_cleaned_full.csv")
print(f"âœ… Dataset Ã³ptimo cargado: {df_full.shape[0]} filas")
```

#### Ejemplo 2: AnÃ¡lisis comparativo entre versiones

```python
from acoustic_ml.dataset import load_processed_data
import pandas as pd

# Cargar las 3 versiones principales
df_v1 = load_processed_data("turkish_music_emotion_v1_original.csv")
df_v2a = load_processed_data("turkish_music_emotion_v2_cleaned_aligned.csv")
df_v3 = load_processed_data("turkish_music_emotion_v2_cleaned_full.csv")

# Comparar dimensiones
print(f"v1_original:        {df_v1.shape[0]} filas")
print(f"v2_cleaned_aligned: {df_v2a.shape[0]} filas")
print(f"v2_cleaned_full:    {df_v3.shape[0]} filas (+{df_v3.shape[0] - df_v2a.shape[0]} filas)")

# Comparar calidad de datos
print("\nğŸ“Š Valores faltantes por versiÃ³n:")
print(f"v1: {df_v1.isnull().sum().sum()} valores faltantes")
print(f"v2a: {df_v2a.isnull().sum().sum()} valores faltantes")
print(f"v3: {df_v3.isnull().sum().sum()} valores faltantes")
```

#### Ejemplo 3: Uso en notebooks

```python
import pandas as pd
from acoustic_ml.config import PROCESSED_DATA_DIR

# MÃ©todo 1: Usando el mÃ³dulo
from acoustic_ml.dataset import load_processed_data
df = load_processed_data("turkish_music_emotion_v2_cleaned_full.csv")

# MÃ©todo 2: Carga directa con pandas
df = pd.read_csv(PROCESSED_DATA_DIR / "turkish_music_emotion_v2_cleaned_full.csv")

print(f"âœ… Dataset cargado: {df.shape[0]} filas, {df.shape[1]} columnas")
print(f"ğŸ“ UbicaciÃ³n: {PROCESSED_DATA_DIR}")
```

#### Ejemplo 4: ValidaciÃ³n de versiÃ³n correcta

```python
from acoustic_ml.dataset import load_processed_data

def validate_dataset_version(df, expected_rows=408):
    """Valida que estÃ©s usando la versiÃ³n correcta del dataset"""
    if df.shape[0] == expected_rows:
        print(f"âœ… Usando v2_cleaned_full ({expected_rows} filas) - CORRECTO")
        return True
    else:
        print(f"âš ï¸  Advertencia: {df.shape[0]} filas (esperadas: {expected_rows})")
        print("ğŸ’¡ Considera usar 'turkish_music_emotion_v2_cleaned_full.csv'")
        return False

# Uso
df = load_processed_data("turkish_music_emotion_v2_cleaned_full.csv")
validate_dataset_version(df)
```

---

### ğŸ¯ Casos de Uso por VersiÃ³n

#### Cuando usar `turkish_music_emotion_cleaned.csv`:
- ğŸ” AuditorÃ­a histÃ³rica del primer proceso de limpieza
- ğŸ“– DocumentaciÃ³n de evoluciÃ³n del proyecto
- âŒ **NUNCA para entrenamiento de modelos**

#### Cuando usar `v1_original.csv`:
- ğŸ“Š Establecer baseline de performance
- ğŸ“ˆ Medir impacto de limpieza en mÃ©tricas
- ğŸ“ Documentar transformaciones aplicadas
- âš–ï¸ Comparar con estado original del dataset

#### Cuando usar `v2_cleaned_aligned.csv`:
- ğŸ”¬ AnÃ¡lisis fila por fila de cambios aplicados
- ğŸ“Š Estudios de impacto de limpieza especÃ­fica
- ğŸ” Validar que la limpieza preserva estructura
- ğŸ“‰ ComparaciÃ³n directa antes/despuÃ©s (400 filas constantes)

#### Cuando usar `v2_cleaned_full.csv` â­:
- ğŸ¤– **Entrenar TODOS los modelos nuevos**
- ğŸ”§ Ajuste de hiperparÃ¡metros
- ğŸ“Š EvaluaciÃ³n de performance
- ğŸš€ Despliegue en producciÃ³n
- ğŸ† Competiciones y benchmarks
- âœ… Cualquier tarea de Machine Learning

---

### ğŸ“¦ GestiÃ³n de Versiones con DVC

Todas las versiones estÃ¡n trackeadas con DVC y disponibles en S3:

```bash
# Descargar todas las versiones desde S3
dvc pull data/processed

# Verificar versiones disponibles localmente
ls -lh data/processed/

# Output esperado:
# turkish_music_emotion_cleaned.csv              (~XX KB)
# turkish_music_emotion_v1_original.csv          (400 filas)
# turkish_music_emotion_v2_cleaned_aligned.csv   (400 filas)
# turkish_music_emotion_v2_cleaned_full.csv      (408 filas) â­
```

---

### ğŸš¨ Advertencias Importantes

âš ï¸ **NO mezcles versiones en el mismo experimento**
```python
# âŒ MAL: Entrenar con una versiÃ³n y evaluar con otra
model.fit(X_train_v2a, y_train_v2a)
score = model.score(X_test_v3, y_test_v3)  # Â¡Datos incompatibles!

# âœ… BIEN: Usa la misma versiÃ³n en todo el pipeline
df = load_processed_data("turkish_music_emotion_v2_cleaned_full.csv")
X_train, X_test, y_train, y_test = train_test_split(df)
model.fit(X_train, y_train)
score = model.score(X_test, y_test)
```

âš ï¸ **Documenta la versiÃ³n en tus experimentos MLflow**
```python
import mlflow

mlflow.set_tag("dataset_version", "v2_cleaned_full")
mlflow.set_tag("dataset_rows", 408)
mlflow.set_tag("dataset_file", "turkish_music_emotion_v2_cleaned_full.csv")
```

âš ï¸ **MantÃ©n consistencia en notebooks**
```python
# Agrega esto al inicio de cada notebook
DATASET_VERSION = "turkish_music_emotion_v2_cleaned_full.csv"  # â­ RECOMENDADO
print(f"ğŸ“Š Usando dataset: {DATASET_VERSION}")

df = load_processed_data(DATASET_VERSION)
```

---

## ğŸ›  Requisitos Previos

Antes de comenzar, asegÃºrate de tener instalado:

- **Python 3.12**
- **Git**
- **Make** (incluido en macOS/Linux; en Windows usar Git Bash)
- **Credenciales de AWS** configuradas

---

## ğŸš€ InstalaciÃ³n

### 1. Clonar el repositorio

```bash
git clone https://github.com/jrebull/MLOps_Team24.git
cd MLOps_Team24
```

### 2. Configurar entorno virtual

```bash
python -m venv .venv
source .venv/bin/activate  # En Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

### 3. Instalar el mÃ³dulo acoustic_ml en modo desarrollo

```bash
pip install -e .
```

Esto permite importar el mÃ³dulo desde cualquier lugar:
```python
from acoustic_ml.dataset import load_raw_data
from acoustic_ml.modeling.train import train_model
```

### 4. Configurar AWS (CRÃTICO)

Crea o edita el archivo `~/.aws/credentials`:

```ini
[default]
aws_access_key_id = TU_ACCESS_KEY_ID
aws_secret_access_key = TU_SECRET_ACCESS_KEY
region = us-east-1
```

**Verificar configuraciÃ³n:**
```bash
aws s3 ls s3://mlops24-haowei-bucket/
```

### 5. Descargar datos y modelos

```bash
dvc pull
# o usando make:
make pull
```

### 6. Verificar instalaciÃ³n

```bash
# Verificar mÃ³dulo
python -c "import acoustic_ml; print(acoustic_ml.__version__)"

# Verificar datos procesados (deberÃ­as ver las 4 versiones)
ls -lh data/processed/

# Verificar DVC
dvc status
```

---

## ğŸ“¦ GestiÃ³n de Datos (DVC + S3)

### ğŸ¯ Â¿DÃ³nde estÃ¡n los datos?

Los datasets **NO** estÃ¡n en Git (buena prÃ¡ctica de MLOps). EstÃ¡n versionados con **DVC** y almacenados en **AWS S3**.

**Estructura de almacenamiento:**

```
ğŸ“ Local (tu mÃ¡quina):
MLOps_Team24/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ processed/
â”‚   â”‚   â”œâ”€â”€ turkish_music_emotion_cleaned.csv              (HistÃ³rico)
â”‚   â”‚   â”œâ”€â”€ turkish_music_emotion_v1_original.csv          (400 filas)
â”‚   â”‚   â”œâ”€â”€ turkish_music_emotion_v2_cleaned_aligned.csv   (400 filas)
â”‚   â”‚   â””â”€â”€ turkish_music_emotion_v2_cleaned_full.csv      (408 filas) â­
â”‚   â””â”€â”€ raw/
â”‚       â”œâ”€â”€ turkis_music_emotion_original.csv   (125 KB)
â”‚       â”œâ”€â”€ turkish_music_emotion_modified.csv  (130 KB)
â”‚       â””â”€â”€ .gitignore  â† Git ignora los CSV
â””â”€â”€ data.dvc  â† Metadatos de tracking

â˜ï¸ AWS S3 (mlops24-haowei-bucket):
s3://mlops24-haowei-bucket/
â””â”€â”€ files/md5/
    â”œâ”€â”€ ae/5f16bc9e...  â† turkish_music_emotion_modified.csv (130 KB)
    â”œâ”€â”€ fe/09496b4b...  â† turkis_music_emotion_original.csv (125 KB)
    â”œâ”€â”€ xx/xxxxxxxx...  â† v1_original.csv (400 filas)
    â”œâ”€â”€ yy/yyyyyyyy...  â† v2_cleaned_aligned.csv (400 filas)
    â”œâ”€â”€ zz/zzzzzzzz...  â† v2_cleaned_full.csv (408 filas)
    â””â”€â”€ aa/a8c3e8fe...  â† Metadatos de DVC (642 Bytes)

ğŸ™‚ GitHub:
MLOps_Team24/
â””â”€â”€ data.dvc  â† Solo metadatos (~100 bytes, NO los CSV)
```

### ğŸ“¥ Descargar los datos (Primera vez)

Si acabas de clonar el repositorio:

```bash
# 1. Configura AWS (solo la primera vez)
aws configure
# Ingresa: Access Key, Secret Key, Region (us-east-1)

# 2. Verifica conexiÃ³n a S3
aws s3 ls s3://mlops24-haowei-bucket/

# 3. Descarga los datos desde S3
dvc pull
# o usando make:
make pull

# 4. Verifica que llegaron (deberÃ­as ver las 4 versiones)
ls -lh data/processed/
```

### ğŸ“¤ Agregar nuevos datos

Si tienes un nuevo dataset:

```bash
# 1. Coloca tu archivo en data/processed/
cp ~/Downloads/nuevo_dataset.csv data/processed/

# 2. Actualiza el tracking de DVC
dvc add data

# 3. Sube a S3
dvc push
# o: make push

# 4. Commitea los metadatos a Git (NO los CSV)
git add data.dvc data/.gitignore
git commit -m "feat: add nuevo_dataset.csv"
git push
```

### ğŸ”„ Actualizar un dataset existente

Si modificaste un archivo de datos:

```bash
# 1. Edita tu archivo
vim data/processed/turkish_music_emotion_v2_cleaned_full.csv

# 2. Actualiza DVC (detecta el cambio automÃ¡ticamente)
dvc add data

# 3. Sube la nueva versiÃ³n a S3
dvc push

# 4. Commitea el cambio de metadatos
git add data.dvc
git commit -m "feat: update v2_cleaned_full with improved imputation"
git push
```

### â®ï¸ Volver a una versiÃ³n anterior

```bash
# 1. Encuentra el commit donde estaba la versiÃ³n que quieres
git log --oneline data.dvc

# 2. Vuelve a ese commit
git checkout <commit_hash> data.dvc

# 3. Descarga esa versiÃ³n desde S3
dvc checkout

# 4. Si quieres quedarte con esta versiÃ³n:
git add data.dvc
git commit -m "revert: rollback to previous dataset version"
git push
```

### ğŸ” Verificar estado de los datos

```bash
# Ver si tus datos estÃ¡n sincronizados con S3
dvc status

# Ver configuraciÃ³n de remotes
dvc remote list

# Ver quÃ© archivos trackea DVC
cat data.dvc
```

### ğŸŒ Ver datos en AWS Console

Accede visualmente a tus datos:

1. Ve a: **https://s3.console.aws.amazon.com/s3/buckets/mlops24-haowei-bucket**
2. Navega a: `files/` â†’ `md5/`
3. VerÃ¡s carpetas con tus datasets (almacenados por hash MD5)

### ğŸš¨ Problemas comunes

**Problema:** `dvc pull` falla con error de AWS
```bash
# SoluciÃ³n: Verifica tus credenciales
aws s3 ls s3://mlops24-haowei-bucket/
# Si falla, reconfigura:
aws configure
```

**Problema:** "Cache is missing" o archivos no se descargan
```bash
# SoluciÃ³n: Fuerza la descarga
dvc pull -f
```

### ğŸ“‹ Comandos de referencia rÃ¡pida

```bash
# Descargar datos desde S3
dvc pull          # Usando DVC
make pull         # Usando Makefile

# Subir datos a S3
dvc push          # Usando DVC
make push         # Usando Makefile

# Ver estado de sincronizaciÃ³n
dvc status        # Estado actual
make status       # Usando Makefile

# Verificar configuraciÃ³n
dvc remote list   # Lista remotes configurados
dvc config --list # ConfiguraciÃ³n completa de DVC
```

---

## ğŸ’» Uso

### ğŸ› ï¸ Usando el Makefile

Este repo incluye un `Makefile` con comandos cortos para las tareas comunes.

#### Comandos disponibles

```bash
# 1) Configurar entorno y dependencias
make setup

# 2) Abrir Jupyter Lab
make jupyter

# 3) Levantar MLflow en http://127.0.0.1:5001
make mlflow

# 4) Reproducir pipeline (solo si hubo cambios)
make reproduce

# 5) Forzar etapa de entrenamiento (nuevo run en MLflow)
make train

# 6) Ver mÃ©tricas actuales y diferencias
make metrics
make diff

# 7) Sincronizar artefactos con el remoto DVC (S3)
make pull
make push

# 8) Limpiar el entorno local
make clean
make clean-caches

# 9) Exportar dependencias actuales
make freeze

# 10) Verificar sincronizaciÃ³n antes de trabajar
make verify-sync

# 11) Muestra si hay datos desactualizados
make status
```

### ğŸ Usando el MÃ³dulo acoustic_ml

El proyecto estÃ¡ organizado como un mÃ³dulo Python instalable. Ejemplos de uso:

#### Cargar datos

```python
from acoustic_ml.dataset import load_processed_data

# Cargar versiÃ³n recomendada para ML (â­ RECOMENDADO)
df = load_processed_data("turkish_music_emotion_v2_cleaned_full.csv")
print(f"âœ… Dataset Ã³ptimo cargado: {df.shape}")

# Cargar otras versiones para comparaciÃ³n
df_original = load_processed_data("turkish_music_emotion_v1_original.csv")
df_aligned = load_processed_data("turkish_music_emotion_v2_cleaned_aligned.csv")

# Comparar dimensiones
print(f"\nğŸ“Š ComparaciÃ³n de versiones:")
print(f"v1_original:        {df_original.shape[0]} filas")
print(f"v2_cleaned_aligned: {df_aligned.shape[0]} filas")
print(f"v2_cleaned_full:    {df.shape[0]} filas (+{df.shape[0] - df_aligned.shape[0]} adicionales)")
```

#### Feature Engineering

```python
from acoustic_ml.features import create_features, select_features

# Crear features adicionales
df_with_features = create_features(df)

# Seleccionar features especÃ­ficas
features = ['tempo', 'energy', 'valence']
df_selected = select_features(df_with_features, features)
```

#### Entrenar modelos

```python
from acoustic_ml.modeling.train import train_model
import mlflow

# Entrenar modelo con versiÃ³n recomendada
# (registra automÃ¡ticamente en MLflow)
with mlflow.start_run():
    # Documentar versiÃ³n de dataset
    mlflow.set_tag("dataset_version", "v2_cleaned_full")
    mlflow.set_tag("dataset_rows", len(X_train))
    
    # Entrenar
    model = train_model(X_train, y_train)
```

#### Hacer predicciones

```python
from acoustic_ml.modeling.predict import load_model, predict

# Cargar modelo entrenado
model = load_model("baseline_model.pkl")

# Predecir
predictions = predict(model, X_test)
```

### Trabajar con Notebooks

**Jupyter Lab:**
```bash
jupyter-lab
# o usando make:
make jupyter
```

**Importar mÃ³dulo en notebooks:**
```python
from acoustic_ml.dataset import load_processed_data
from acoustic_ml.config import PROCESSED_DATA_DIR

# â­ Usar versiÃ³n recomendada
DATASET_VERSION = "turkish_music_emotion_v2_cleaned_full.csv"
df = load_processed_data(DATASET_VERSION)

print(f"ğŸ“Š Dataset: {DATASET_VERSION}")
print(f"ğŸ“ Dimensiones: {df.shape[0]} filas, {df.shape[1]} columnas")
print(f"ğŸ“ UbicaciÃ³n: {PROCESSED_DATA_DIR}")
```

### Tracking de Experimentos

Inicia el servidor MLflow:

```bash
mlflow ui --port 5001
# o usando make:
make mlflow
```

Accede a la interfaz en: **http://127.0.0.1:5001**

### Pipeline DVC

**Ejecutar el pipeline completo:**
```bash
dvc repro
# o usando make:
make reproduce
```

**Ver mÃ©tricas actuales:**
```bash
dvc metrics show
# o usando make:
make metrics
```

**Comparar mÃ©tricas entre commits:**
```bash
dvc metrics diff
# o usando make:
make diff
```

---

## âœ… VerificaciÃ³n RÃ¡pida antes de Trabajar

Usa el `Makefile` para confirmar que tu repo estÃ¡ **limpio**, **sincronizado** y listo:

```bash
make verify-sync
```

**QuÃ© valida:**
- âœ” Ãrbol de trabajo limpio (sin cambios sin commit)
- âœ” HEAD == origin/<rama> (sin ahead/behind)
- âœ” Datos sincronizados con S3

---

## ğŸ”„ Reproducibilidad de Entornos

Exporta dependencias despuÃ©s de instalar paquetes nuevos:

```bash
make freeze
# luego:
git add requirements.txt
git commit -m "chore: update dependencies"
git push
```

ReconstrucciÃ³n rÃ¡pida en cualquier mÃ¡quina:

```bash
python -m venv .venv
source .venv/bin/activate   # Windows: .venv\Scripts\activate
pip install -r requirements.txt
pip install -e .  # Instalar mÃ³dulo acoustic_ml
```

---

## ğŸ““ Buenas PrÃ¡cticas con Notebooks

Instala hooks para limpiar outputs y tener diffs legibles:

```bash
make nb-hooks
```

**Beneficios:**
- `nbstripout` limpia salidas/celdas ejecutadas al commitear
- `nbdime` muestra diffs de `.ipynb` de forma amigable

**ConvenciÃ³n de nombres para notebooks:**
```
<nÃºmero>.<versiÃ³n>-<iniciales>-<descripciÃ³n-corta>.ipynb

Ejemplos:
- 1.0-jrs-initial-data-exploration.ipynb
- 2.0-hw-feature-engineering.ipynb
- 3.1-sc-model-evaluation.ipynb
```

**Template recomendado para notebooks:**
```python
# === CONFIGURACIÃ“N INICIAL ===
import pandas as pd
from acoustic_ml.dataset import load_processed_data
from acoustic_ml.config import PROCESSED_DATA_DIR

# â­ Definir versiÃ³n de dataset a usar
DATASET_VERSION = "turkish_music_emotion_v2_cleaned_full.csv"

print(f"ğŸ“Š Notebook: [Nombre del notebook]")
print(f"ğŸ“… Fecha: {pd.Timestamp.now().strftime('%Y-%m-%d')}")
print(f"ğŸ“¦ Dataset: {DATASET_VERSION}")

# Cargar datos
df = load_processed_data(DATASET_VERSION)
print(f"âœ… Datos cargados: {df.shape}")
```

---

## ğŸ³ Docker Compose

```
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ config.env
â”œâ”€â”€ mlartifacts/           # Almacena los artefactos de MLflow 
â”œâ”€â”€ ml_pipeline.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ acoustic_ml/           # MÃ³dulo del proyecto
â””â”€â”€ .venv/                 # Entorno virtual local
```

### âš™ï¸ Archivos requeridos
âœ… config.env

### âš™ï¸ Comandos de uso

**ğŸ”§ Levantar servicios**

```bash
docker-compose --env-file config.env up -d --build
```

MinIO (Consola): http://localhost:9001

**ğŸ›‘ Detener los servicios**
```bash
docker-compose down
```

**ğŸ”„ Reiniciar**
```bash
docker-compose --env-file config.env up -d --build
```

---

## ğŸ§¹ Limpieza Local

Si necesitas borrar cachÃ©s locales (sin afectar Git):

```bash
make clean-caches
```

Limpieza completa (incluye artefactos de MLflow/DVC):
```bash
make clean
```

---

## ğŸ— Arquitectura del Pipeline

```mermaid
flowchart TD
    A[ğŸ“‚ data/raw/*.csv] -->|limpieza inicial| B[ğŸ”µ turkish_music_emotion_cleaned.csv]
    B -->|formalizaciÃ³n| C[ğŸ“¦ v1_original.csv - 400 filas]
    C -->|limpieza alineada| D[ğŸ”„ v2_cleaned_aligned.csv - 400 filas]
    C -->|limpieza completa| E[â­ v2_cleaned_full.csv - 408 filas]
    
    E -->|DVC tracking| F[â˜ï¸ AWS S3]
    E -->|entrenamiento| G[âš™ï¸ acoustic_ml/modeling/train.py]
    G --> H[ğŸ¤– models/baseline_model.pkl]
    G --> I[ğŸ“ˆ metrics/metrics.json]
    H -->|log_model| J[MLflow Tracking]
    I -->|log_metrics| J
    J --> K[ğŸ–¥ MLflow UI :5001]
    
    style E fill:#90EE90,stroke:#228B22,stroke-width:3px
    style A fill:#e1f5ff
    style F fill:#fff4e1
    style H fill:#e8f5e9
    style K fill:#f3e5f5
```

**Flujo de trabajo:**

1. ğŸ“¥ Datos crudos en `data/raw/` (versionados con DVC)
2. ğŸ”§ Primera limpieza â†’ `turkish_music_emotion_cleaned.csv` (histÃ³rico)
3. ğŸ“¦ FormalizaciÃ³n â†’ `v1_original.csv` (400 filas, baseline)
4. ğŸ”„ Limpieza alineada â†’ `v2_cleaned_aligned.csv` (400 filas, comparaciÃ³n)
5. â­ Limpieza completa â†’ `v2_cleaned_full.csv` (408 filas, **PRODUCCIÃ“N**)
6. â˜ï¸ Almacenamiento en S3 para colaboraciÃ³n
7. âš™ï¸ El mÃ³dulo `acoustic_ml` entrena modelos con v2_cleaned_full
8. ğŸ¤– Modelos entrenados se guardan en `models/`
9. ğŸ“ˆ Experimentos y artefactos se registran en MLflow
10. ğŸ“Š MÃ©tricas se trackean con DVC
11. âœ… Todo es reproducible y trazable

---

## ğŸ¤ ContribuciÃ³n

### Flujo de trabajo

1. **Verificar sincronizaciÃ³n:**
   ```bash
   make verify-sync
   ```

2. **Crear una nueva rama:**
   ```bash
   git checkout -b feat/nombre-descriptivo
   ```

3. **Realizar cambios:**
   
   **Si modificas cÃ³digo Python:**
   ```bash
   # Edita archivos en acoustic_ml/
   vim acoustic_ml/features.py
   
   # Los cambios estÃ¡n disponibles inmediatamente (instalaciÃ³n en modo -e)
   ```

   **Si modificas datos:**
   ```bash
   dvc add data
   git add data.dvc data/.gitignore
   dvc push
   ```

   **Si instalaste paquetes:**
   ```bash
   make freeze
   git add requirements.txt
   ```

4. **Commitear cambios:**
   ```bash
   git add .
   git commit -m "feat: descripciÃ³n clara del cambio"
   ```

5. **Subir cambios:**
   ```bash
   git push origin feat/nombre-descriptivo
   dvc push  # o: make push
   ```

6. **Crear Pull Request** a la rama `main`

### Buenas prÃ¡cticas

- âœ… Ejecuta `make verify-sync` antes de comenzar a trabajar
- âœ… **SIEMPRE usa `v2_cleaned_full.csv` para entrenar nuevos modelos**
- âœ… Documenta la versiÃ³n de dataset en MLflow tags
- âœ… Ejecuta `dvc status` para verificar estado de datos
- âœ… Ejecuta `make reproduce` antes de hacer commit
- âœ… Documenta tus experimentos en MLflow
- âœ… Escribe mensajes de commit descriptivos ([Conventional Commits](https://www.conventionalcommits.org/))
- âœ… MantÃ©n el cÃ³digo limpio y con docstrings
- âœ… Usa `make nb-hooks` para configurar hooks de notebooks
- âœ… Escribe cÃ³digo en el mÃ³dulo `acoustic_ml/`, no en notebooks
- âœ… Siempre haz `dvc push` despuÃ©s de modificar datos

---

## ğŸ‘¥ **Equipo de Desarrollo**

<div align="center">

<table style="width:100%; border:none;">
  <tr>
    <td align="center" style="border:none; padding:20px 10px;">
      <img src="https://iili.io/Kw90kmB.png" alt="David Cruz BeltrÃ¡n" width="160" style="border-radius: 50%; border: 5px solid #667eea; box-shadow: 0 8px 16px rgba(102, 126, 234, 0.4);"/>
      <h3>David Cruz BeltrÃ¡n</h3>
      <img src="https://img.shields.io/badge/ID-A01360416-667eea?style=for-the-badge" alt="MatrÃ­cula"/>
      <p><strong>ğŸ”§ Software Engineer</strong><br/>
      <em>Data Pipeline & Versioning</em></p>
    </td>
    <td align="center" style="border:none; padding:20px 10px;">
      <img src="https://iili.io/KuvsGKx.png" alt="Javier Augusto Rebull Saucedo" width="160" style="border-radius: 50%; border: 5px solid #764ba2; box-shadow: 0 8px 16px rgba(118, 75, 162, 0.4);"/>
      <h3>Javier Augusto Rebull Saucedo</h3>
      <img src="https://img.shields.io/badge/ID-A01795838-764ba2?style=for-the-badge" alt="MatrÃ­cula"/>
      <p><strong>âš™ï¸ SRE / Data Engineer</strong><br/>
      <em>DevOps & Infrastructure</em></p>
    </td>
    <td align="center" style="border:none; padding:20px 10px;">
      <img src="https://iili.io/Kw91d74.png" alt="Sandra Luz Cervantes Espinoza" width="160" style="border-radius: 50%; border: 5px solid #f093fb; box-shadow: 0 8px 16px rgba(240, 147, 251, 0.4);"/>
      <h3>Sandra Luz Cervantes Espinoza</h3>
      <img src="https://img.shields.io/badge/ID-A01796937-f093fb?style=for-the-badge" alt="MatrÃ­cula"/>
      <p><strong>ğŸ¤– ML Engineer / Data Scientist</strong><br/>
      <em>Model Development & Analysis</em></p>
    </td>
  </tr>
</table>

</div>

---

<div align="center">

**â­ Si este proyecto te resulta Ãºtil, considera darle una estrella**

Desarrollado con â¤ï¸ por el Equipo 24 | Estructura basada en [Cookiecutter Data Science](https://drivendata.github.io/cookiecutter-data-science/)

</div>
