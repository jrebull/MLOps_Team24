# ğŸµ Acoustic ML - Music Emotion Recognition

<div align="center">

**MLOps Team 24 - Proyecto de reconocimiento de emociones musicales**

[![Python](https://img.shields.io/badge/Python-3.12-blue.svg)](https://www.python.org/downloads/)
[![MLflow](https://img.shields.io/badge/MLflow-Tracking-0194E2?logo=mlflow)](https://mlflow.org/)
[![DVC](https://img.shields.io/badge/DVC-Data%20Versioning-945DD6?logo=dvc)](https://dvc.org/)
[![AWS S3](https://img.shields.io/badge/AWS-S3-FF9900?logo=amazon-aws)](https://aws.amazon.com/s3/)

<!-- Badges -->
[![verify-sync](https://img.shields.io/badge/verify--sync-make-blue?logo=gnu&logoColor=white)](#verificaciÃ³n-rÃ¡pida-antes-de-trabajar)
[![dependencies](https://img.shields.io/badge/deps-requirements.txt-informational?logo=python&logoColor=white)](#reproducibilidad-de-entornos)
[![notebooks](https://img.shields.io/badge/notebooks-clean%20outputs-success?logo=jupyter&logoColor=white)](#buenas-prÃ¡cticas-con-notebooks)

</div>

---

## ğŸ“‹ Tabla de Contenidos

- [Sobre el Proyecto](#-sobre-el-proyecto)
- [InformaciÃ³n AcadÃ©mica](#-informaciÃ³n-acadÃ©mica)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [Requisitos Previos](#-requisitos-previos)
- [InstalaciÃ³n](#-instalaciÃ³n)
- [GestiÃ³n de Datos (DVC + S3)](#-gestiÃ³n-de-datos-dvc--s3)
- [Uso del MÃ³dulo en Notebooks](#-uso-del-mÃ³dulo-en-notebooks)
- [Uso](#-uso)
  - [Usando el Makefile](#%EF%B8%8F-usando-el-makefile)
  - [Usando el MÃ³dulo acoustic_ml](#-usando-el-mÃ³dulo-acoustic_ml)
  - [Trabajar con Notebooks](#trabajar-con-notebooks)
  - [Tracking de Experimentos](#tracking-de-experimentos)
  - [Pipeline DVC](#pipeline-dvc)
- [VerificaciÃ³n RÃ¡pida antes de Trabajar](#-verificaciÃ³n-rÃ¡pida-antes-de-trabajar)
- [Reproducibilidad de Entornos](#-reproducibilidad-de-entornos)
- [Buenas PrÃ¡cticas con Notebooks](#-buenas-prÃ¡cticas-con-notebooks)
- [Limpieza Local](#-limpieza-local)
- [Arquitectura del Pipeline](#-arquitectura-del-pipeline)
- [ContribuciÃ³n](#-contribuciÃ³n)
- [Equipo](#-equipo)

---

## ğŸ¯ Sobre el Proyecto

Este repositorio contiene la implementaciÃ³n completa de un sistema MLOps para reconocimiento de emociones en mÃºsica, siguiendo las mejores prÃ¡cticas de la industria con la estructura **Cookiecutter Data Science**. El proyecto integra:

- ğŸ“Š **Versionado de datos** con DVC
- ğŸ”„ **Pipelines reproducibles** automatizados
- ğŸ“ˆ **Tracking de experimentos** con MLflow
- â˜ï¸ **Almacenamiento en la nube** (AWS S3)
- ğŸ¤– **Modelos de Machine Learning** versionados
- ğŸ—ï¸ **Estructura modular** siguiendo estÃ¡ndares de la industria

---

## ğŸ“˜ InformaciÃ³n AcadÃ©mica

**Instituto TecnolÃ³gico y de Estudios Superiores de Monterrey**  
*MaestrÃ­a en Inteligencia Artificial Aplicada (MNA)*

- **Curso:** Operaciones de Aprendizaje AutomÃ¡tico
- **Periodo:** Septiembre â€“ Diciembre 2025
- **Equipo:** NÂ° 24

### ğŸ‘¨â€ğŸ« Profesores

| Rol | Nombre |
|-----|--------|
| Titular | Dr. Gerardo RodrÃ­guez HernÃ¡ndez |
| Titular | Mtro. Ricardo Valdez HernÃ¡ndez |
| Asistente | Mtra. MarÃ­a Mylen TreviÃ±o Elizondo |
| Tutor | JosÃ© Ãngel MartÃ­nez Navarro |

---

## ğŸ—ï¸ Estructura del Proyecto

Organizado siguiendo **Cookiecutter Data Science** para mÃ¡xima reproducibilidad y claridad:

```
â”œâ”€â”€ LICENSE                 <- Licencia del proyecto
â”œâ”€â”€ Makefile               <- Comandos Ãºtiles (make data, make train, etc.)
â”œâ”€â”€ README.md              <- Este archivo
â”œâ”€â”€ pyproject.toml         <- ConfiguraciÃ³n del proyecto y dependencias
â”‚
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ external           <- Datos de fuentes externas
â”‚   â”œâ”€â”€ interim            <- Datos intermedios transformados
â”‚   â”œâ”€â”€ processed          <- Datasets finales para modelado
â”‚   â””â”€â”€ raw                <- Datos originales inmutables (versionados con DVC)
â”‚       â”œâ”€â”€ turkis_music_emotion_original.csv      (125 KB)
â”‚       â”œâ”€â”€ turkish_music_emotion_modified.csv     (130 KB)
â”‚       â””â”€â”€ .gitignore                             (Git ignora los CSV)
â”‚
â”œâ”€â”€ models                 <- Modelos entrenados y serializados
â”‚   â””â”€â”€ baseline_model.pkl
â”‚
â”œâ”€â”€ notebooks              <- Jupyter notebooks para exploraciÃ³n
â”‚   â”œâ”€â”€ Fase1_equipo24.ipynb
â”‚   â””â”€â”€ NoteBook Testing.ipynb
â”‚   
â”‚   ConvenciÃ³n de nombres: nÃºmero-iniciales-descripciÃ³n
â”‚   Ej: 1.0-hw-exploratory-analysis.ipynb
â”‚
â”œâ”€â”€ reports                <- AnÃ¡lisis generados (HTML, PDF, etc.)
â”‚   â””â”€â”€ figures            <- GrÃ¡ficas y figuras para reportes
â”‚
â”œâ”€â”€ references             <- Diccionarios de datos, manuales, etc.
â”‚
â”œâ”€â”€ requirements.txt       <- Dependencias del proyecto (pip freeze)
â”œâ”€â”€ requirements-optional.txt
â”‚
â”œâ”€â”€ scripts                <- Scripts auxiliares
â”‚   â””â”€â”€ train_baseline.py
â”‚
â”œâ”€â”€ acoustic_ml            <- CÃ³digo fuente del proyecto (mÃ³dulo Python)
â”‚   â”œâ”€â”€ __init__.py        <- Hace de acoustic_ml un mÃ³dulo Python
â”‚   â”œâ”€â”€ config.py          <- ConfiguraciÃ³n y variables globales
â”‚   â”œâ”€â”€ dataset.py         <- Scripts para cargar/generar datos
â”‚   â”œâ”€â”€ features.py        <- Feature engineering
â”‚   â”œâ”€â”€ plots.py           <- Visualizaciones
â”‚   â””â”€â”€ modeling           
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ train.py       <- Entrenamiento de modelos
â”‚       â””â”€â”€ predict.py     <- Inferencia con modelos
â”‚
â”œâ”€â”€ metrics                <- MÃ©tricas del pipeline DVC
â”‚   â””â”€â”€ metrics.json
â”‚
â”œâ”€â”€ mlruns                 <- Experimentos de MLflow
â”œâ”€â”€ mlartifacts            <- Artifacts de MLflow
â”œâ”€â”€ dvcstore               <- Almacenamiento local de DVC
â”‚
â”œâ”€â”€ .dvc                   <- ConfiguraciÃ³n de DVC
â”œâ”€â”€ dvc.yaml               <- DefiniciÃ³n del pipeline DVC
â”œâ”€â”€ dvc.lock               <- Lock file del pipeline
â”œâ”€â”€ data.dvc               <- Metadatos de tracking (versionado en Git)
â”‚
â”œâ”€â”€ .git                   <- Control de versiones Git
â””â”€â”€ .venv                  <- Entorno virtual de Python
```

---

## ğŸ›  Requisitos Previos

Antes de comenzar, asegÃºrate de tener instalado:

- **Python 3.12**
- **Git**
- **Make** (incluido en macOS/Linux; en Windows usar Git Bash)
- **Credenciales de AWS** configuradas

---

## ğŸš€ InstalaciÃ³n

### 1. Clonar el repositorio

```bash
git clone https://github.com/jrebull/MLOps_Team24.git
cd MLOps_Team24
```

### 2. Configurar entorno virtual

```bash
python -m venv .venv
source .venv/bin/activate  # En Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

### 3. Instalar el mÃ³dulo acoustic_ml en modo desarrollo

```bash
pip install -e .
```

Esto permite importar el mÃ³dulo desde cualquier lugar:
```python
from acoustic_ml import load_turkish_modified
from acoustic_ml.modeling.train import train_model
```

### 4. Configurar AWS

Crea o edita el archivo `~/.aws/credentials`:

```ini
[default]
aws_access_key_id = TU_ACCESS_KEY_ID
aws_secret_access_key = TU_SECRET_ACCESS_KEY
region = us-east-1
```

### 5. Descargar datos y modelos

```bash
dvc pull
# o usando make:
make pull
```

---

## ğŸ“¦ GestiÃ³n de Datos (DVC + S3)

### ğŸ¯ Â¿DÃ³nde estÃ¡n los datos?

Los datasets **NO** estÃ¡n en Git (buena prÃ¡ctica de MLOps). EstÃ¡n versionados con **DVC** y almacenados en **AWS S3**.

**Estructura de almacenamiento:**

```
ğŸ“ Local (tu mÃ¡quina):
MLOps_Team24/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/
â”‚       â”œâ”€â”€ turkis_music_emotion_original.csv   (125 KB)
â”‚       â”œâ”€â”€ turkish_music_emotion_modified.csv  (130 KB)
â”‚       â””â”€â”€ .gitignore  â† Git ignora los CSV
â””â”€â”€ data.dvc  â† Metadatos de tracking

â˜ï¸ AWS S3 (mlops24-haowei-bucket):
s3://mlops24-haowei-bucket/
â””â”€â”€ files/md5/
    â”œâ”€â”€ ae/5f16bc9e...  â† turkish_music_emotion_modified.csv (130 KB)
    â”œâ”€â”€ fe/09496b4b...  â† turkis_music_emotion_original.csv (125 KB)
    â””â”€â”€ aa/a8c3e8fe...  â† Metadatos de DVC (642 Bytes)

ğŸ™ GitHub:
MLOps_Team24/
â””â”€â”€ data.dvc  â† Solo metadatos (~100 bytes, NO los CSV)
```

### ğŸ“¥ Descargar los datos (Primera vez)

Si acabas de clonar el repositorio:

```bash
# 1. Configura AWS (solo la primera vez)
aws configure
# Ingresa: Access Key, Secret Key, Region (us-east-1)

# 2. Verifica conexiÃ³n a S3
aws s3 ls s3://mlops24-haowei-bucket/

# 3. Descarga los datos desde S3
dvc pull
# o usando make:
make pull

# 4. Verifica que llegaron
ls -lh data/raw/
# DeberÃ­as ver:
# turkis_music_emotion_original.csv   (125 KB)
# turkish_music_emotion_modified.csv  (130 KB)
```

### ğŸ“¤ Agregar nuevos datos

Si tienes un nuevo dataset:

```bash
# 1. Coloca tu archivo en data/raw/
cp ~/Downloads/nuevo_dataset.csv data/raw/

# 2. Actualiza el tracking de DVC
dvc add data

# 3. Sube a S3
dvc push
# o: make push

# 4. Commitea los metadatos a Git (NO los CSV)
git add data.dvc data/.gitignore
git commit -m "feat: add nuevo_dataset.csv"
git push
```

### ğŸ”„ Actualizar un dataset existente

Si modificaste un archivo de datos:

```bash
# 1. Edita tu archivo
vim data/raw/turkish_music_emotion_modified.csv

# 2. Actualiza DVC (detecta el cambio automÃ¡ticamente)
dvc add data

# 3. Sube la nueva versiÃ³n a S3
dvc push

# 4. Commitea el cambio de metadatos
git add data.dvc
git commit -m "feat: update turkish dataset with new features"
git push
```

### â®ï¸ Volver a una versiÃ³n anterior

```bash
# 1. Encuentra el commit donde estaba la versiÃ³n que quieres
git log --oneline data.dvc

# 2. Vuelve a ese commit
git checkout <commit-hash> data.dvc

# 3. Descarga esa versiÃ³n desde S3
dvc checkout

# 4. Si quieres quedarte con esta versiÃ³n:
git add data.dvc
git commit -m "revert: rollback to previous dataset version"
git push
```

### ğŸ” Verificar estado de los datos

```bash
# Ver si tus datos estÃ¡n sincronizados con S3
dvc status
# Output esperado: "Data and pipelines are up to date."

# Ver configuraciÃ³n de remotes
dvc remote list
# Output: s3store  s3://mlops24-haowei-bucket (default)

# Ver quÃ© archivos trackea DVC
cat data.dvc
```

### ğŸŒ Ver datos en AWS Console

Accede visualmente a tus datos:

1. Ve a: **https://s3.console.aws.amazon.com/s3/buckets/mlops24-haowei-bucket**
2. Navega a: `files/` â†’ `md5/`
3. VerÃ¡s carpetas con tus datasets (almacenados por hash MD5)

### ğŸ“‹ Comandos de referencia rÃ¡pida

```bash
# Descargar datos desde S3
dvc pull          # Usando DVC
make pull         # Usando Makefile

# Subir datos a S3
dvc push          # Usando DVC
make push         # Usando Makefile

# Ver estado de sincronizaciÃ³n
dvc status        # Estado actual
make status       # Usando Makefile

# Verificar configuraciÃ³n
dvc remote list   # Lista remotes configurados
dvc config --list # ConfiguraciÃ³n completa de DVC
```

---

## ğŸ““ Uso del MÃ³dulo en Notebooks

El mÃ³dulo `acoustic_ml` proporciona funciones listas para usar en tus notebooks, siguiendo las mejores prÃ¡cticas de MLOps.

### ğŸ¯ Funciones Disponibles

```python
from acoustic_ml import (
    # Cargar datos
    load_turkish_original,      # Dataset original
    load_turkish_modified,      # Dataset modificado
    load_raw_data,              # Cargar cualquier CSV de data/raw/
    
    # Guardar datos
    save_processed_data,        # Guardar en data/processed/
    
    # Utilidades
    get_dataset_info,           # Info detallada del dataset
    
    # ConfiguraciÃ³n
    RAW_DATA_DIR,               # Path a data/raw/
    PROCESSED_DATA_DIR,         # Path a data/processed/
    MODELS_DIR,                 # Path a models/
    RANDOM_STATE,               # Seed (42) para reproducibilidad
)
```

### ğŸ“ Template para Notebooks

Usa este template en tus notebooks de Jupyter/VSCode:

#### **CELDA 1: Setup e Imports**

```python
# ============================================
# SETUP: Imports y ConfiguraciÃ³n
# ============================================
import subprocess
import pandas as pd
import numpy as np

# Importar mÃ³dulo del proyecto
from acoustic_ml import (
    load_turkish_modified,
    get_dataset_info,
    RAW_DATA_DIR,
    RANDOM_STATE
)

# ConfiguraciÃ³n
np.random.seed(RANDOM_STATE)
pd.set_option('display.max_columns', None)

print(f"ğŸ“ Directorio de datos: {RAW_DATA_DIR}")
print(f"ğŸ² Random state: {RANDOM_STATE}")
```

#### **CELDA 2: Descarga de Datos**

```python
# ============================================
# DESCARGA: Sincronizar datos desde S3
# ============================================
print("ğŸ“¥ Sincronizando datos desde S3 con DVC...")
print("=" * 60)

try:
    result = subprocess.run(
        ['dvc', 'pull'],
        check=True,
        capture_output=True,
        text=True
    )
    
    if result.stdout:
        print(result.stdout)
    
    print("âœ… Datos sincronizados correctamente")
    
except subprocess.CalledProcessError as e:
    print("âš ï¸  Error al ejecutar DVC pull:")
    print(e.stderr if e.stderr else str(e))
    print("\nğŸ’¡ Ejecuta en terminal: dvc pull")
```

#### **CELDA 3: Cargar y Explorar Datos**

```python
# ============================================
# CARGA: Cargar dataset
# ============================================
# Cargar dataset usando el mÃ³dulo
df = load_turkish_modified()

# Mostrar informaciÃ³n detallada
get_dataset_info(df)

# Primeras filas
print("\nğŸ“Š Primeras 5 filas:")
display(df.head())
```

### âœ¨ Ejemplo Completo

```python
# ============================================
# EJEMPLO: Pipeline completo de carga
# ============================================
import subprocess
from acoustic_ml import load_turkish_modified, get_dataset_info, save_processed_data

# 1. Descargar datos
subprocess.run(['dvc', 'pull'], check=True)

# 2. Cargar
df = load_turkish_modified()
get_dataset_info(df)

# 3. Procesar (ejemplo)
df_processed = df.dropna()
df_processed = df_processed.reset_index(drop=True)

# 4. Guardar procesado
save_processed_data(df_processed, 'turkish_cleaned.csv')

print(f"âœ… Pipeline completado: {df_processed.shape}")
```

### ğŸ“ Ventajas de usar el mÃ³dulo

| Sin mÃ³dulo | Con mÃ³dulo `acoustic_ml` |
|-----------|-------------------------|
| `pd.read_csv('../../data/raw/file.csv')` | `load_turkish_modified()` |
| Rutas hardcodeadas | Rutas centralizadas |
| Sin validaciÃ³n | Valida que archivo existe |
| Sin informaciÃ³n | Muestra shape, nulls, etc. |
| CÃ³digo repetitivo | Reutilizable |
| DifÃ­cil de testear | FÃ¡cil de testear |

### ğŸš¨ Troubleshooting

**Error: `ModuleNotFoundError: No module named 'acoustic_ml'`**
```bash
# SoluciÃ³n: Instala el mÃ³dulo
pip install -e .
```

**Error: `FileNotFoundError: Dataset no encontrado`**
```bash
# SoluciÃ³n: Descarga los datos
dvc pull
```

**Error: `ModuleNotFoundError: No module named 'pandas'`**
```bash
# SoluciÃ³n: Instala dependencias
pip install -r requirements.txt
```

---

## ğŸ’» Uso

### ğŸ› ï¸ Usando el Makefile

Este repo incluye un `Makefile` con comandos cortos para las tareas comunes.

#### Comandos disponibles

```bash
# 1) Configurar entorno y dependencias
make setup

# 2) Abrir Jupyter Lab
make jupyter

# 3) Levantar MLflow en http://127.0.0.1:5001
make mlflow

# 4) Reproducir pipeline (solo si hubo cambios)
make reproduce

# 5) Forzar etapa de entrenamiento (nuevo run en MLflow)
make train

# 6) Ver mÃ©tricas actuales y diferencias
make metrics
make diff

# 7) Sincronizar artefactos con el remoto DVC (S3)
make pull
make push

# 8) Limpiar el entorno local
make clean
make clean-caches

# 9) Exportar dependencias actuales
make freeze

# 10) Verificar sincronizaciÃ³n antes de trabajar
make verify-sync

# 11) Muestra si hay datos desactualizados
make status
```

### ğŸ Usando el MÃ³dulo acoustic_ml

El proyecto estÃ¡ organizado como un mÃ³dulo Python instalable. Ejemplos de uso:

#### Cargar datos

```python
from acoustic_ml import load_turkish_modified, save_processed_data

# Cargar dataset
df = load_turkish_modified()

# Procesar y guardar
df_processed = process_data(df)
save_processed_data(df_processed, "features_v1.csv")
```

#### Feature Engineering

```python
from acoustic_ml.features import create_features, select_features

# Crear features adicionales
df_with_features = create_features(df)

# Seleccionar features especÃ­ficas
features = ['tempo', 'energy', 'valence']
df_selected = select_features(df_with_features, features)
```

#### Entrenar modelos

```python
from acoustic_ml.modeling.train import train_model

# Entrenar modelo (registra en MLflow automÃ¡ticamente)
model = train_model(X_train, y_train)
```

#### Hacer predicciones

```python
from acoustic_ml.modeling.predict import load_model, predict

# Cargar modelo entrenado
model = load_model("baseline_model.pkl")

# Predecir
predictions = predict(model, X_test)
```

#### Crear visualizaciones

```python
from acoustic_ml.plots import plot_feature_importance, save_figure

# Crear grÃ¡fica
fig = plot_feature_importance(feature_importance_dict)

# Guardar en reports/figures/
save_figure(fig, "feature_importance.png")
```

### Trabajar con Notebooks

**Jupyter Lab:**
```bash
jupyter-lab
# o usando make:
make jupyter
```

**VSCode:**
```bash
code .
```

### Tracking de Experimentos

Inicia el servidor MLflow:

```bash
mlflow ui --port 5001
# o usando make:
make mlflow
```

Accede a la interfaz en: **http://127.0.0.1:5001**

### Pipeline DVC

**Ejecutar el pipeline completo:**
```bash
dvc repro
# o usando make:
make reproduce
```

**Ver mÃ©tricas actuales:**
```bash
dvc metrics show
# o usando make:
make metrics
```

**Comparar mÃ©tricas entre commits:**
```bash
dvc metrics diff
# o usando make:
make diff
```

---

## âœ… VerificaciÃ³n RÃ¡pida antes de Trabajar

> Usa el `Makefile` para confirmar que tu repo estÃ¡ **limpio**, **sincronizado** y que el notebook principal **no tiene diffs**.

```bash
make verify-sync
# o, si trabajas con otro notebook:
make verify-sync NOTEBOOK=notebooks/tu_notebook.ipynb
```

**QuÃ© valida:**
- âœ“ Ãrbol de trabajo limpio (sin cambios sin commit)
- âœ“ HEAD == origin/<rama> (sin ahead/behind)
- âœ“ El notebook indicado no tiene diferencias locales

Si algo falla, el comando te dirÃ¡ exactamente quÃ© corregir (pull/push/diff).

---

## ğŸ”„ Reproducibilidad de Entornos

Exporta dependencias despuÃ©s de instalar paquetes nuevos:

```bash
make freeze
# luego:
git add requirements.txt
git commit -m "chore: update dependencies"
git push
```

ReconstrucciÃ³n rÃ¡pida en cualquier mÃ¡quina:

```bash
python -m venv .venv
source .venv/bin/activate   # Windows: .venv\Scripts\activate
pip install -r requirements.txt
pip install -e .  # Instalar mÃ³dulo acoustic_ml
```

---

## ğŸ³ Docker compose

```

â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ config.env
â”œâ”€â”€ mlartifacts/           # Almacena los artefactos de MLflow 
â”œâ”€â”€ ml_pipeline.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ acoustic_ml/           # MÃ³dulo del proyecto
â”œâ”€â”€ .venv/                 # Entorno virtual local

```
--- 
âš™ï¸ Archivos requeridos
âœ… config.env

âš™ï¸ Comandos de uso

ğŸ”§ Levantar servicios

```bash
docker-compose --env-file config.env up -d --build
```

MinIO (Consola): http://localhost:9001

ğŸ›‘ Detener los servicios
```bash
docker-compose down
```
ğŸ” Reiniciar 
```bash
docker-compose --env-file config.env up -d --build
```

## ğŸ““ Buenas PrÃ¡cticas con Notebooks

Instala hooks para limpiar outputs y tener diffs legibles:

```bash
make nb-hooks
```

**Beneficios:**
- `nbstripout` limpia salidas/celdas ejecutadas al commitear
- `nbdime` muestra diffs de `.ipynb` de forma amigable

**ConvenciÃ³n de nombres para notebooks:**
```
<nÃºmero>.<versiÃ³n>-<iniciales>-<descripciÃ³n-corta>.ipynb

Ejemplos:
- 1.0-jrs-initial-data-exploration.ipynb
- 2.0-hw-feature-engineering.ipynb
- 3.1-sc-model-evaluation.ipynb
```

**Tip:** Antes de commitear, puedes correr `make verify-sync` para asegurarte de que todo estÃ¡ en orden.

---

## ğŸ§¹ Limpieza Local

Si necesitas borrar cachÃ©s locales (sin afectar Git):

```bash
make clean-caches
```

Esto elimina `__pycache__`, `.ipynb_checkpoints` y archivos temporales solo en tu mÃ¡quina.

Limpieza completa (incluye artefactos de MLflow/DVC):
```bash
make clean
```

---

## ğŸ— Arquitectura del Pipeline

```mermaid
flowchart TD
    A[ğŸ“‚ data/raw/*.csv] -->|dvc add| B[DVC Tracking]
    B -->|almacenado en| C[â˜ï¸ S3: mlops24-haowei-bucket]
    A --> D[âš™ï¸ acoustic_ml/modeling/train.py]
    D --> E[ğŸ¤– models/baseline_model.pkl]
    D --> F[ğŸ“ˆ metrics/metrics.json]
    E -->|log_model| G[MLflow Tracking]
    F -->|log_metrics| G
    G --> H[ğŸ–¥ MLflow UI :5001]
    
    style A fill:#e1f5ff
    style C fill:#fff4e1
    style E fill:#e8f5e9
    style H fill:#f3e5f5
```

**Flujo de trabajo:**

1. Los datos crudos viven en `data/raw/` y se versionan con DVC
2. Se almacenan en S3 (`mlops24-haowei-bucket`) para colaboraciÃ³n
3. El mÃ³dulo `acoustic_ml` procesa datos y entrena modelos
4. Modelos entrenados se guardan en `models/`
5. Experimentos y artefactos se registran en MLflow
6. MÃ©tricas se trackean con DVC en `metrics/metrics.json`
7. Todo es reproducible y trazable

---

## ğŸ¤ ContribuciÃ³n

### Flujo de trabajo

1. **Verificar sincronizaciÃ³n:**
   ```bash
   make verify-sync
   ```

2. **Crear una nueva rama:**
   ```bash
   git checkout -b feat/nombre-descriptivo
   ```

3. **Realizar cambios:**
   
   **Si modificas cÃ³digo Python:**
   ```bash
   # Edita archivos en acoustic_ml/
   vim acoustic_ml/features.py
   
   # Los cambios estÃ¡n disponibles inmediatamente (instalaciÃ³n en modo -e)
   ```

   **Si modificas datos:**
   ```bash
   dvc add data
   git add data.dvc data/.gitignore
   dvc push
   ```

   **Si instalaste paquetes:**
   ```bash
   make freeze
   git add requirements.txt
   ```

4. **Commitear cambios:**
   ```bash
   git add .
   git commit -m "feat: descripciÃ³n clara del cambio"
   ```

5. **Subir cambios:**
   ```bash
   git push origin feat/nombre-descriptivo
   dvc push  # o: make push
   ```

6. **Crear Pull Request** a la rama `main`

### Buenas prÃ¡cticas

- âœ… Ejecuta `make verify-sync` antes de comenzar a trabajar
- âœ… Ejecuta `dvc status` para verificar estado de datos
- âœ… Usa el mÃ³dulo `acoustic_ml` en lugar de cÃ³digo hardcodeado
- âœ… Ejecuta `make reproduce` antes de hacer commit
- âœ… Documenta tus experimentos en MLflow
- âœ… Escribe mensajes de commit descriptivos ([Conventional Commits](https://www.conventionalcommits.org/))
- âœ… MantÃ©n el cÃ³digo limpio y con docstrings
- âœ… Usa `make nb-hooks` para configurar hooks de notebooks
- âœ… Escribe cÃ³digo en el mÃ³dulo `acoustic_ml/`, no en notebooks
- âœ… Los notebooks son para exploraciÃ³n, el cÃ³digo productivo va en el mÃ³dulo
- âœ… Siempre haz `dvc push` despuÃ©s de modificar datos

---

## ğŸ‘¥ Equipo

<table>
  <tr>
    <td align="center">
      <strong>Sandra Luz Cervantes Espinoza</strong><br>
      <sub>A01796937</sub>
    </td>
    <td align="center">
      <strong>HÃ©ctor JesÃºs LÃ³pez Meza</strong><br>
      <sub>A01226881</sub>
    </td>
    <td align="center">
      <strong>Mauricio Torres Baena</strong><br>
      <sub>A01796697</sub>
    </td>
  </tr>
  <tr>
    <td align="center">
      <strong>David Cruz BeltrÃ¡n</strong><br>
      <sub>A01360416</sub>
    </td>
    <td align="center">
      <strong>Javier Augusto Rebull Saucedo</strong><br>
      <sub>A01795838</sub>
    </td>
    <td></td>
  </tr>
</table>

---

<div align="center">

**â­ Si este proyecto te resulta Ãºtil, considera darle una estrella**

Desarrollado con â¤ï¸ por el Equipo 24 | Estructura basada en [Cookiecutter Data Science](https://drivendata.github.io/cookiecutter-data-science/)

</div>
