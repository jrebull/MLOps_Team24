# ğŸµ Acoustic ML - Music Emotion Recognition

<div align="center">

**MLOps Team 24 - Proyecto de reconocimiento de emociones musicales**

[![Python](https://img.shields.io/badge/Python-3.12-blue.svg)](https://www.python.org/downloads/)
[![MLflow](https://img.shields.io/badge/MLflow-Tracking-0194E2?logo=mlflow)](https://mlflow.org/)
[![DVC](https://img.shields.io/badge/DVC-Data%20Versioning-945DD6?logo=dvc)](https://dvc.org/)
[![AWS S3](https://img.shields.io/badge/AWS-S3-FF9900?logo=amazon-aws)](https://aws.amazon.com/s3/)

<!-- Badges -->
[![verify-sync](https://img.shields.io/badge/verify--sync-make-blue?logo=gnu&logoColor=white)](#verificaciÃ³n-rÃ¡pida-antes-de-trabajar)
[![dependencies](https://img.shields.io/badge/deps-requirements.txt-informational?logo=python&logoColor=white)](#reproducibilidad-de-entornos)
[![notebooks](https://img.shields.io/badge/notebooks-clean%20outputs-success?logo=jupyter&logoColor=white)](#buenas-prÃ¡cticas-con-notebooks)
[![Tests](https://img.shields.io/badge/tests-37%2F37_passing-success?logo=pytest&logoColor=white)](#-testing-y-validaciÃ³n)
[![Code Quality](https://img.shields.io/badge/code%20quality-production--ready-brightgreen?logo=python&logoColor=white)](#-arquitectura-del-cÃ³digo)
[![Accuracy](https://img.shields.io/badge/accuracy-80.17%25-success?logo=tensorflow&logoColor=white)](#-sklearn-pipeline-end-to-end)

</div>

---

## ğŸ“‹ Tabla de Contenidos

- [Sobre el Proyecto](#-sobre-el-proyecto)
- [InformaciÃ³n AcadÃ©mica](#-informaciÃ³n-acadÃ©mica)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [ğŸ†• Arquitectura del CÃ³digo](#-arquitectura-del-cÃ³digo)
  - [MÃ³dulos Refactorizados](#mÃ³dulos-refactorizados)
  - [Design Patterns Implementados](#design-patterns-implementados)
  - [MÃ©tricas de RefactorizaciÃ³n](#-mÃ©tricas-de-refactorizaciÃ³n)
- [ğŸ†• Sklearn Pipeline End-to-End](#-sklearn-pipeline-end-to-end)
- [ğŸ†• Manejo de Outliers y Robustez](#-manejo-de-outliers-y-robustez)
- [ğŸ†• GuÃ­a de Uso de MÃ³dulos](#-guÃ­a-de-uso-de-mÃ³dulos)
- [ğŸ†• Testing y ValidaciÃ³n](#-testing-y-validaciÃ³n)
- [Datasets Disponibles](#-datasets-disponibles)
- [Requisitos Previos](#-requisitos-previos)
- [InstalaciÃ³n](#-instalaciÃ³n)
- [GestiÃ³n de Datos (DVC + S3)](#-gestiÃ³n-de-datos-dvc--s3)
- [Uso](#-uso--usage)
- [Scripts Disponibles](#-scripts-disponibles)
- [VerificaciÃ³n RÃ¡pida antes de Trabajar](#-verificaciÃ³n-rÃ¡pida-antes-de-trabajar)
- [Docker Compose](#-docker-compose)
- [Limpieza Local](#-limpieza-local)
- [Arquitectura del Pipeline](#-arquitectura-del-pipeline)
- [ContribuciÃ³n](#-contribuciÃ³n)
- [Equipo](#-equipo)

---

## ğŸ¯ Sobre el Proyecto

Este repositorio contiene la implementaciÃ³n completa de un sistema MLOps para reconocimiento de emociones en mÃºsica turca, siguiendo las mejores prÃ¡cticas de la industria con la estructura **Cookiecutter Data Science**. El proyecto integra un **pipeline sklearn end-to-end completo y listo para producciÃ³n** con las siguientes caracterÃ­sticas:

- ğŸ“Š **Versionado de datos** con DVC
- ğŸ”„ **Pipelines reproducibles** automatizados y compatibles con scikit-learn
- ğŸ“ˆ **Tracking de experimentos** con MLflow
- â˜ï¸ **Almacenamiento en la nube** (AWS S3: mlops24-haowei-bucket)
- ğŸ¤– **Modelos de Machine Learning** versionados (Accuracy: **80.17%**)
- ğŸ—‚ï¸ **Estructura modular** siguiendo estÃ¡ndares de la industria
- ğŸ—ï¸ **Arquitectura OOP** con SOLID principles
- ğŸ§ª **Testing comprehensivo** (37/37 tests passing)
- ğŸ¯ **Pipeline sklearn profesional** compatible con GridSearchCV y cross_val_score
- ğŸ›¡ï¸ **Manejo robusto de outliers** con anÃ¡lisis cuantitativo completo

### ğŸµ Dataset y Objetivo

**Dataset:** Turkish Music Emotion Dataset  
**Clases:** 4 emociones (Happy, Sad, Angry, Relax)  
**Features:** 50 caracterÃ­sticas acÃºsticas extraÃ­das  
**Objetivo:** ClasificaciÃ³n automÃ¡tica de emociones en mÃºsica turca

---

## ğŸ“˜ InformaciÃ³n AcadÃ©mica

**Instituto TecnolÃ³gico y de Estudios Superiores de Monterrey**  
*MaestrÃ­a en Inteligencia Artificial Aplicada (MNA)*

- **Curso:** Operaciones de Aprendizaje AutomÃ¡tico
- **Periodo:** Septiembre â€“ Diciembre 2025
- **Equipo:** NÂ° 24

### ğŸ‘¨â€ğŸ« Profesores

| Rol | Nombre |
|-----|--------|
| Titular | Dr. Gerardo RodrÃ­guez HernÃ¡ndez |
| Titular | Mtro. Ricardo Valdez HernÃ¡ndez |
| Asistente | Mtra. MarÃ­a Mylen TreviÃ±o Elizondo |
| Tutor | JosÃ© Ãngel MartÃ­nez Navarro |

---

## ğŸ—‚ï¸ Estructura del Proyecto

Organizado siguiendo **Cookiecutter Data Science** para mÃ¡xima reproducibilidad y claridad:

```
â”œâ”€â”€ LICENSE                 <- Licencia del proyecto
â”œâ”€â”€ Makefile               <- Comandos Ãºtiles (make data, make train, etc.)
â”œâ”€â”€ README.md              <- Este archivo
â”œâ”€â”€ pyproject.toml         <- ConfiguraciÃ³n del proyecto y dependencias
â”‚
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ external           <- Datos de fuentes externas
â”‚   â”œâ”€â”€ interim            <- Datos intermedios transformados
â”‚   â”œâ”€â”€ processed          <- Datasets finales para modelado
â”‚   â”‚   â”œâ”€â”€ turkish_music_emotion_cleaned.csv              (Limpieza inicial)
â”‚   â”‚   â”œâ”€â”€ turkish_music_emotion_v1_original.csv          (400 filas - Baseline)
â”‚   â”‚   â”œâ”€â”€ turkish_music_emotion_v2_cleaned_aligned.csv   (400 filas - ComparaciÃ³n)
â”‚   â”‚   â”œâ”€â”€ turkish_music_emotion_v2_cleaned_full.csv      (408 filas) â­ RECOMENDADO
â”‚   â”‚   â”œâ”€â”€ X_train.csv    <- Training features
â”‚   â”‚   â”œâ”€â”€ X_test.csv     <- Test features
â”‚   â”‚   â”œâ”€â”€ y_train.csv    <- Training labels
â”‚   â”‚   â””â”€â”€ y_test.csv     <- Test labels
â”‚   â””â”€â”€ raw                <- Datos originales inmutables (versionados con DVC)
â”‚       â”œâ”€â”€ turkis_music_emotion_original.csv      (125 KB)
â”‚       â”œâ”€â”€ turkish_music_emotion_modified.csv     (130 KB)
â”‚       â””â”€â”€ .gitignore                             (Git ignora los CSV)
â”‚
â”œâ”€â”€ models                 <- Modelos entrenados y serializados
â”‚   â””â”€â”€ baseline_model.pkl
â”‚
â”œâ”€â”€ notebooks              <- Jupyter notebooks para exploraciÃ³n
â”‚   â”œâ”€â”€ Fase1_equipo24.ipynb
â”‚   â””â”€â”€ NoteBook Testing.ipynb
â”‚   
â”‚   ConvenciÃ³n de nombres: nÃºmero-iniciales-descripciÃ³n
â”‚   Ej: 1.0-hw-exploratory-analysis.ipynb
â”‚
â”œâ”€â”€ reports                <- AnÃ¡lisis generados (HTML, PDF, etc.)
â”‚   â””â”€â”€ figures            <- GrÃ¡ficas y figuras para reportes
â”‚       â”œâ”€â”€ outlier_analysis.png          <- DistribuciÃ³n de outliers por feature
â”‚       â”œâ”€â”€ outlier_boxplots.png          <- Boxplots de top features con outliers
â”‚       â”œâ”€â”€ outlier_analysis_report.txt   <- Reporte tÃ©cnico completo de outliers
â”‚       â””â”€â”€ scaler_comparison_results.txt <- ComparaciÃ³n StandardScaler vs RobustScaler
â”‚
â”œâ”€â”€ references             <- Diccionarios de datos, manuales, etc.
â”‚
â”œâ”€â”€ requirements.txt       <- Dependencias del proyecto (pip freeze)
â”‚
â”œâ”€â”€ scripts                <- Scripts auxiliares
â”‚   â”œâ”€â”€ train_baseline.py
â”‚   â”œâ”€â”€ validate_plots.py           <- ValidaciÃ³n de mÃ³dulo plots
â”‚   â”œâ”€â”€ validate_features.py        <- ValidaciÃ³n de mÃ³dulo features
â”‚   â”œâ”€â”€ validate_dataset.py         <- ValidaciÃ³n de mÃ³dulo dataset
â”‚   â”œâ”€â”€ analyze_outliers.py         <- AnÃ¡lisis estadÃ­stico de outliers âœ¨ NUEVO
â”‚   â”œâ”€â”€ compare_scalers.py          <- ComparaciÃ³n empÃ­rica A/B de scalers âœ¨ NUEVO
â”‚   â”œâ”€â”€ test_sklearn_pipeline.py    <- Test de integraciÃ³n del pipeline âœ¨ NUEVO
â”‚   â”œâ”€â”€ test_full_integration.py    <- ValidaciÃ³n completa del sistema âœ¨ NUEVO
â”‚   â””â”€â”€ run_full_analysis.py        <- Script maestro de anÃ¡lisis âœ¨ NUEVO
â”‚
â”œâ”€â”€ acoustic_ml            <- CÃ³digo fuente del proyecto (mÃ³dulo Python) â­ REFACTORIZADO
â”‚   â”œâ”€â”€ __init__.py        <- Hace de acoustic_ml un mÃ³dulo Python
â”‚   â”œâ”€â”€ config.py          <- ConfiguraciÃ³n y variables globales
â”‚   â”œâ”€â”€ dataset.py         <- GestiÃ³n de datos (650 lÃ­neas, 16 tests) âœ¨ NUEVO
â”‚   â”œâ”€â”€ features.py        <- Feature engineering (930 lÃ­neas, 13 tests) âœ¨ NUEVO
â”‚   â”œâ”€â”€ plots.py           <- Visualizaciones (370 lÃ­neas, 8 tests) âœ¨ NUEVO
â”‚   â””â”€â”€ modeling           <- MÃ³dulos de modelado
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ train.py          <- Entrenamiento de modelos (122 lÃ­neas)
â”‚       â”œâ”€â”€ predict.py        <- Inferencia con modelos (189 lÃ­neas)
â”‚       â”œâ”€â”€ evaluate.py       <- EvaluaciÃ³n de modelos (311 lÃ­neas)
â”‚       â”œâ”€â”€ pipeline.py       <- Pipeline completo (370 lÃ­neas)
â”‚       â””â”€â”€ sklearn_pipeline.py <- Pipeline sklearn end-to-end â­ PRODUCCIÃ“N
â”‚
â”œâ”€â”€ metrics                <- MÃ©tricas del pipeline DVC
â”‚   â””â”€â”€ metrics.json
â”‚
â”œâ”€â”€ mlruns                 <- Experimentos de MLflow
â”œâ”€â”€ mlartifacts            <- Artifacts de MLflow
â”œâ”€â”€ dvcstore               <- Almacenamiento local de DVC
â”‚
â”œâ”€â”€ docs                   <- Detailed information for the project
â”œâ”€â”€ .dvc                   <- ConfiguraciÃ³n de DVC
â”œâ”€â”€ dvc.yaml               <- DefiniciÃ³n del pipeline DVC
â”œâ”€â”€ dvc.lock               <- Lock file del pipeline
â”œâ”€â”€ data.dvc               <- Metadatos de tracking (versionado en Git)
â”‚
â”œâ”€â”€ .git                   <- Control de versiones Git
â””â”€â”€ .venv                  <- Entorno virtual de Python
```

---

## ğŸ—ï¸ Arquitectura del CÃ³digo

### ğŸ“Š Resumen Ejecutivo

En la **Fase 2 del proyecto**, realizamos una **refactorizaciÃ³n masiva** del mÃ³dulo `acoustic_ml/` transformÃ¡ndolo de scripts funcionales simples a una **arquitectura MLOps profesional** basada en **OOP** y **SOLID principles**.

**Resultado:**
- **+1,718 lÃ­neas** de cÃ³digo profesional (+740% de crecimiento)
- **15 clases principales** con responsabilidades claras
- **37 tests** comprehensivos (100% passing)
- **100% type hints** y documentaciÃ³n en espaÃ±ol
- **Design patterns** de la industria implementados
- **Pipeline sklearn end-to-end** listo para producciÃ³n â­ NUEVO

---

### MÃ³dulos Refactorizados

#### ğŸ¨ **1. acoustic_ml/plots.py** - Sistema de VisualizaciÃ³n

**TransformaciÃ³n:** 49 â†’ 370 lÃ­neas (+321 lÃ­neas, +655%)

```python
PlotManager
â”œâ”€â”€ GestiÃ³n centralizada de figuras y estilos
â”œâ”€â”€ ConfiguraciÃ³n automÃ¡tica de seaborn
â”œâ”€â”€ MÃ©todo save_figure() robusto con validaciÃ³n
â””â”€â”€ create_subplot_grid() para layouts complejos

BasePlotter (ABC)
â”œâ”€â”€ Clase base abstracta para todos los plotters
â”œâ”€â”€ Interfaz comÃºn estandarizada
â”œâ”€â”€ ValidaciÃ³n de datos automÃ¡tica
â””â”€â”€ PatrÃ³n Template Method

FeatureImportancePlotter
â”œâ”€â”€ Hereda de BasePlotter
â”œâ”€â”€ VisualizaciÃ³n especializada de feature importance
â”œâ”€â”€ PersonalizaciÃ³n completa (colores, tamaÃ±os, top_n)
â””â”€â”€ MÃ©todo plot_and_save() conveniente
```

**CaracterÃ­sticas destacadas:**
- âœ… SOLID principles implementados
- âœ… Python `DeprecationWarnings` oficiales para funciones legacy
- âœ… DocumentaciÃ³n completa con ejemplos
- âœ… **8/8 tests pasados**

**Ejemplo de uso:**
```python
from acoustic_ml.plots import FeatureImportancePlotter

# Crear plotter
plotter = FeatureImportancePlotter(
    importance_values=feature_importances,
    feature_names=feature_names,
    title="Feature Importance - Random Forest"
)

# Generar y guardar visualizaciÃ³n
plotter.plot_and_save("reports/figures/feature_importance.png")
```

---

#### ğŸ”§ **2. acoustic_ml/features.py** - Feature Engineering Pipeline

**TransformaciÃ³n:** 88 â†’ 930 lÃ­neas (+842 lÃ­neas, +956%)

```python
FeatureTransformer (Base abstracta)
â”œâ”€â”€ ValidaciÃ³n automÃ¡tica de datos
â”œâ”€â”€ Logging integrado en todas las operaciones
â”œâ”€â”€ PreservaciÃ³n de formato (DataFrame/array)
â””â”€â”€ get_feature_names_out() para inspecciÃ³n

NumericFeatureSelector
â”œâ”€â”€ SelecciÃ³n automÃ¡tica de features numÃ©ricas
â”œâ”€â”€ ValidaciÃ³n de tipos de datos
â”œâ”€â”€ Compatible con sklearn pipelines
â””â”€â”€ Manejo inteligente de DataFrames vs arrays

PowerTransformer
â”œâ”€â”€ TransformaciÃ³n Yeo-Johnson por defecto
â”œâ”€â”€ ReducciÃ³n de skewness
â”œâ”€â”€ Mejora de normalidad
â””â”€â”€ PreservaciÃ³n de nombres de features

RobustScaler
â”œâ”€â”€ Escalado robusto a outliers
â”œâ”€â”€ Usa mediana y rango intercuartil (IQR)
â”œâ”€â”€ Mejor generalizaciÃ³n en producciÃ³n
â””â”€â”€ Compatible con datos con distribuciones no normales

FeaturePipeline
â”œâ”€â”€ Encadena mÃºltiples transformers
â”œâ”€â”€ Preserva nombres de features en cada paso
â”œâ”€â”€ Logging comprehensivo
â””â”€â”€ FÃ¡cil de serializar para producciÃ³n

FeaturePipelineBuilder
â”œâ”€â”€ PatrÃ³n Builder para construcciÃ³n fluida
â”œâ”€â”€ add_transformer() encadenable
â”œâ”€â”€ build() genera el pipeline final
â””â”€â”€ Flexible y extensible
```

**CaracterÃ­sticas destacadas:**
- âœ… 7 transformers especializados
- âœ… Builder pattern para construcciÃ³n flexible
- âœ… Type hints completos
- âœ… **13/13 tests pasados**

**Ejemplo de uso:**
```python
from acoustic_ml.features import FeaturePipelineBuilder

# Construir pipeline de features
pipeline = (
    FeaturePipelineBuilder()
    .add_transformer(NumericFeatureSelector())
    .add_transformer(PowerTransformer())
    .add_transformer(RobustScaler())
    .build()
)

# Usar el pipeline
X_transformed = pipeline.fit_transform(X_train)
```

---

#### ğŸ“¦ **3. acoustic_ml/dataset.py** - GestiÃ³n de Datos

**TransformaciÃ³n:** 46 â†’ 650 lÃ­neas (+604 lÃ­neas, +1,313%)

```python
DatasetManager (Singleton)
â”œâ”€â”€ Thread-safe con _lock para concurrencia
â”œâ”€â”€ CachÃ© inteligente de datasets
â”œâ”€â”€ MÃ©todos get_* para acceso rÃ¡pido
â”œâ”€â”€ ValidaciÃ³n automÃ¡tica de estructura
â””â”€â”€ ConfiguraciÃ³n centralizada

DatasetValidator
â”œâ”€â”€ ValidaciÃ³n de estructura (filas, columnas)
â”œâ”€â”€ ValidaciÃ³n de tipos de datos
â”œâ”€â”€ DetecciÃ³n de valores faltantes
â”œâ”€â”€ ValidaciÃ³n de target_column
â””â”€â”€ Reportes detallados de validaciÃ³n

DataPreprocessor
â”œâ”€â”€ Limpieza de datos automÃ¡tica
â”œâ”€â”€ Manejo de valores faltantes
â”œâ”€â”€ Encoding de variables categÃ³ricas
â””â”€â”€ NormalizaciÃ³n opcional
```

**CaracterÃ­sticas destacadas:**
- âœ… PatrÃ³n Singleton thread-safe
- âœ… ValidaciÃ³n comprehensiva
- âœ… CachÃ© inteligente
- âœ… **16/16 tests pasados**

**Ejemplo de uso:**
```python
from acoustic_ml.dataset import DatasetManager

# Obtener instancia (Singleton)
dm = DatasetManager.get_instance()

# Cargar dataset con validaciÃ³n automÃ¡tica
df = dm.get_dataset("turkish_music_emotion_v2_cleaned_full.csv")

# Obtener training splits
X_train, y_train = dm.get_train_data()
X_test, y_test = dm.get_test_data()
```

---

### Design Patterns Implementados

| Pattern | UbicaciÃ³n | PropÃ³sito |
|---------|-----------|-----------|
| **Singleton** | `DatasetManager` | Ãšnica instancia thread-safe de gestiÃ³n de datos |
| **Builder** | `FeaturePipelineBuilder` | ConstrucciÃ³n fluida de pipelines complejos |
| **Template Method** | `BasePlotter` | Estructura comÃºn para todos los plotters |
| **Strategy** | `FeatureTransformer` | Intercambio flexible de transformadores |
| **Factory** | `create_sklearn_pipeline()` | CreaciÃ³n simplificada de pipelines â­ NUEVO |

---

### ğŸ“ˆ MÃ©tricas de RefactorizaciÃ³n

| MÃ³dulo | Antes | DespuÃ©s | Crecimiento | Tests |
|--------|-------|---------|-------------|-------|
| `plots.py` | 49 lÃ­neas | 370 lÃ­neas | **+655%** | 8/8 âœ… |
| `features.py` | 88 lÃ­neas | 930 lÃ­neas | **+956%** | 13/13 âœ… |
| `dataset.py` | 46 lÃ­neas | 650 lÃ­neas | **+1,313%** | 16/16 âœ… |
| **TOTAL** | 183 lÃ­neas | 1,950 lÃ­neas | **+965%** | 37/37 âœ… |

---

## ğŸ¯ Sklearn Pipeline End-to-End

### DescripciÃ³n

El mÃ³dulo `acoustic_ml/modeling/sklearn_pipeline.py` implementa un **pipeline completamente compatible con scikit-learn** que integra preprocessing, feature engineering, y modelado en un Ãºnico objeto que puede ser usado directamente con herramientas de sklearn como `GridSearchCV`, `cross_val_score`, y `Pipeline`.

### CaracterÃ­sticas Principales

- ğŸ”„ **Pipeline End-to-End:** Desde datos crudos hasta predicciones
- ğŸ¯ **Compatible con sklearn:** Funciona con GridSearchCV, cross_val_score, etc.
- ğŸ›¡ï¸ **Robusto a outliers:** Usa RobustScaler por defecto
- ğŸ“Š **Modelos soportados:** RandomForest, SVM, LogisticRegression, KNN
- ğŸ¨ **Factory function:** `create_sklearn_pipeline()` para creaciÃ³n rÃ¡pida
- ğŸ’¾ **Serializable:** Guarda y carga con pickle/joblib

### Arquitectura del Pipeline

```python
SklearnMLPipeline
â”œâ”€â”€ NumericFeatureSelector    # Selecciona solo features numÃ©ricas
â”œâ”€â”€ PowerTransformer           # Yeo-Johnson transformation
â”œâ”€â”€ RobustScaler              # Escalado robusto a outliers
â””â”€â”€ Model                     # RandomForest, SVM, LogisticRegression, o KNN
```

**Pipeline optimizado actual (80.17% accuracy):**
```
NumericFeatureSelector â†’ PowerTransformer â†’ RobustScaler â†’ RandomForest
```

### Uso BÃ¡sico

```python
from acoustic_ml.modeling.sklearn_pipeline import create_sklearn_pipeline
import pandas as pd

# Cargar datos
X_train = pd.read_csv("data/processed/X_train.csv")
y_train = pd.read_csv("data/processed/y_train.csv").squeeze()
X_test = pd.read_csv("data/processed/X_test.csv")
y_test = pd.read_csv("data/processed/y_test.csv").squeeze()

# Crear pipeline con RandomForest
pipeline = create_sklearn_pipeline(
    model_type="random_forest",
    model_params={'n_estimators': 100, 'max_depth': None, 'random_state': 42}
)

# Entrenar
pipeline.fit(X_train, y_train)

# Predecir
predictions = pipeline.predict(X_test)

# Evaluar
accuracy = pipeline.score(X_test, y_test)
print(f"Accuracy: {accuracy:.2%}")  # Output: Accuracy: 80.17%
```

### Uso Avanzado: GridSearchCV

```python
from sklearn.model_selection import GridSearchCV
from acoustic_ml.modeling.sklearn_pipeline import create_sklearn_pipeline

# Crear pipeline base
pipeline = create_sklearn_pipeline(model_type="random_forest")

# Definir grid de hiperparÃ¡metros
param_grid = {
    'model__n_estimators': [50, 100, 200],
    'model__max_depth': [None, 10, 20, 30],
    'model__min_samples_split': [2, 5, 10]
}

# Grid Search
grid_search = GridSearchCV(
    pipeline, 
    param_grid, 
    cv=5, 
    scoring='accuracy',
    n_jobs=-1
)

# Buscar mejores hiperparÃ¡metros
grid_search.fit(X_train, y_train)

# Mejores parÃ¡metros y score
print(f"Best params: {grid_search.best_params_}")
print(f"Best CV score: {grid_search.best_score_:.2%}")

# Evaluar en test set
test_score = grid_search.score(X_test, y_test)
print(f"Test accuracy: {test_score:.2%}")
```

### Uso Avanzado: Cross-Validation

```python
from sklearn.model_selection import cross_val_score
from acoustic_ml.modeling.sklearn_pipeline import create_sklearn_pipeline

# Crear pipeline
pipeline = create_sklearn_pipeline(
    model_type="random_forest",
    model_params={'n_estimators': 100, 'random_state': 42}
)

# Cross-validation con 5 folds
cv_scores = cross_val_score(
    pipeline, 
    X_train, 
    y_train, 
    cv=5, 
    scoring='accuracy'
)

print(f"CV Scores: {cv_scores}")
print(f"Mean CV Score: {cv_scores.mean():.2%} (+/- {cv_scores.std() * 2:.2%})")
```

### Modelos Disponibles

| Modelo | `model_type` | ParÃ¡metros por defecto |
|--------|--------------|------------------------|
| Random Forest | `"random_forest"` | `n_estimators=100, random_state=42` |
| SVM | `"svm"` | `kernel='rbf', C=1.0, random_state=42` |
| Logistic Regression | `"logistic_regression"` | `max_iter=1000, random_state=42` |
| KNN | `"knn"` | `n_neighbors=5` |

### SerializaciÃ³n

```python
import joblib

# Guardar pipeline entrenado
joblib.dump(pipeline, "models/sklearn_pipeline.pkl")

# Cargar pipeline
loaded_pipeline = joblib.load("models/sklearn_pipeline.pkl")

# Usar pipeline cargado
predictions = loaded_pipeline.predict(X_new)
```

### MÃ©tricas de Rendimiento

**Modelo actual en producciÃ³n:**
- **Arquitectura:** NumericFeatureSelector â†’ PowerTransformer â†’ RobustScaler â†’ RandomForest
- **Accuracy:** 80.17%
- **Dataset:** turkish_music_emotion_v2_cleaned_full.csv (408 filas, 50 features)
- **Train/Test split:** 70/30
- **Random state:** 42

---

## ğŸ›¡ï¸ Manejo de Outliers y Robustez

### AnÃ¡lisis Cuantitativo de Outliers

Realizamos un **anÃ¡lisis estadÃ­stico exhaustivo** de outliers en el dataset Turkish Music Emotion usando el mÃ©todo IQR (Interquartile Range):

#### ğŸ“Š Resultados Clave

- **62.4% de filas** contienen al menos un outlier (176/282 filas)
- **38 features de 50** tienen outliers detectados
- **Features mÃ¡s afectados:**
  - `AttackTime_Mean`: 8.87% de valores son outliers
  - `Roughness_Slope`: 7.09% de valores son outliers
  - `ZeroCrossingRate_Mean`: 6.03% de valores son outliers

### ğŸ“ˆ ComparaciÃ³n EmpÃ­rica de Scalers

Realizamos una **comparaciÃ³n A/B** entre `StandardScaler` y `RobustScaler`:

| Scaler | Accuracy | Observaciones |
|--------|----------|---------------|
| StandardScaler | 80.17% | Sensible a outliers, asume distribuciÃ³n normal |
| RobustScaler | 80.17% | **Robusto a outliers**, usa mediana e IQR |

**Resultado:** EMPATE en accuracy, pero **RobustScaler elegido** por:
- ğŸ›¡ï¸ Mayor robustez en producciÃ³n
- ğŸ“Š Mejor generalizaciÃ³n con datos nuevos
- ğŸ¯ No asume distribuciÃ³n normal
- âœ… MLOps best practice para datos del mundo real

### ğŸ¯ DecisiÃ³n TÃ©cnica: Â¿Eliminar o Transformar?

Evaluamos dos enfoques para manejo de outliers:

| Enfoque | Ventajas | Desventajas | DecisiÃ³n |
|---------|----------|-------------|----------|
| **OutlierRemover** | Elimina ruido | âŒ Elimina filas (rompe pipeline sklearn)<br>âŒ No reproducible en nuevos datos<br>âŒ Reduce tamaÃ±o del dataset | âŒ NO usar |
| **RobustScaler** | âœ… Transforma sin eliminar<br>âœ… Reproducible<br>âœ… Compatible con sklearn | Puede mantener outliers extremos | âœ… **ELEGIDO** |

### ğŸ§ª JustificaciÃ³n MLOps

En **producciÃ³n**, no podemos eliminar filas de datos nuevos. Por lo tanto:

1. âœ… **RobustScaler** transforma outliers manteniendo reproducibilidad
2. âœ… **Random Forest** es naturalmente robusto a outliers por su construcciÃ³n con bagging
3. âœ… **PowerTransformer** reduce skewness antes del escalado
4. âœ… Pipeline completo es **reproducible** en cualquier dato nuevo

### ğŸ“ Reportes Generados

Los anÃ¡lisis detallados estÃ¡n disponibles en:

```
reports/figures/
â”œâ”€â”€ outlier_analysis.png          # DistribuciÃ³n de outliers por feature
â”œâ”€â”€ outlier_boxplots.png          # Boxplots de top features con outliers
â”œâ”€â”€ outlier_analysis_report.txt   # Reporte tÃ©cnico completo
â””â”€â”€ scaler_comparison_results.txt # ComparaciÃ³n StandardScaler vs RobustScaler
```

### ğŸ”¬ Scripts de AnÃ¡lisis

```bash
# AnÃ¡lisis de outliers con visualizaciones
python scripts/analyze_outliers.py

# ComparaciÃ³n empÃ­rica de scalers
python scripts/compare_scalers.py

# AnÃ¡lisis completo (outliers + scalers)
python scripts/run_full_analysis.py
```

---

## ğŸ“š GuÃ­a de Uso de MÃ³dulos

### 1ï¸âƒ£ GestiÃ³n de Datos con DatasetManager

```python
from acoustic_ml.dataset import DatasetManager

# Singleton instance
dm = DatasetManager.get_instance()

# Cargar dataset completo
df = dm.get_dataset("turkish_music_emotion_v2_cleaned_full.csv")

# Obtener datos de entrenamiento
X_train, y_train = dm.get_train_data()

# Obtener datos de prueba
X_test, y_test = dm.get_test_data()

# InformaciÃ³n del dataset
print(f"Shape: {df.shape}")
print(f"Columns: {df.columns.tolist()}")
```

### 2ï¸âƒ£ Feature Engineering con FeaturePipeline

```python
from acoustic_ml.features import (
    FeaturePipelineBuilder,
    NumericFeatureSelector,
    PowerTransformer,
    RobustScaler
)

# Construir pipeline
feature_pipeline = (
    FeaturePipelineBuilder()
    .add_transformer(NumericFeatureSelector())
    .add_transformer(PowerTransformer(method='yeo-johnson'))
    .add_transformer(RobustScaler())
    .build()
)

# Aplicar transformaciones
X_transformed = feature_pipeline.fit_transform(X_train)

# Inspeccionar nombres de features
feature_names = feature_pipeline.get_feature_names_out()
print(f"Features: {feature_names}")
```

### 3ï¸âƒ£ VisualizaciÃ³n con Plotters

```python
from acoustic_ml.plots import FeatureImportancePlotter
import numpy as np

# Simular feature importances
feature_importances = np.random.rand(10)
feature_names = [f"Feature_{i}" for i in range(10)]

# Crear plotter
plotter = FeatureImportancePlotter(
    importance_values=feature_importances,
    feature_names=feature_names,
    title="Top 10 Features",
    top_n=10
)

# Generar y guardar
plotter.plot_and_save("reports/figures/importance.png")
```

### 4ï¸âƒ£ Pipeline Sklearn End-to-End

```python
from acoustic_ml.modeling.sklearn_pipeline import create_sklearn_pipeline

# Crear pipeline optimizado
pipeline = create_sklearn_pipeline(
    model_type="random_forest",
    model_params={
        'n_estimators': 100,
        'max_depth': None,
        'random_state': 42
    }
)

# Entrenar y evaluar
pipeline.fit(X_train, y_train)
accuracy = pipeline.score(X_test, y_test)
print(f"Accuracy: {accuracy:.2%}")

# Guardar modelo
import joblib
joblib.dump(pipeline, "models/production_pipeline.pkl")
```

---

## ğŸ§ª Testing y ValidaciÃ³n

### Suite de Tests Completa

El proyecto cuenta con **37 tests comprehensivos** que validan:

- âœ… GestiÃ³n de datos (`dataset.py` - 16 tests)
- âœ… Feature engineering (`features.py` - 13 tests)
- âœ… Sistema de visualizaciÃ³n (`plots.py` - 8 tests)

### Scripts de ValidaciÃ³n

```bash
# Validar mÃ³dulo de datasets
python scripts/validate_dataset.py

# Validar mÃ³dulo de features
python scripts/validate_features.py

# Validar mÃ³dulo de plots
python scripts/validate_plots.py

# Test de integraciÃ³n del pipeline sklearn
python scripts/test_sklearn_pipeline.py

# ValidaciÃ³n completa del sistema
python scripts/test_full_integration.py
```

### Resultados de Tests

```
âœ… acoustic_ml.dataset   - 16/16 tests passing
âœ… acoustic_ml.features  - 13/13 tests passing
âœ… acoustic_ml.plots     - 8/8 tests passing
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ… TOTAL: 37/37 tests passing (100%)
```

---

## ğŸ“¦ Datasets Disponibles

| Archivo | Filas | DescripciÃ³n | Recomendado |
|---------|-------|-------------|-------------|
| `turkis_music_emotion_original.csv` | ~400 | Dataset original crudo | âŒ |
| `turkish_music_emotion_modified.csv` | ~400 | Dataset con modificaciones manuales | âŒ |
| `turkish_music_emotion_cleaned.csv` | ~400 | Primera limpieza | âŒ |
| `turkish_music_emotion_v1_original.csv` | 400 | VersiÃ³n formalizada (baseline) | âš ï¸ |
| `turkish_music_emotion_v2_cleaned_aligned.csv` | 400 | Limpieza alineada (comparaciÃ³n) | âš ï¸ |
| **`turkish_music_emotion_v2_cleaned_full.csv`** | **408** | **Dataset completo limpio** | âœ… **USAR** |

### Dataset Recomendado: v2_cleaned_full.csv

- **Filas:** 408 (mÃ¡xima informaciÃ³n preservada)
- **Features:** 50 caracterÃ­sticas acÃºsticas
- **Target:** 4 clases (Happy, Sad, Angry, Relax)
- **Calidad:** Limpieza profesional sin pÃ©rdida innecesaria de datos
- **Versionado:** Trackeado con DVC en S3

---

## âš™ï¸ Requisitos Previos

- **Python:** 3.12 o superior
- **Sistema operativo:** Linux, macOS, Windows
- **Git:** Para control de versiones
- **AWS CLI:** Configurado con credenciales para S3
- **DVC:** Para versionado de datos

---

## ğŸš€ InstalaciÃ³n

### 1. Clonar el repositorio

```bash
git clone https://github.com/jrebull/MLOps_Team24.git
cd MLOps_Team24
```

### 2. Crear entorno virtual

**macOS/Linux:**
```bash
python3.12 -m venv .venv
source .venv/bin/activate
```

**Windows:**
```bash
python -m venv .venv
.venv\Scripts\activate
```

### 3. Instalar dependencias

```bash
pip install -r requirements.txt
```

### 4. Instalar el mÃ³dulo acoustic_ml en modo desarrollo

```bash
pip install -e .
```

Esto permite que cualquier cambio en `acoustic_ml/` se refleje inmediatamente sin reinstalar.

### 5. Configurar DVC con S3

**Verificar configuraciÃ³n:**
```bash
dvc remote list
```

DeberÃ­a mostrar:
```
myremote	s3://mlops24-haowei-bucket/dvcstore
```

**Si no estÃ¡ configurado:**
```bash
dvc remote add -d myremote s3://mlops24-haowei-bucket/dvcstore
```

### 6. Descargar datos desde S3

```bash
dvc pull
```

O usando Makefile:
```bash
make pull
```

### 7. Verificar instalaciÃ³n

```bash
python scripts/validate_dataset.py
python scripts/validate_features.py
python scripts/validate_plots.py
```

Si todos los tests pasan âœ…, Â¡estÃ¡s listo!

---

## â˜ï¸ GestiÃ³n de Datos (DVC + S3)

### Comandos DVC Esenciales

```bash
# Ver estado de los datos
dvc status

# Descargar datos desde S3
dvc pull

# Subir cambios de datos a S3
dvc push

# Agregar nuevos archivos al tracking
dvc add data/raw/new_file.csv
git add data/raw/new_file.csv.dvc data/raw/.gitignore
git commit -m "data: add new dataset"
dvc push
```

### Makefile Shortcuts

```bash
make pull    # Equivalente a: dvc pull
make push    # Equivalente a: dvc push + git push
make status  # Equivalente a: dvc status
```

### Estructura de Versionado

```
S3 Bucket: mlops24-haowei-bucket
â”œâ”€â”€ dvcstore/
â”‚   â”œâ”€â”€ files/              <- Contenido de archivos versionados
â”‚   â””â”€â”€ tmp/                <- Archivos temporales
```

**Importante:** Los archivos CSV en `data/raw/` estÃ¡n en `.gitignore` pero trackeados con DVC mediante archivos `.dvc`.

---

## ğŸ’» Uso / Usage

### OpciÃ³n 1: Pipeline Sklearn (Recomendado para ProducciÃ³n) â­

```python
from acoustic_ml.modeling.sklearn_pipeline import create_sklearn_pipeline
import pandas as pd

# Cargar datos
X_train = pd.read_csv("data/processed/X_train.csv")
y_train = pd.read_csv("data/processed/y_train.csv").squeeze()
X_test = pd.read_csv("data/processed/X_test.csv")
y_test = pd.read_csv("data/processed/y_test.csv").squeeze()

# Crear pipeline optimizado
pipeline = create_sklearn_pipeline(
    model_type="random_forest",
    model_params={'n_estimators': 100, 'max_depth': None, 'random_state': 42}
)

# Entrenar
pipeline.fit(X_train, y_train)

# Evaluar
accuracy = pipeline.score(X_test, y_test)
print(f"Test Accuracy: {accuracy:.2%}")  # 80.17%

# Guardar modelo
import joblib
joblib.dump(pipeline, "models/production_pipeline.pkl")
```

### OpciÃ³n 2: Usando MÃ³dulos Individuales

```python
from acoustic_ml.dataset import DatasetManager
from acoustic_ml.features import FeaturePipelineBuilder, NumericFeatureSelector, PowerTransformer, RobustScaler
from sklearn.ensemble import RandomForestClassifier

# 1. Cargar datos
dm = DatasetManager.get_instance()
X_train, y_train = dm.get_train_data()
X_test, y_test = dm.get_test_data()

# 2. Construir feature pipeline
feature_pipeline = (
    FeaturePipelineBuilder()
    .add_transformer(NumericFeatureSelector())
    .add_transformer(PowerTransformer())
    .add_transformer(RobustScaler())
    .build()
)

# 3. Transformar features
X_train_transformed = feature_pipeline.fit_transform(X_train)
X_test_transformed = feature_pipeline.transform(X_test)

# 4. Entrenar modelo
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train_transformed, y_train)

# 5. Evaluar
accuracy = model.score(X_test_transformed, y_test)
print(f"Accuracy: {accuracy:.2%}")
```

### OpciÃ³n 3: Usando Makefile

```bash
# Reproducir pipeline completo
make reproduce

# Entrenar modelo baseline
make train

# Ver mÃ©tricas
cat metrics/metrics.json
```

### OpciÃ³n 4: Usar MLflow UI

```bash
# Levantar servidor MLflow
mlflow ui --port 5001

# Abrir en navegador
# http://localhost:5001
```

---

## ğŸ“œ Scripts Disponibles

### Scripts de ValidaciÃ³n

| Script | DescripciÃ³n | Comando |
|--------|-------------|---------|
| `validate_dataset.py` | Valida mÃ³dulo dataset.py (16 tests) | `python scripts/validate_dataset.py` |
| `validate_features.py` | Valida mÃ³dulo features.py (13 tests) | `python scripts/validate_features.py` |
| `validate_plots.py` | Valida mÃ³dulo plots.py (8 tests) | `python scripts/validate_plots.py` |

### Scripts de AnÃ¡lisis âœ¨ NUEVOS

| Script | DescripciÃ³n | Comando |
|--------|-------------|---------|
| `analyze_outliers.py` | AnÃ¡lisis estadÃ­stico de outliers con visualizaciones | `python scripts/analyze_outliers.py` |
| `compare_scalers.py` | ComparaciÃ³n empÃ­rica A/B: StandardScaler vs RobustScaler | `python scripts/compare_scalers.py` |
| `test_sklearn_pipeline.py` | Test de integraciÃ³n del pipeline sklearn | `python scripts/test_sklearn_pipeline.py` |
| `test_full_integration.py` | ValidaciÃ³n completa del sistema end-to-end | `python scripts/test_full_integration.py` |
| `run_full_analysis.py` | Script maestro: ejecuta anÃ¡lisis completo | `python scripts/run_full_analysis.py` |

### Ejemplo: AnÃ¡lisis Completo

```bash
# Ejecutar anÃ¡lisis completo de outliers y scalers
python scripts/run_full_analysis.py

# Salida esperada:
# âœ… Outlier analysis completed
# âœ… Scaler comparison completed
# ğŸ“Š Reports saved in: reports/figures/
```

---

## âœ… VerificaciÃ³n RÃ¡pida antes de Trabajar

Antes de comenzar a trabajar, **siempre** verifica sincronizaciÃ³n:

```bash
make verify-sync
```

Este comando automÃ¡ticamente:
1. âœ… Verifica estado de Git
2. âœ… Verifica estado de DVC
3. âœ… Detecta cambios no commiteados
4. âœ… Detecta datos no sincronizados con S3

**Salida esperada:**
```
âœ… Everything is synchronized!
âœ… Git: Working directory clean
âœ… DVC: Data in sync with remote
```

---

## ğŸ³ Docker Compose

```
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ config.env
â”œâ”€â”€ mlartifacts/           # Almacena los artefactos de MLflow 
â”œâ”€â”€ ml_pipeline.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ acoustic_ml/           # MÃ³dulo del proyecto
â””â”€â”€ .venv/                 # Entorno virtual local
```

### âš™ï¸ Archivos requeridos
âœ… config.env

### âš™ï¸ Comandos de uso

**ğŸ”§ Levantar servicios**

```bash
docker-compose --env-file config.env up -d --build
```

MinIO (Consola): http://localhost:9001

**ğŸ›‘ Detener los servicios**
```bash
docker-compose down
```

**ğŸ”„ Reiniciar**
```bash
docker-compose --env-file config.env up -d --build
```

---

## ğŸ§¹ Limpieza Local

Si necesitas borrar cachÃ©s locales (sin afectar Git):

```bash
make clean-caches
```

Limpieza completa (incluye artefactos de MLflow/DVC):
```bash
make clean
```

---

## ğŸ— Arquitectura del Pipeline

```mermaid
flowchart TD
    A[ğŸ“‚ data/raw/*.csv] -->|limpieza inicial| B[ğŸ”µ turkish_music_emotion_cleaned.csv]
    B -->|formalizaciÃ³n| C[ğŸ“¦ v1_original.csv - 400 filas]
    C -->|limpieza alineada| D[ğŸ”„ v2_cleaned_aligned.csv - 400 filas]
    C -->|limpieza completa| E[â­ v2_cleaned_full.csv - 408 filas]
    
    E -->|DVC tracking| F[â˜ï¸ AWS S3]
    E -->|DatasetManager| G[ğŸ”§ acoustic_ml/dataset.py]
    G -->|feature engineering| H[âš™ï¸ acoustic_ml/features.py]
    H -->|sklearn pipeline| I[ğŸ¯ acoustic_ml/modeling/sklearn_pipeline.py]
    I --> J[ğŸ’¾ models/production_pipeline.pkl]
    I --> K[ğŸ“ˆ metrics/metrics.json]
    J -->|log_model| L[MLflow Tracking]
    K -->|log_metrics| L
    L --> M[ğŸ–¥ MLflow UI :5001]
    
    style E fill:#90EE90,stroke:#228B22,stroke-width:3px
    style A fill:#e1f5ff
    style F fill:#fff4e1
    style J fill:#e8f5e9
    style M fill:#f3e5f5
    style G fill:#ffe4e1
    style H fill:#e6f3ff
    style I fill:#fff9c4
```

**Flujo de trabajo optimizado:**

1. ğŸ“¥ Datos crudos en `data/raw/` (versionados con DVC)
2. ğŸ”§ Primera limpieza â†’ `turkish_music_emotion_cleaned.csv` (histÃ³rico)
3. ğŸ“¦ FormalizaciÃ³n â†’ `v1_original.csv` (400 filas, baseline)
4. ğŸ”„ Limpieza alineada â†’ `v2_cleaned_aligned.csv` (400 filas, comparaciÃ³n)
5. â­ Limpieza completa â†’ `v2_cleaned_full.csv` (408 filas, **PRODUCCIÃ“N**)
6. â˜ï¸ Almacenamiento en S3 para colaboraciÃ³n
7. ğŸ”§ **DatasetManager** (Singleton thread-safe) gestiona carga/validaciÃ³n
8. âš™ï¸ **FeaturePipeline** transforma datos con transformers especializados
9. ğŸ¯ **SklearnMLPipeline** integra preprocessing + modelo en un Ãºnico objeto â­ NUEVO
10. ğŸ’¾ Modelos entrenados se guardan en `models/`
11. ğŸ“ˆ Experimentos y artefactos se registran en MLflow
12. ğŸ“Š MÃ©tricas se trackean con DVC
13. âœ… Todo es reproducible, versionado y testado (37 tests)
14. ğŸ›¡ï¸ Robusto a outliers con RobustScaler y anÃ¡lisis cuantitativo

---

## ğŸ¤ ContribuciÃ³n

### Flujo de trabajo

1. **Verificar sincronizaciÃ³n:**
   ```bash
   make verify-sync
   ```

2. **Crear una nueva rama:**
   ```bash
   git checkout -b feat/nombre-descriptivo
   ```

3. **Realizar cambios:**
   
   **Si modificas cÃ³digo Python:**
   ```bash
   # Edita archivos en acoustic_ml/
   vim acoustic_ml/features.py
   
   # Los cambios estÃ¡n disponibles inmediatamente (instalaciÃ³n en modo -e)
   
   # Ejecutar tests relevantes
   python scripts/validate_features.py
   ```

   **Si modificas datos:**
   ```bash
   dvc add data
   git add data.dvc data/.gitignore
   dvc push
   ```

   **Si instalaste paquetes:**
   ```bash
   make freeze
   git add requirements.txt
   ```

4. **Commitear cambios:**
   ```bash
   git add .
   git commit -m "feat: descripciÃ³n clara del cambio"
   ```

5. **Subir cambios:**
   ```bash
   git push origin feat/nombre-descriptivo
   dvc push  # o: make push
   ```

6. **Crear Pull Request** a la rama `main`

### Buenas prÃ¡cticas

- âœ… Ejecuta `make verify-sync` antes de comenzar a trabajar
- âœ… **SIEMPRE usa `DatasetManager` para gestionar datos**
- âœ… **Usa `create_sklearn_pipeline()` para pipelines de producciÃ³n** â­ NUEVO
- âœ… **Usa `RobustScaler` para manejo de outliers** (no OutlierRemover)
- âœ… **Ejecuta tests de validaciÃ³n antes de commit** (`validate_*.py`)
- âœ… **Prueba el pipeline completo** con `test_sklearn_pipeline.py`
- âœ… Documenta la versiÃ³n de dataset en MLflow tags
- âœ… Ejecuta `dvc status` para verificar estado de datos
- âœ… Ejecuta `make reproduce` antes de hacer commit
- âœ… Documenta tus experimentos en MLflow
- âœ… Escribe mensajes de commit descriptivos ([Conventional Commits](https://www.conventionalcommits.org/))
- âœ… MantÃ©n el cÃ³digo limpio y con docstrings
- âœ… Usa `make nb-hooks` para configurar hooks de notebooks
- âœ… Escribe cÃ³digo en el mÃ³dulo `acoustic_ml/`, no en notebooks
- âœ… Siempre haz `dvc push` despuÃ©s de modificar datos
- âœ… **MantÃ©n los tests actualizados** cuando agregues funcionalidades

---

## ğŸ‘¥ **Equipo de Desarrollo**

<div align="center">

<table style="width:100%; border:none;">
  <tr>
    <td align="center" style="border:none; padding:20px 10px;">
      <img src="https://iili.io/Kw90kmB.png" alt="David Cruz BeltrÃ¡n" width="160" style="border-radius: 50%; border: 5px solid #667eea; box-shadow: 0 8px 16px rgba(102, 126, 234, 0.4);"/>
      <h3>David Cruz BeltrÃ¡n</h3>
      <img src="https://img.shields.io/badge/ID-A01360416-667eea?style=for-the-badge" alt="MatrÃ­cula"/>
      <p><strong>ğŸ”§ Software Engineer</strong><br/>
      <em>Data Pipeline & Versioning</em></p>
    </td>
    <td align="center" style="border:none; padding:20px 10px;">
      <img src="https://iili.io/KuvsGKx.png" alt="Javier Augusto Rebull Saucedo" width="160" style="border-radius: 50%; border: 5px solid #764ba2; box-shadow: 0 8px 16px rgba(118, 75, 162, 0.4);"/>
      <h3>Javier Augusto Rebull Saucedo</h3>
      <img src="https://img.shields.io/badge/ID-A01795838-764ba2?style=for-the-badge" alt="MatrÃ­cula"/>
      <p><strong>âš™ï¸ SRE / Data Engineer</strong><br/>
      <em>DevOps & Infrastructure</em></p>
    </td>
    <td align="center" style="border:none; padding:20px 10px;">
      <img src="https://iili.io/Kw91d74.png" alt="Sandra Luz Cervantes Espinoza" width="160" style="border-radius: 50%; border: 5px solid #f093fb; box-shadow: 0 8px 16px rgba(240, 147, 251, 0.4);"/>
      <h3>Sandra Luz Cervantes Espinoza</h3>
      <img src="https://img.shields.io/badge/ID-A01796937-f093fb?style=for-the-badge" alt="MatrÃ­cula"/>
      <p><strong>ğŸ¤– ML Engineer / Data Scientist</strong><br/>
      <em>Model Development & Analysis</em></p>
    </td>
  </tr>
</table>

</div>

---

<div align="center">

**â­ Si este proyecto te resulta Ãºtil, considera darle una estrella**

Desarrollado con â¤ï¸ por el Equipo 24 | Estructura basada en [Cookiecutter Data Science](https://drivendata.github.io/cookiecutter-data-science/)

**ğŸ—ï¸ Refactorizado con SOLID Principles & Design Patterns** | **ğŸ§ª 100% Tested (37/37 passing)** | **ğŸ¯ Production-Ready Sklearn Pipeline**

</div>
