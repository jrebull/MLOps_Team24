# ğŸ” AnÃ¡lisis Completo: Problema de ClasificaciÃ³n "Angry"

## ğŸ“‹ Contexto

El modelo de Turkish Music Emotion Recognition tiene un problema especÃ­fico con la clase **"Angry"**:
- âœ… Test accuracy de "angry": **86%** (bastante bueno)
- âŒ Predicciones en audios reales de sample_audio: **Fallan consistentemente**

**Observaciones:**
```
âœ… sad/harman_yeri_surseler_salih_gundogdu.mp3 â†’ PredicciÃ³n: sad (correcto)
âœ… relax/fikret_kizilok_gonul.mp3 â†’ PredicciÃ³n: relax (correcto)
âŒ happy/gir_kanima_harun_kolcak.mp3 â†’ PredicciÃ³n: angry (incorrecto, esperado: happy)
âŒ angry/adanali.mp3 â†’ PredicciÃ³n: relax (incorrecto, esperado: angry)
```

Este anÃ¡lisis investiga las **causas raÃ­z** de este problema.

---

## ğŸ¯ HipÃ³tesis a Investigar

### 1ï¸âƒ£ **Dataset Imbalance**
- Â¿Hay suficientes samples de "angry" en training?
- Â¿EstÃ¡ desbalanceado respecto a otras clases?

### 2ï¸âƒ£ **Feature Distribution Mismatch**
- Â¿Los audios de sample_audio tienen features consistentes con training?
- Â¿Hay "distribution drift"?

### 3ï¸âƒ£ **Confusion Patterns**
- Â¿Con quÃ© emociones se confunde "angry" mÃ¡s frecuentemente?
- Â¿Hay overlap en feature space?

### 4ï¸âƒ£ **Feature Discriminability**
- Â¿QuÃ© features son crÃ­ticas para identificar "angry"?
- Â¿Son suficientemente discriminativas?

---

## ğŸ› ï¸ Scripts de AnÃ¡lisis

Se crearon 4 scripts especializados (siguiendo MLOps best practices):

### **Script 1: `analyze_1_dataset_distribution.py`**
**Objetivo:** Analizar distribuciÃ³n de clases y balance del dataset

**Output:**
- Conteo de samples por clase
- MÃ©tricas de balance (min/max ratio)
- EstadÃ­sticas de features por clase
- VerificaciÃ³n de NaN values y duplicados

### **Script 2: `analyze_2_confusion_matrix.py`**
**Objetivo:** Generar confusion matrix detallada y analizar patrones de error

**Output:**
- Confusion matrix absoluta y normalizada
- AnÃ¡lisis de errores por clase
- **Focus especÃ­fico en "Angry"**: Con quÃ© se confunde y quÃ© se confunde como angry
- Classification report completo
- VisualizaciÃ³n (confusion_matrix_angry_analysis.png)

### **Script 3: `analyze_3_sample_audio_features.py`**
**Objetivo:** Extraer features de sample_audio y comparar con training set

**Output:**
- Features extraÃ­dos de todos los audios en sample_audio/
- ComparaciÃ³n estadÃ­stica (mean, std, Z-scores) con training set
- IdentificaciÃ³n de features con distribuciÃ³n diferente
- Predicciones del modelo en sample audios
- Accuracy por emociÃ³n en sample_audio
- CSV con features (sample_audio_features_analysis.csv)

### **Script 4: `analyze_4_feature_importance.py`**
**Objetivo:** Analizar quÃ© features son importantes para clasificar "angry"

**Output:**
- Feature importance del Random Forest
- DistribuciÃ³n de top features para "angry" vs otras clases
- Cohen's d (effect size) para medir discriminabilidad
- ComparaciÃ³n "angry" vs cada emociÃ³n individual
- DetecciÃ³n de outliers en samples "angry"
- CSV con feature importance (feature_importance_analysis.csv)

---

## ğŸš€ Instrucciones de Uso

### **PreparaciÃ³n:**

1. **Navegar al directorio del proyecto:**
```bash
cd /Users/haowei/Documents/MLOps/MNA_Team24/MLOps_Team24
```

2. **Activar entorno virtual:**
```bash
source .venv/bin/activate  # macOS/Linux
```

3. **Verificar que tienes los datos:**
```bash
ls data/processed/turkish_music_emotion_v2_cleaned_full.csv
ls turkish_music_app/assets/sample_audio/
```

---

### **OpciÃ³n A: Ejecutar AnÃ¡lisis Completo (RECOMENDADO)**

```bash
python3 run_complete_analysis.py
```

Esto ejecutarÃ¡ los 4 scripts en secuencia y generarÃ¡ un reporte consolidado.

---

### **OpciÃ³n B: Ejecutar Scripts Individuales**

```bash
# Script 1: Dataset Distribution
python3 analyze_1_dataset_distribution.py

# Script 2: Confusion Matrix
python3 analyze_2_confusion_matrix.py

# Script 3: Sample Audio Features
python3 analyze_3_sample_audio_features.py

# Script 4: Feature Importance
python3 analyze_4_feature_importance.py
```

---

## ğŸ“Š Archivos Generados

DespuÃ©s de ejecutar los anÃ¡lisis, tendrÃ¡s:

```
confusion_matrix_angry_analysis.png     # VisualizaciÃ³n de confusion matrix
sample_audio_features_analysis.csv      # Features de sample_audio
feature_importance_analysis.csv         # Feature importance del modelo
```

---

## ğŸ”¬ MetodologÃ­a de AnÃ¡lisis

Este anÃ¡lisis sigue **MLOps best practices** para debugging de modelos:

### **1. Data-Centric Approach**
- Primero verificamos la calidad y distribuciÃ³n de los datos
- Identificamos desbalances, outliers, NaN values

### **2. Model-Centric Analysis**
- Analizamos cÃ³mo el modelo estÃ¡ clasificando (confusion matrix)
- Identificamos patrones de error sistemÃ¡ticos

### **3. Feature Engineering Validation**
- Verificamos que las features extraÃ­das sean consistentes
- Comparamos training vs inference features

### **4. Interpretability**
- Usamos feature importance para entender decisiones del modelo
- Medimos discriminabilidad con Cohen's d

---

## ğŸ¯ InterpretaciÃ³n de Resultados

### **Dataset Distribution (Script 1)**

**Si encuentras:**
- Balance ratio < 70% â†’ âš ï¸ Dataset desbalanceado
- NaN values > 0 â†’ âš ï¸ Problemas de calidad de datos
- Una clase tiene < 50 samples â†’ âš ï¸ Insuficientes datos

**AcciÃ³n:** Considerar rebalanceo, limpieza, o recolecciÃ³n de mÃ¡s datos

---

### **Confusion Matrix (Script 2)**

**Si encuentras:**
- "Angry" se confunde >20% con una emociÃ³n especÃ­fica â†’ âš ï¸ Overlap semÃ¡ntico
- Accuracy de "angry" < 70% â†’ âš ï¸ Problema grave
- Patrones asimÃ©tricos (Aâ†’B pero no Bâ†’A) â†’ ğŸ” Investigar features

**AcciÃ³n:** Identificar quÃ© causa la confusiÃ³n especÃ­fica

---

### **Sample Audio Features (Script 3)**

**Si encuentras:**
- Z-score > 2.0 en >5 features â†’ âš ï¸ Distribution drift significativo
- Accuracy en sample_audio << test accuracy â†’ âš ï¸ Sample audio no representativo
- Todas las emociones fallan excepto angry â†’ ğŸ” Problema de preprocessing

**AcciÃ³n:** 
- Verificar que AudioFeatureExtractor usa mismos parÃ¡metros que training
- Revisar si sample_audio es representativo
- Re-extraer features con configuraciÃ³n consistente

---

### **Feature Importance (Script 4)**

**Si encuentras:**
- Cohen's d < 0.3 para top features â†’ âš ï¸ Features poco discriminativas
- "Angry" tiene alta varianza en features importantes â†’ âš ï¸ Clase heterogÃ©nea
- Top features tienen outliers en angry â†’ âš ï¸ Problemas de calidad

**AcciÃ³n:**
- Considerar feature engineering adicional
- Ajustar hyperparÃ¡metros del modelo
- Limpiar outliers si son errores de extracciÃ³n

---

## ğŸ“ˆ Plan de AcciÃ³n Post-AnÃ¡lisis

Basado en los hallazgos, el siguiente flujo de decisiÃ³n:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Â¿Dataset desbalanceado?         â”‚
â”‚ (Script 1)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â”œâ”€ SÃ â†’ Rebalancear con SMOTE / class_weight
        â”‚
        â””â”€ NO â†’ Continuar
                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Â¿Sample audio no representativo?â”‚
        â”‚ (Script 3)                      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â”œâ”€ SÃ â†’ Probar con mÃ¡s audios / revisar labels
                â”‚
                â””â”€ NO â†’ Continuar
                            â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚ Â¿Features poco discriminativas? â”‚
                â”‚ (Script 4)                      â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â”œâ”€ SÃ â†’ Feature engineering / cambiar modelo
                        â”‚
                        â””â”€ NO â†’ Ajustar hyperparÃ¡metros
```

---

## âš™ï¸ ConfiguraciÃ³n TÃ©cnica

**Requisitos:**
- Python 3.12+
- scikit-learn 1.7.2
- pandas, numpy, matplotlib, seaborn
- MLflow
- acoustic_ml package instalado

**MLflow Run ID:**
- Modelo actual: `eb05c7698f12499b86ed35ca6efc15a7`
- Test accuracy: 84.30%

**Dataset:**
- Path: `data/processed/turkish_music_emotion_v2_cleaned_full.csv`
- Total samples: 403 (despuÃ©s de limpieza)
- Features: 50 acoustic features

---

## ğŸ“ Notas Adicionales

### **Sobre Cohen's d (Effect Size):**
- **d < 0.2**: Diferencia pequeÃ±a
- **d = 0.5**: Diferencia mediana
- **d > 0.8**: Diferencia grande

Para clasificaciÃ³n, queremos **d > 0.5** en features importantes.

### **Sobre Z-scores:**
- **Z > 2.0**: Valor a mÃ¡s de 2 desviaciones estÃ¡ndar del mean
- Indica que sample_audio tiene features "fuera de lo normal"

### **Sobre Confusion Matrix:**
- Diagonal = Predicciones correctas
- Off-diagonal = Errores
- NormalizaciÃ³n por fila muestra "recall" por clase

---

## ğŸ¤ Siguientes Pasos para el Equipo

1. **Ejecutar anÃ¡lisis** y compartir resultados en el grupo
2. **Documentar hallazgos** en un documento colaborativo
3. **Decidir estrategia** de correcciÃ³n basada en evidencia
4. **Implementar cambios** siguiendo MLOps workflow (DVC + MLflow)
5. **Re-entrenar y validar** mejoras

---

## ğŸ“§ Contacto

**MLOps Team 24:**
- David Cruz BeltrÃ¡n (Software Engineer)
- Javier Augusto Rebull Saucedo (SRE/Data Engineer)
- Sandra Luz Cervantes Espinoza (ML Engineer/Data Scientist)

**Proyecto:** Turkish Music Emotion Recognition
**Fase:** 2 (MLOps Implementation)
**PrÃ³ximo deadline:** Fase 3 (Production Deployment)

---

**Â¡Ã‰xito con el anÃ¡lisis!** ğŸš€
