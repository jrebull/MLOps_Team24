# ğŸ§  DocumentaciÃ³n del Pipeline de Machine Learning

## ğŸ“˜ DescripciÃ³n General

Este documento explica el **pipeline de Machine Learning (ML)** desarrollado para este proyecto de **MLOps**, detallando sus etapas principales: **carga de datos, preprocesamiento, entrenamiento, evaluaciÃ³n y seguimiento de experimentos** mediante herramientas como MLflow.

El objetivo es garantizar un flujo automatizado, reproducible y escalable para el desarrollo y despliegue de modelos de ML en entornos productivos.

---

## ğŸ“‚ Arquitectura del Pipeline

La arquitectura del pipeline estÃ¡ organizada en mÃ³dulos independientes, facilitando su mantenimiento y evoluciÃ³n:

```
mlops/
â”‚
â”œâ”€â”€ data_loader.py         # Carga de datos (CSV, bases de datos, APIs)
â”œâ”€â”€ preprocessor.py        # Limpieza y transformaciÃ³n de datos
â”œâ”€â”€ model_trainer.py       # Entrenamiento y validaciÃ³n de modelos
â”œâ”€â”€ evaluator.py           # EvaluaciÃ³n y mÃ©tricas de rendimiento
â”œâ”€â”€ tracking.py            # Registro y seguimiento de experimentos (MLflow)
â””â”€â”€ utils/                 # Funciones auxiliares
```

---

## ğŸ“¥ Carga de Datos (`DataLoader`)

El mÃ³dulo **DataLoader** se encarga de la ingesta de datos desde diversas fuentes y de la validaciÃ³n inicial.

### Funcionalidades principales:

* Admite mÃºltiples formatos: `.csv`, `.parquet`, SQL, API REST.
* Valida el esquema de columnas y tipos de datos.
* Maneja errores de lectura y archivos faltantes.

### Ejemplo de uso:

```python
from ml_pipeline import DataLoader
loader = DataLoader(path='data/interim/turkish_music_emotion_cleaned.csv')
df = loader.load_csv()
```

---

#### ğŸ“¦ VersiÃ³n 1: Original (v1_original)

```
ğŸ“ UbicaciÃ³n: data/processed/turkish_music_emotion_v1_original.csv
ğŸ“ Dimensiones: 400 filas Ã— 21 columnas
ğŸ¯ Uso: Baseline y comparaciones histÃ³ricas
ğŸ”– Estado: Referencia oficial (sin modificaciones)
```

**CaracterÃ­sticas:**
- Dataset crudo sin modificaciones post-descarga
- Incluye todas las inconsistencias originales del dataset fuente
- Punto de referencia oficial para todas las comparaciones
- Ãštil para reproducir anÃ¡lisis iniciales y validar mejoras

**Mejoras respecto a versiÃ³n 0:**
- âœ… Versionado formal con DVC
- âœ… DocumentaciÃ³n estructurada
- âœ… Punto de referencia estable

**CuÃ¡ndo usar:**
- âœ… Baseline para comparar todas las versiones posteriores
- âœ… ValidaciÃ³n de procesos de limpieza aplicados
- âœ… DocumentaciÃ³n de transformaciones histÃ³ricas
- âœ… ReproducciÃ³n de experimentos iniciales del proyecto
- âŒ NO recomendado para entrenar nuevos modelos

---

#### ğŸ”„ VersiÃ³n 2: Limpia Alineada (v2_cleaned_aligned)

```
ğŸ“ UbicaciÃ³n: data/processed/turkish_music_emotion_v2_cleaned_aligned.csv
ğŸ“ Dimensiones: 400 filas Ã— 21 columnas
ğŸ¯ Uso: Comparaciones directas fila por fila con v1
ğŸ”– Estado: ProducciÃ³n (anÃ¡lisis comparativos)
```

**CaracterÃ­sticas:**
- Dataset limpio manteniendo exactamente las 400 filas originales
- Mismo orden y estructura que v1_original para facilitar diffs
- Valores faltantes imputados con estrategias estadÃ­sticas
- Outliers corregidos sin eliminar filas
- Perfecta alineaciÃ³n 1:1 con v1 para anÃ¡lisis de impacto

**Mejoras respecto a v1:**
- âœ… Limpieza sistemÃ¡tica de valores faltantes
- âœ… CorrecciÃ³n de outliers estadÃ­sticos
- âœ… NormalizaciÃ³n de features numÃ©ricas
- âœ… ValidaciÃ³n de consistencia de datos
- âœ… PreservaciÃ³n de estructura original (400 filas)

**CuÃ¡ndo usar:**
- âœ… AnÃ¡lisis de impacto de limpieza (antes/despuÃ©s)
- âœ… ValidaciÃ³n de transformaciones especÃ­ficas fila por fila
- âœ… Reportes que comparan resultados con/sin limpieza
- âœ… AuditorÃ­a de cambios aplicados al dataset
- âš ï¸ Puede usarse para entrenar modelos, pero v2_cleaned_full es superior

---

#### â­ VersiÃ³n 3: Limpia Completa (v2_cleaned_full) **[RECOMENDADO]**

```
ğŸ“ UbicaciÃ³n: data/processed/turkish_music_emotion_v2_cleaned_full.csv
ğŸ“ Dimensiones: 408 filas Ã— 21 columnas
ğŸ¯ Uso: Entrenamiento de modelos de producciÃ³n
ğŸ”– Estado: ProducciÃ³n (versiÃ³n oficial para ML)
```

**CaracterÃ­sticas:**
- Dataset limpio mÃ¡s completo del proyecto (+8 filas adicionales)
- MÃ¡xima calidad y cantidad de datos para Machine Learning
- Duplicados inteligentemente consolidados sin pÃ©rdida de informaciÃ³n
- Outliers corregidos manteniendo variabilidad natural
- Features normalizadas y validadas para ML
- Estrategias avanzadas de imputaciÃ³n de valores faltantes

**Mejoras respecto a v2_aligned:**
- âœ… +8 filas adicionales recuperadas mediante anÃ¡lisis avanzado
- âœ… ConsolidaciÃ³n inteligente de duplicados (preservando informaciÃ³n Ãºnica)
- âœ… ImputaciÃ³n avanzada de valores faltantes (KNN, iterativa)
- âœ… DetecciÃ³n y correcciÃ³n robusta de outliers multivariados
- âœ… ValidaciÃ³n cruzada de consistencia en todas las features
- âœ… MÃ¡xima representatividad del espacio de caracterÃ­sticas

**CuÃ¡ndo usar:**
- âœ… **Entrenamiento de todos los modelos nuevos** (PRIMERA OPCIÃ“N)
- âœ… ExperimentaciÃ³n y bÃºsqueda de hiperparÃ¡metros
- âœ… EvaluaciÃ³n de performance de modelos
- âœ… Pipeline de producciÃ³n y despliegue
- âœ… Benchmarking y competiciones internas
- âœ… ValidaciÃ³n final de modelos antes de producciÃ³n

---

### ğŸ“‹ ComparaciÃ³n RÃ¡pida de Versiones

| VersiÃ³n | Archivo | Filas | Uso Principal | Estado | RecomendaciÃ³n |
|---------|---------|-------|---------------|--------|---------------|
| **v0** | `turkish_music_emotion_cleaned.csv` | Variable | HistÃ³rico (notebook inicial) | ğŸ“š Archivo | âŒ No usar |
| **v1** | `v1_original.csv` | 400 | Baseline sin modificar | ğŸ“– Referencia | Solo comparaciones |
| **v2a** | `v2_cleaned_aligned.csv` | 400 | ComparaciÃ³n directa con v1 | ğŸ”„ AnÃ¡lisis | AnÃ¡lisis de impacto |
| **v3** | `v2_cleaned_full.csv` | 408 | **Entrenamiento ML** | â­ ProducciÃ³n | **âœ… USAR ESTO** |

---


### ğŸ”§ CÃ³mo usar cada versiÃ³n en cÃ³digo

#### Ejemplo 1: Cargar versiÃ³n recomendada

```python
from acoustic_ml.dataset import load_processed_data

# VersiÃ³n recomendada para ML
df_full = load_processed_data("turkish_music_emotion_v2_cleaned_full.csv")
print(f"âœ… Dataset Ã³ptimo cargado: {df_full.shape[0]} filas")
```

#### Ejemplo 2: AnÃ¡lisis comparativo entre versiones

```python
from acoustic_ml.dataset import load_processed_data
import pandas as pd

# Cargar las 3 versiones principales
df_v1 = load_processed_data("turkish_music_emotion_v1_original.csv")
df_v2a = load_processed_data("turkish_music_emotion_v2_cleaned_aligned.csv")
df_v3 = load_processed_data("turkish_music_emotion_v2_cleaned_full.csv")

# Comparar dimensiones
print(f"v1_original:        {df_v1.shape[0]} filas")
print(f"v2_cleaned_aligned: {df_v2a.shape[0]} filas")
print(f"v2_cleaned_full:    {df_v3.shape[0]} filas (+{df_v3.shape[0] - df_v2a.shape[0]} filas)")

# Comparar calidad de datos
print("\nğŸ“Š Valores faltantes por versiÃ³n:")
print(f"v1: {df_v1.isnull().sum().sum()} valores faltantes")
print(f"v2a: {df_v2a.isnull().sum().sum()} valores faltantes")
print(f"v3: {df_v3.isnull().sum().sum()} valores faltantes")
```

#### Ejemplo 3: Uso en notebooks

```python
import pandas as pd
from acoustic_ml.config import PROCESSED_DATA_DIR

# MÃ©todo 1: Usando el mÃ³dulo
from acoustic_ml.dataset import load_processed_data
df = load_processed_data("turkish_music_emotion_v2_cleaned_full.csv")

# MÃ©todo 2: Carga directa con pandas
df = pd.read_csv(PROCESSED_DATA_DIR / "turkish_music_emotion_v2_cleaned_full.csv")

print(f"âœ… Dataset cargado: {df.shape[0]} filas, {df.shape[1]} columnas")
print(f"ğŸ“ UbicaciÃ³n: {PROCESSED_DATA_DIR}")
```

#### Ejemplo 4: ValidaciÃ³n de versiÃ³n correcta

```python
from acoustic_ml.dataset import load_processed_data

def validate_dataset_version(df, expected_rows=408):
    """Valida que estÃ©s usando la versiÃ³n correcta del dataset"""
    if df.shape[0] == expected_rows:
        print(f"âœ… Usando v2_cleaned_full ({expected_rows} filas) - CORRECTO")
        return True
    else:
        print(f"âš ï¸  Advertencia: {df.shape[0]} filas (esperadas: {expected_rows})")
        print("ğŸ’¡ Considera usar 'turkish_music_emotion_v2_cleaned_full.csv'")
        return False

# Uso
df = load_processed_data("turkish_music_emotion_v2_cleaned_full.csv")
validate_dataset_version(df)
```

---

### ğŸ¯ Casos de Uso por VersiÃ³n

#### Cuando usar `turkish_music_emotion_cleaned.csv`:
- ğŸ” AuditorÃ­a histÃ³rica del primer proceso de limpieza
- ğŸ“– DocumentaciÃ³n de evoluciÃ³n del proyecto
- âŒ **NUNCA para entrenamiento de modelos**

#### Cuando usar `v1_original.csv`:
- ğŸ“Š Establecer baseline de performance
- ğŸ“ˆ Medir impacto de limpieza en mÃ©tricas
- ğŸ“ Documentar transformaciones aplicadas
- âš–ï¸ Comparar con estado original del dataset

#### Cuando usar `v2_cleaned_aligned.csv`:
- ğŸ”¬ AnÃ¡lisis fila por fila de cambios aplicados
- ğŸ“Š Estudios de impacto de limpieza especÃ­fica
- ğŸ” Validar que la limpieza preserva estructura
- ğŸ“‰ ComparaciÃ³n directa antes/despuÃ©s (400 filas constantes)

#### Cuando usar `v2_cleaned_full.csv` â­:
- ğŸ¤– **Entrenar TODOS los modelos nuevos**
- ğŸ”§ Ajuste de hiperparÃ¡metros
- ğŸ“Š EvaluaciÃ³n de performance
- ğŸš€ Despliegue en producciÃ³n
- ğŸ† Competiciones y benchmarks
- âœ… Cualquier tarea de Machine Learning

---

## ğŸ§¹ Preprocesamiento (`Preprocessor`)

El **Preprocessor** transforma los datos brutos en un formato adecuado para el modelado.

### Etapas principales:

1. **EliminaciÃ³n de duplicados** â€“ Evita la redundancia en los datos.
2. **EliminaciÃ³n de columnas constantes** â€“ Quita variables sin informaciÃ³n relevante.
3. **CodificaciÃ³n de etiquetas** â€“ Transforma variables categÃ³ricas a formato numÃ©rico.
4. **NormalizaciÃ³n de datos sesgados** â€“ Aplica transformaciones logarÃ­tmicas o Box-Cox.
5. **DetecciÃ³n de outliers** â€“ Filtra valores extremos mediante Z-score o IQR.

### Ejemplo:

```python
from ml_pipeline import Preprocessor
pre = Preprocessor(df)
pre.drop_duplicates()
pre.encode_labels()
pre.normalize_skewed(threshold=0.5)
clean_df = pre.get_clean_df()
```

---

## âš™ï¸ Entrenamiento de Modelos (`ModelTrainer`)

El mÃ³dulo **ModelTrainer** maneja la separaciÃ³n de datos, el escalado y el entrenamiento de distintos modelos de ML.

### Funcionalidades:

* DivisiÃ³n de datos en entrenamiento y prueba (train/test split).
* Escalado mediante `StandardScaler` o `MinMaxScaler`.
* Modelos disponibles: **RegresiÃ³n LogÃ­stica**, **KNN**, **Random Forest**, **XGBoost**.
* Soporte para **validaciÃ³n cruzada (cross-validation)**.

### Ejemplo:

```python
trainer = ModelTrainer(clean_df)
trainer.split_and_scale(test_size=0.2)
trainer.train_logistic()
```

---

## ğŸ“Š EvaluaciÃ³n de Modelos (`Evaluator`)

El **Evaluator** calcula las mÃ©tricas clave del desempeÃ±o del modelo y genera visualizaciones de resultados.

### MÃ©tricas incluidas:

* Accuracy (exactitud)
* Precision, Recall, F1-score
* ROC-AUC
* Matriz de confusiÃ³n

### Ejemplo:

```python
from ml_pipeline import Evaluator
eval = Evaluator(model, X_test, y_test)
eval.compute_metrics()
eval.plot_confusion_matrix()
```

---

## ğŸ“ˆ Seguimiento de Experimentos (`Tracking`)

El mÃ³dulo **Tracking** utiliza **MLflow** para registrar parÃ¡metros, mÃ©tricas y versiones de modelos.

### CaracterÃ­sticas:

* Guarda los resultados de cada ejecuciÃ³n de entrenamiento.
* Permite comparar experimentos con distintas configuraciones.
* Compatible con almacenamiento local o remoto (S3, Databricks, GCP, etc.).

### Ejemplo:

```python
from ml_pipeline import Tracking
track = Tracking(experiment_name='ml_pipeline_v1')
track.log_params(params)
track.log_metrics(metrics)
track.log_model(model)
```

---

## ğŸ§ª Pruebas Unitarias

El proyecto utiliza **pytest** para validar el correcto funcionamiento de cada componente del pipeline.

```bash
pytest tests/test_ml_pipeline.py -v
```

Las pruebas cubren la carga de datos, la limpieza, la transformaciÃ³n, el entrenamiento y la evaluaciÃ³n de modelos.

---

## ğŸš€ Despliegue e IntegraciÃ³n

Una vez validado el modelo, puede:

* Serializarse con `joblib`, `pickle` o almacenarse en **MLflow Models**.
* Servirse mediante **FastAPI**, **AWS Lambda** o **Docker**.

### Ejemplo de endpoint en FastAPI:

```python
@app.post('/predict')
def predict(data: InputSchema):
    input_df = pd.DataFrame([data.dict()])
    prediction = model.predict(input_df)
    return {"prediccion": int(prediction[0])}
```

---

## ğŸ” AutomatizaciÃ³n CI/CD

Integrado con herramientas como:

* **GitHub Actions** o **GitLab CI**: ejecuciÃ³n automÃ¡tica de pruebas y despliegues.
* **Docker**: contenedorizaciÃ³n del entorno.
* **MLflow Model Registry**: control de versiones y promociÃ³n de modelos.

---

## ğŸ“š Referencias

* [DocumentaciÃ³n de MLflow](https://mlflow.org/docs/latest/index.html)
* [GuÃ­a de scikit-learn](https://scikit-learn.org/stable/user_guide.html)
* [DocumentaciÃ³n de FastAPI](https://fastapi.tiangolo.com/)
* [Buenas PrÃ¡cticas en MLOps (Google Cloud)](https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning)
