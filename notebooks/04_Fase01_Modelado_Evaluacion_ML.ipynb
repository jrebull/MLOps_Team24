{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¤– Operaciones de Aprendizaje AutomÃ¡tico (MLOps)\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "![Institution](https://img.shields.io/badge/ğŸ›ï¸_ITESM-TecnolÃ³gico_de_Monterrey-003366?style=flat-square&labelColor=002147)\n",
    "![Program](https://img.shields.io/badge/ğŸ“_MaestrÃ­a-Inteligencia_Artificial_Aplicada-7B2CBF?style=flat-square&labelColor=5A189A)\n",
    "![Phase](https://img.shields.io/badge/ğŸ¤–_Fase_2-Modelado_y_EvaluaciÃ³n-10B981?style=flat-square&labelColor=059669)\n",
    "![Deadline](https://img.shields.io/badge/ğŸ“…_Entrega-13_Octubre_2025-EF4444?style=flat-square&labelColor=DC2626)\n",
    "\n",
    "</div>\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "```\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘                   ğŸ¼ TURKISH MUSIC EMOTION                    â•‘\n",
    "â•‘         Machine Learning Model Training & Evaluation          â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "```\n",
    "\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ‘¨â€ğŸ« **Equipo Docente**\n",
    "\n",
    "<table align=\"center\" style=\"border: none;\">\n",
    "<tr>\n",
    "<td width=\"50%\" style=\"border: none;\">\n",
    "\n",
    "**ğŸ‘” Profesores Titulares**\n",
    "- Dr. Gerardo RodrÃ­guez HernÃ¡ndez\n",
    "- Maestro Ricardo Valdez HernÃ¡ndez\n",
    "\n",
    "</td>\n",
    "<td width=\"50%\" style=\"border: none;\">\n",
    "\n",
    "**ğŸ“ Equipo de Apoyo**\n",
    "- Maestra MarÃ­a Mylen TreviÃ±o Elizondo  \n",
    "  *Profesora Asistente*\n",
    "- M. en C. JosÃ© Ãngel MartÃ­nez Navarro  \n",
    "  *Profesor Tutor*\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ’¥ **Equipo de Desarrollo**\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "<table style=\"width:100%; border:none; background-color: #1a1a2e;\">\n",
    "<tr>\n",
    "<td align=\"center\" style=\"border:none; padding:20px 10px; background-color: #16213e; color: #ffffff;\">\n",
    "\n",
    "<img src=\"https://iili.io/Kw90kmB.png\" alt=\"David Cruz BeltrÃ¡n\" width=\"160\" style=\"border-radius: 50%; border: 5px solid #667eea; box-shadow: 0 8px 16px rgba(102, 126, 234, 0.4);\"/>\n",
    "\n",
    "<h3 style=\"color: #ffffff;\">David Cruz BeltrÃ¡n</h3>\n",
    "\n",
    "![Matricula](https://img.shields.io/badge/ID-A01360416-667eea?style=for-the-badge)\n",
    "\n",
    "<p style=\"color: #ffffff;\"><strong>ğŸ”§ Software Engineer</strong><br/>\n",
    "<em>Model Pipeline & Versioning</em></p>\n",
    "\n",
    "</td>\n",
    "<td align=\"center\" style=\"border:none; padding:20px 10px; background-color: #16213e; color: #ffffff;\">\n",
    "\n",
    "<img src=\"https://iili.io/KuvsGKx.png\" alt=\"Javier Augusto Rebull Saucedo\" width=\"160\" style=\"border-radius: 50%; border: 5px solid #764ba2; box-shadow: 0 8px 16px rgba(118, 75, 162, 0.4);\"/>\n",
    "\n",
    "<h3 style=\"color: #ffffff;\">Javier Augusto Rebull Saucedo</h3>\n",
    "\n",
    "![Matricula](https://img.shields.io/badge/ID-A01795838-764ba2?style=for-the-badge)\n",
    "\n",
    "<p style=\"color: #ffffff;\"><strong>âš™ï¸ SRE / Data Engineer</strong><br/>\n",
    "<em>Model Deployment & Monitoring</em></p>\n",
    "\n",
    "</td>\n",
    "<td align=\"center\" style=\"border:none; padding:20px 10px; background-color: #16213e; color: #ffffff;\">\n",
    "\n",
    "<img src=\"https://iili.io/Kw91d74.png\" alt=\"Sandra Luz Cervantes Espinoza\" width=\"160\" style=\"border-radius: 50%; border: 5px solid #f093fb; box-shadow: 0 8px 16px rgba(240, 147, 251, 0.4);\"/>\n",
    "\n",
    "<h3 style=\"color: #ffffff;\">Sandra Luz Cervantes Espinoza</h3>\n",
    "\n",
    "![Matricula](https://img.shields.io/badge/ID-A01796937-f093fb?style=for-the-badge)\n",
    "\n",
    "<p style=\"color: #ffffff;\"><strong>ğŸ¤– ML Engineer / Data Scientist</strong><br/>\n",
    "<em>Model Training & Optimization</em></p>\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ **Objetivos de la Fase 2**\n",
    "\n",
    "<table width=\"100%\">\n",
    "<tr>\n",
    "<td width=\"25%\" align=\"center\">\n",
    "\n",
    "### ğŸ—ï¸ **ConstrucciÃ³n**\n",
    "```\n",
    "ğŸ”¨ Baseline Models\n",
    "ğŸ§ª ExperimentaciÃ³n\n",
    "ğŸ“Š ComparaciÃ³n\n",
    "```\n",
    "\n",
    "</td>\n",
    "<td width=\"25%\" align=\"center\">\n",
    "\n",
    "### ğŸ›ï¸ **Ajuste**\n",
    "```\n",
    "ğŸ” Grid Search\n",
    "ğŸ² Random Search\n",
    "âš¡ Bayesian Opt\n",
    "```\n",
    "\n",
    "</td>\n",
    "<td width=\"25%\" align=\"center\">\n",
    "\n",
    "### ğŸ“Š **EvaluaciÃ³n**\n",
    "```\n",
    "ğŸ¯ Accuracy\n",
    "ğŸ“ˆ F1-Score\n",
    "ğŸ”¢ Confusion Matrix\n",
    "```\n",
    "\n",
    "</td>\n",
    "<td width=\"25%\" align=\"center\">\n",
    "\n",
    "### ğŸ’¾ **Versionado**\n",
    "```\n",
    "ğŸ“¦ Model Registry\n",
    "ğŸ·ï¸ Tagging\n",
    "â˜ï¸ DVC Push\n",
    "```\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¤– **Algoritmos a Evaluar**\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "| CategorÃ­a | Algoritmos | JustificaciÃ³n |\n",
    "|:---------:|:-----------|:--------------|\n",
    "| **ğŸŒ³ Tree-Based** | Random Forest, XGBoost, LightGBM | Robustos, manejan no-linealidad, feature importance |\n",
    "| **ğŸ¯ Linear** | Logistic Regression, SVM | Baseline rÃ¡pido, interpretable |\n",
    "| **ğŸ§  Neural** | MLP Classifier | Captura relaciones complejas |\n",
    "| **ğŸ“ Distance** | KNN | Simple, efectivo con normalizaciÃ³n |\n",
    "| **ğŸ² Ensemble** | Voting, Stacking | Combina fortalezas de mÃºltiples modelos |\n",
    "\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“Š **MÃ©tricas de EvaluaciÃ³n**\n",
    "\n",
    "<table width=\"100%\">\n",
    "<tr>\n",
    "<td width=\"33%\" align=\"center\">\n",
    "\n",
    "### ğŸ¯ **Principales**\n",
    "- **Accuracy**: ProporciÃ³n de predicciones correctas\n",
    "- **F1-Score**: Balance precision-recall\n",
    "- **Macro F1**: F1 promedio por clase\n",
    "\n",
    "</td>\n",
    "<td width=\"33%\" align=\"center\">\n",
    "\n",
    "### ğŸ” **Por Clase**\n",
    "- **Precision**: VP / (VP + FP)\n",
    "- **Recall**: VP / (VP + FN)\n",
    "- **Support**: Muestras por clase\n",
    "\n",
    "</td>\n",
    "<td width=\"33%\" align=\"center\">\n",
    "\n",
    "### ğŸ“ˆ **Visuales**\n",
    "- **Confusion Matrix**: Errores por clase\n",
    "- **ROC Curve**: Threshold analysis\n",
    "- **Learning Curves**: Overfitting check\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸš€ **Pipeline de Modelado**\n",
    "\n",
    "```mermaid\n",
    "graph LR\n",
    "    A[ğŸ“¥ Load Splits] --> B[ğŸ—ï¸ Baseline Models]\n",
    "    B --> C[ğŸ“Š Compare Results]\n",
    "    C --> D[ğŸ¯ Select Top 3]\n",
    "    D --> E[ğŸ›ï¸ Hyperparameter Tuning]\n",
    "    E --> F[ğŸ† Best Model]\n",
    "    F --> G[ğŸ“ˆ Final Evaluation]\n",
    "    G --> H[ğŸ’¾ Save & Version]\n",
    "    H --> I[â˜ï¸ DVC Push]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "### **ğŸµ De emociones musicales a predicciones precisas con MLOps ğŸ¤–**\n",
    "\n",
    "---\n",
    "\n",
    "![Made with Love](https://img.shields.io/badge/Made_with-â¤ï¸_and_ğŸµ-FF69B4?style=flat-square)\n",
    "![ITESM](https://img.shields.io/badge/ITESM-MNA_2025-003366?style=flat-square)\n",
    "![MLOps](https://img.shields.io/badge/MLOps-Phase_2-10B981?style=flat-square)\n",
    "\n",
    "---\n",
    "\n",
    "ğŸ“… **Fecha de entrega:** 13 de Octubre 2025 â€¢ 01:00 hrs  \n",
    "ğŸ“§ **Contacto:** A travÃ©s de Canvas\n",
    "\n",
    "---\n",
    "\n",
    "*Proyecto desarrollado como parte de la MaestrÃ­a en Inteligencia Artificial Aplicada*  \n",
    "*Instituto TecnolÃ³gico y de Estudios Superiores de Monterrey*\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ” PARTE 1: VALIDACIÃ“N DE ENTORNO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "================================================================================\n",
    "ğŸ” VALIDACIÃ“N DEL ENTORNO Y DEPENDENCIAS - MODELING PHASE\n",
    "================================================================================\n",
    "\"\"\"\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# ====================\n",
    "# 1. CONFIGURACIÃ“N DEL DIRECTORIO\n",
    "# ====================\n",
    "print(\"ğŸ“ Verificando directorio de trabajo...\")\n",
    "current_dir = Path.cwd()\n",
    "print(f\"   Directorio actual: {current_dir}\")\n",
    "\n",
    "# Si estamos en notebooks/, subir un nivel\n",
    "if current_dir.name == \"notebooks\":\n",
    "    project_root = current_dir.parent\n",
    "    os.chdir(project_root)\n",
    "    print(f\"   âœ… RaÃ­z del proyecto: {project_root}\")\n",
    "else:\n",
    "    project_root = current_dir\n",
    "    print(f\"   âœ… Ya estamos en la raÃ­z: {project_root}\")\n",
    "\n",
    "# Actualizar PROJECT_ROOT global\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "PROCESSED_DATA_DIR = DATA_DIR / \"processed\"\n",
    "MODELS_DIR = PROJECT_ROOT / \"models\"\n",
    "REPORTS_DIR = PROJECT_ROOT / \"reports\"\n",
    "\n",
    "print(f\"   âœ… Directorio de trabajo: {PROJECT_ROOT}\\n\")\n",
    "\n",
    "# ====================\n",
    "# 2. VERIFICAR MÃ“DULO ACOUSTIC_ML\n",
    "# ====================\n",
    "print(\"ğŸ“¦ Verificando mÃ³dulo acoustic_ml...\")\n",
    "try:\n",
    "    import acoustic_ml\n",
    "    print(f\"   âœ… acoustic_ml v{acoustic_ml.__version__}\")\n",
    "    print(f\"   ğŸ“ UbicaciÃ³n: {acoustic_ml.__file__}\\n\")\n",
    "except ImportError as e:\n",
    "    print(f\"   âŒ ERROR: {e}\")\n",
    "    print(\"   ğŸ’¡ SoluciÃ³n: pip install -e .\\n\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# ====================\n",
    "# 3. VERIFICAR DEPENDENCIAS CRÃTICAS\n",
    "# ====================\n",
    "print(\"ğŸ”§ Verificando dependencias crÃ­ticas...\")\n",
    "dependencies = {\n",
    "    # Core\n",
    "    'pandas': 'Procesamiento de datos',\n",
    "    'numpy': 'Operaciones numÃ©ricas',\n",
    "    \n",
    "    # ML Framework\n",
    "    'sklearn': 'Scikit-learn (ML principal)',\n",
    "    'xgboost': 'XGBoost (gradient boosting)',\n",
    "    'lightgbm': 'LightGBM (gradient boosting)',\n",
    "    \n",
    "    # Visualization\n",
    "    'matplotlib': 'Visualizaciones',\n",
    "    'seaborn': 'GrÃ¡ficos estadÃ­sticos',\n",
    "    \n",
    "    # Utilities\n",
    "    'joblib': 'Guardado de modelos',\n",
    "    'json': 'Manejo de metadata (built-in)',\n",
    "}\n",
    "\n",
    "missing_deps = []\n",
    "for package, description in dependencies.items():\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f\"   âœ… {package:20s} - {description}\")\n",
    "    except ImportError:\n",
    "        print(f\"   âŒ {package:20s} - {description}\")\n",
    "        missing_deps.append(package)\n",
    "\n",
    "if missing_deps:\n",
    "    print(f\"\\n   âŒ Faltan: {', '.join(missing_deps)}\")\n",
    "    print(f\"   ğŸ’¡ SoluciÃ³n: pip install {' '.join(missing_deps)}\\n\")\n",
    "    sys.exit(1)\n",
    "\n",
    "print()\n",
    "\n",
    "# ====================\n",
    "# 4. VERIFICAR MODELOS DE SKLEARN\n",
    "# ====================\n",
    "print(\"ğŸ¤– Verificando modelos de ML disponibles...\")\n",
    "ml_models = {\n",
    "    'RandomForestClassifier': 'sklearn.ensemble',\n",
    "    'LogisticRegression': 'sklearn.linear_model',\n",
    "    'SVC': 'sklearn.svm',\n",
    "    'KNeighborsClassifier': 'sklearn.neighbors',\n",
    "    'MLPClassifier': 'sklearn.neural_network',\n",
    "    'GradientBoostingClassifier': 'sklearn.ensemble',\n",
    "}\n",
    "\n",
    "for model, module in ml_models.items():\n",
    "    try:\n",
    "        exec(f\"from {module} import {model}\")\n",
    "        print(f\"   âœ… {model:30s} - {module}\")\n",
    "    except ImportError as e:\n",
    "        print(f\"   âŒ {model:30s} - ERROR: {e}\")\n",
    "        missing_deps.append(f\"{module}.{model}\")\n",
    "\n",
    "# XGBoost y LightGBM\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    print(f\"   âœ… {'XGBClassifier':30s} - xgboost v{xgb.__version__}\")\n",
    "except ImportError:\n",
    "    print(f\"   âš ï¸  {'XGBClassifier':30s} - No disponible (opcional)\")\n",
    "\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    print(f\"   âœ… {'LGBMClassifier':30s} - lightgbm v{lgb.__version__}\")\n",
    "except ImportError:\n",
    "    print(f\"   âš ï¸  {'LGBMClassifier':30s} - No disponible (opcional)\")\n",
    "\n",
    "print()\n",
    "\n",
    "# ====================\n",
    "# 5. VERIFICAR HERRAMIENTAS DE EVALUACIÃ“N\n",
    "# ====================\n",
    "print(\"ğŸ“Š Verificando herramientas de evaluaciÃ³n...\")\n",
    "eval_tools = {\n",
    "    'classification_report': 'sklearn.metrics',\n",
    "    'confusion_matrix': 'sklearn.metrics',\n",
    "    'accuracy_score': 'sklearn.metrics',\n",
    "    'f1_score': 'sklearn.metrics',\n",
    "    'precision_score': 'sklearn.metrics',\n",
    "    'recall_score': 'sklearn.metrics',\n",
    "    'GridSearchCV': 'sklearn.model_selection',\n",
    "    'RandomizedSearchCV': 'sklearn.model_selection',\n",
    "    'cross_val_score': 'sklearn.model_selection',\n",
    "}\n",
    "\n",
    "for tool, module in eval_tools.items():\n",
    "    try:\n",
    "        exec(f\"from {module} import {tool}\")\n",
    "        print(f\"   âœ… {tool:25s} - {module}\")\n",
    "    except ImportError as e:\n",
    "        print(f\"   âŒ {tool:25s} - ERROR: {e}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# ====================\n",
    "# 6. VERIFICAR DVC\n",
    "# ====================\n",
    "print(\"â˜ï¸  Verificando DVC y sincronizaciÃ³n...\")\n",
    "\n",
    "errors = []\n",
    "warnings = []\n",
    "\n",
    "if (PROJECT_ROOT / \".dvc\").exists():\n",
    "    print(\"   âœ… Repositorio DVC inicializado\")\n",
    "else:\n",
    "    print(\"   âŒ Repositorio DVC no encontrado\")\n",
    "    errors.append(\"Repositorio DVC no inicializado\")\n",
    "\n",
    "import subprocess\n",
    "\n",
    "try:\n",
    "    result = subprocess.run(\n",
    "        ['dvc', 'status'],\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        cwd=PROJECT_ROOT,\n",
    "        timeout=15\n",
    "    )\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        output = result.stdout.strip()\n",
    "        \n",
    "        if not output or \"up to date\" in output.lower():\n",
    "            print(\"   âœ… Datos sincronizados con S3\")\n",
    "        else:\n",
    "            has_real_changes = any(\n",
    "                keyword in output.lower() \n",
    "                for keyword in ['changed', 'modified', 'deleted', 'new file', 'added']\n",
    "            )\n",
    "            \n",
    "            if has_real_changes:\n",
    "                print(f\"   âŒ Cambios pendientes en DVC\")\n",
    "                errors.append(\"Sincronizar DVC antes de continuar\")\n",
    "            else:\n",
    "                print(f\"   âœ… DVC sincronizado\")\n",
    "except Exception as e:\n",
    "    print(f\"   âš ï¸  No se pudo verificar DVC: {e}\")\n",
    "    warnings.append(f\"Error al verificar DVC: {str(e)}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# ====================\n",
    "# 7. VERIFICAR ARCHIVOS DE ENTRADA (SPLITS)\n",
    "# ====================\n",
    "print(\"ğŸ“‚ Verificando datasets de entrada (train/test splits)...\")\n",
    "\n",
    "required_files = {\n",
    "    'X_train.csv': 'Features de entrenamiento',\n",
    "    'X_test.csv': 'Features de prueba',\n",
    "    'y_train.csv': 'Target de entrenamiento',\n",
    "    'y_test.csv': 'Target de prueba',\n",
    "    'split_metadata.json': 'Metadata del split',\n",
    "}\n",
    "\n",
    "for filename, description in required_files.items():\n",
    "    filepath = PROCESSED_DATA_DIR / filename\n",
    "    if filepath.exists():\n",
    "        size_kb = filepath.stat().st_size / 1024\n",
    "        print(f\"   âœ… {filename:25s} - {description} ({size_kb:.1f} KB)\")\n",
    "    else:\n",
    "        print(f\"   âŒ {filename:25s} - NO ENCONTRADO\")\n",
    "        errors.append(f\"Falta archivo: {filename}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# ====================\n",
    "# 8. VERIFICAR/CREAR DIRECTORIOS DE SALIDA\n",
    "# ====================\n",
    "print(\"ğŸ“ Verificando directorios de salida...\")\n",
    "\n",
    "output_dirs = {\n",
    "    MODELS_DIR: 'Modelos entrenados',\n",
    "    MODELS_DIR / 'baseline': 'Modelos baseline',\n",
    "    MODELS_DIR / 'optimized': 'Modelos optimizados',\n",
    "    REPORTS_DIR: 'Reportes de evaluaciÃ³n',\n",
    "    REPORTS_DIR / 'figures': 'GrÃ¡ficos y visualizaciones',\n",
    "}\n",
    "\n",
    "for dir_path, description in output_dirs.items():\n",
    "    if dir_path.exists():\n",
    "        print(f\"   âœ… {str(dir_path.relative_to(PROJECT_ROOT)):30s} - {description}\")\n",
    "    else:\n",
    "        dir_path.mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"   âœ¨ {str(dir_path.relative_to(PROJECT_ROOT)):30s} - Creado ({description})\")\n",
    "\n",
    "print()\n",
    "\n",
    "# ====================\n",
    "# 9. RESUMEN FINAL\n",
    "# ====================\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if errors:\n",
    "    print(\"âŒ ERRORES CRÃTICOS DETECTADOS:\")\n",
    "    print(\"=\" * 80)\n",
    "    for i, error in enumerate(errors, 1):\n",
    "        print(f\"\\n   {i}. {error}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ğŸ’¡ SOLUCIONES:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"   â€¢ Datos faltantes: dvc pull\")\n",
    "    print(\"   â€¢ MÃ³dulos faltantes: pip install -e .\")\n",
    "    print(\"   â€¢ Ejecutar notebook 03_Fase01_Explora_Preprocesa_datos.ipynb primero\")\n",
    "    print(\"\\nğŸ›‘ EJECUCIÃ“N DETENIDA\")\n",
    "    print(\"=\" * 80)\n",
    "    raise RuntimeError(\"âŒ ValidaciÃ³n fallÃ³ - corrige errores antes de continuar\")\n",
    "\n",
    "if warnings:\n",
    "    print(\"âš ï¸  ADVERTENCIAS (NO CRÃTICAS):\")\n",
    "    print(\"=\" * 80)\n",
    "    for i, warning in enumerate(warnings, 1):\n",
    "        print(f\"   {i}. {warning}\")\n",
    "    print()\n",
    "\n",
    "print(\"âœ… TODAS LAS VALIDACIONES CRÃTICAS PASARON\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "print(\"ğŸ¯ Este notebook realizarÃ¡:\")\n",
    "print(\"   1. âœ… Carga de datasets train/test\")\n",
    "print(\"   2. âœ… Entrenamiento de modelos baseline\")\n",
    "print(\"   3. âœ… ComparaciÃ³n de resultados\")\n",
    "print(\"   4. âœ… OptimizaciÃ³n de hiperparÃ¡metros\")\n",
    "print(\"   5. âœ… SelecciÃ³n del mejor modelo\")\n",
    "print(\"   6. âœ… EvaluaciÃ³n final completa\")\n",
    "print(\"   7. âœ… Guardado y versionado con DVC\")\n",
    "print()\n",
    "print(\"ğŸ“¤ OUTPUTS que se generarÃ¡n:\")\n",
    "print(\"   â€¢ models/baseline/*.pkl (modelos baseline)\")\n",
    "print(\"   â€¢ models/optimized/*.pkl (mejor modelo)\")\n",
    "print(\"   â€¢ reports/model_comparison.csv\")\n",
    "print(\"   â€¢ reports/final_evaluation.json\")\n",
    "print(\"   â€¢ reports/figures/*.png (visualizaciones)\")\n",
    "print()\n",
    "print(\"ğŸš€ Notebook listo para ejecutarse\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ“¥ PARTE 2: CARGA DE DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ğŸ“¥ CARGA DE DATASETS DE ENTRENAMIENTO Y PRUEBA\n",
    "Cargamos los splits generados en la fase de EDA\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ğŸ“¥ CARGANDO DATASETS TRAIN/TEST\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Cargar splits\n",
    "print(\"\\nğŸ”„ Cargando archivos...\")\n",
    "\n",
    "X_train = pd.read_csv(PROCESSED_DATA_DIR / \"X_train.csv\")\n",
    "print(f\"   âœ… X_train: {X_train.shape[0]:,} muestras Ã— {X_train.shape[1]} features\")\n",
    "\n",
    "X_test = pd.read_csv(PROCESSED_DATA_DIR / \"X_test.csv\")\n",
    "print(f\"   âœ… X_test:  {X_test.shape[0]:,} muestras Ã— {X_test.shape[1]} features\")\n",
    "\n",
    "y_train = pd.read_csv(PROCESSED_DATA_DIR / \"y_train.csv\")['Class']\n",
    "print(f\"   âœ… y_train: {len(y_train):,} valores\")\n",
    "\n",
    "y_test = pd.read_csv(PROCESSED_DATA_DIR / \"y_test.csv\")['Class']\n",
    "print(f\"   âœ… y_test:  {len(y_test):,} valores\")\n",
    "\n",
    "# Cargar metadata\n",
    "with open(PROCESSED_DATA_DIR / \"split_metadata.json\", 'r') as f:\n",
    "    split_metadata = json.load(f)\n",
    "print(f\"   âœ… Metadata del split cargada\")\n",
    "\n",
    "# Verificar integridad\n",
    "print(\"\\nğŸ” VERIFICACIÃ“N DE INTEGRIDAD:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# 1. TamaÃ±os coinciden\n",
    "assert len(X_train) == len(y_train), \"âŒ X_train y y_train no coinciden\"\n",
    "assert len(X_test) == len(y_test), \"âŒ X_test y y_test no coinciden\"\n",
    "print(\"   âœ… TamaÃ±os de X e y coinciden\")\n",
    "\n",
    "# 2. Mismas features\n",
    "assert list(X_train.columns) == list(X_test.columns), \"âŒ Features diferentes\"\n",
    "print(f\"   âœ… Mismas {len(X_train.columns)} features en train y test\")\n",
    "\n",
    "# 3. Sin valores nulos\n",
    "assert X_train.isnull().sum().sum() == 0, \"âŒ Valores nulos en X_train\"\n",
    "assert X_test.isnull().sum().sum() == 0, \"âŒ Valores nulos en X_test\"\n",
    "assert y_train.isnull().sum() == 0, \"âŒ Valores nulos en y_train\"\n",
    "assert y_test.isnull().sum() == 0, \"âŒ Valores nulos en y_test\"\n",
    "print(\"   âœ… Sin valores nulos\")\n",
    "\n",
    "# 4. Clases vÃ¡lidas\n",
    "valid_classes = {0, 1, 2, 3}\n",
    "assert set(y_train.unique()).issubset(valid_classes), \"âŒ Clases invÃ¡lidas en y_train\"\n",
    "assert set(y_test.unique()).issubset(valid_classes), \"âŒ Clases invÃ¡lidas en y_test\"\n",
    "print(f\"   âœ… Clases vÃ¡lidas: {sorted(y_train.unique())}\")\n",
    "\n",
    "# Mapeo de emociones\n",
    "EMOTION_NAMES = {0: 'ğŸ˜Š Happy', 1: 'ğŸ˜¢ Sad', 2: 'ğŸ˜  Angry', 3: 'ğŸ˜Œ Relax'}\n",
    "EMOTION_LABELS = ['Happy', 'Sad', 'Angry', 'Relax']\n",
    "\n",
    "# DistribuciÃ³n de clases\n",
    "print(\"\\nğŸ“Š DISTRIBUCIÃ“N DE CLASES:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "train_dist = y_train.value_counts().sort_index()\n",
    "test_dist = y_test.value_counts().sort_index()\n",
    "\n",
    "print(f\"\\n{'EmociÃ³n':15s} | {'Train':>8s} | {'%':>6s} | {'Test':>8s} | {'%':>6s}\")\n",
    "print(\"-\" * 60)\n",
    "for class_id in sorted(y_train.unique()):\n",
    "    emotion = EMOTION_NAMES[int(class_id)]\n",
    "    train_count = train_dist.get(class_id, 0)\n",
    "    test_count = test_dist.get(class_id, 0)\n",
    "    train_pct = (train_count / len(y_train)) * 100\n",
    "    test_pct = (test_count / len(y_test)) * 100\n",
    "    print(f\"{emotion:15s} | {train_count:8d} | {train_pct:5.1f}% | {test_count:8d} | {test_pct:5.1f}%\")\n",
    "\n",
    "print(f\"\\n{'TOTAL':15s} | {len(y_train):8d} | 100.0% | {len(y_test):8d} | 100.0%\")\n",
    "\n",
    "# InformaciÃ³n del split\n",
    "print(\"\\nğŸ“‹ INFORMACIÃ“N DEL SPLIT:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"   â€¢ Fecha de split: {split_metadata.get('split_date', 'N/A')}\")\n",
    "print(f\"   â€¢ Test size: {split_metadata.get('test_size', 'N/A')}\")\n",
    "print(f\"   â€¢ Random state: {split_metadata.get('random_state', 'N/A')}\")\n",
    "print(f\"   â€¢ Estratificado: {'SÃ­' if split_metadata.get('stratified', False) else 'No'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"âœ… DATOS CARGADOS Y VERIFICADOS CORRECTAMENTE\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ—ï¸ PARTE 3: MODELOS BASELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ğŸ—ï¸ ENTRENAMIENTO DE MODELOS BASELINE\n",
    "Entrenamos mÃºltiples algoritmos con parÃ¡metros por defecto\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, precision_score, recall_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ğŸ—ï¸ ENTRENAMIENTO DE MODELOS BASELINE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Definir modelos baseline\n",
    "baseline_models = {\n",
    "    'Random Forest': RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'Logistic Regression': LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'SVM (RBF)': SVC(\n",
    "        kernel='rbf',\n",
    "        random_state=42,\n",
    "        probability=True  # Para ROC curves\n",
    "    ),\n",
    "    'KNN': KNeighborsClassifier(\n",
    "        n_neighbors=5,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'MLP Neural Network': MLPClassifier(\n",
    "        hidden_layer_sizes=(100, 50),\n",
    "        max_iter=500,\n",
    "        random_state=42\n",
    "    ),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(\n",
    "        n_estimators=100,\n",
    "        random_state=42\n",
    "    ),\n",
    "}\n",
    "\n",
    "# Intentar agregar XGBoost y LightGBM si estÃ¡n disponibles\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    baseline_models['XGBoost'] = XGBClassifier(\n",
    "        n_estimators=100,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        eval_metric='mlogloss'\n",
    "    )\n",
    "except ImportError:\n",
    "    print(\"âš ï¸  XGBoost no disponible - saltando\")\n",
    "\n",
    "try:\n",
    "    from lightgbm import LGBMClassifier\n",
    "    baseline_models['LightGBM'] = LGBMClassifier(\n",
    "        n_estimators=100,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    )\n",
    "except ImportError:\n",
    "    print(\"âš ï¸  LightGBM no disponible - saltando\")\n",
    "\n",
    "print(f\"\\nğŸ¤– Modelos a entrenar: {len(baseline_models)}\\n\")\n",
    "\n",
    "# Entrenar y evaluar cada modelo\n",
    "results = []\n",
    "trained_models = {}\n",
    "\n",
    "for i, (name, model) in enumerate(baseline_models.items(), 1):\n",
    "    print(f\"{i}/{len(baseline_models)} - Entrenando {name}...\")\n",
    "    \n",
    "    # Entrenar\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    # Predecir\n",
    "    start_time = time.time()\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    pred_time = time.time() - start_time\n",
    "    \n",
    "    # MÃ©tricas\n",
    "    train_acc = accuracy_score(y_train, y_pred_train)\n",
    "    test_acc = accuracy_score(y_test, y_pred_test)\n",
    "    test_f1_macro = f1_score(y_test, y_pred_test, average='macro')\n",
    "    test_f1_weighted = f1_score(y_test, y_pred_test, average='weighted')\n",
    "    test_precision = precision_score(y_test, y_pred_test, average='macro')\n",
    "    test_recall = recall_score(y_test, y_pred_test, average='macro')\n",
    "    \n",
    "    # Guardar resultados\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Train_Accuracy': train_acc,\n",
    "        'Test_Accuracy': test_acc,\n",
    "        'F1_Macro': test_f1_macro,\n",
    "        'F1_Weighted': test_f1_weighted,\n",
    "        'Precision': test_precision,\n",
    "        'Recall': test_recall,\n",
    "        'Train_Time': train_time,\n",
    "        'Pred_Time': pred_time,\n",
    "        'Overfit': train_acc - test_acc\n",
    "    })\n",
    "    \n",
    "    # Guardar modelo entrenado\n",
    "    trained_models[name] = {\n",
    "        'model': model,\n",
    "        'y_pred_train': y_pred_train,\n",
    "        'y_pred_test': y_pred_test\n",
    "    }\n",
    "    \n",
    "    print(f\"   âœ… Test Accuracy: {test_acc:.4f} | F1-Macro: {test_f1_macro:.4f} | Tiempo: {train_time:.2f}s\\n\")\n",
    "\n",
    "# Crear DataFrame de resultados\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('Test_Accuracy', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸ“Š RESULTADOS DE MODELOS BASELINE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nğŸ† RANKING POR TEST ACCURACY:\\n\")\n",
    "print(results_df[[\n",
    "    'Model', 'Test_Accuracy', 'F1_Macro', 'F1_Weighted', \n",
    "    'Precision', 'Recall', 'Overfit', 'Train_Time'\n",
    "]].to_string(index=False))\n",
    "\n",
    "# Top 3 modelos\n",
    "print(\"\\nğŸ¥‡ TOP 3 MODELOS:\")\n",
    "print(\"-\" * 80)\n",
    "for i, row in results_df.head(3).iterrows():\n",
    "    print(f\"{i+1}. {row['Model']:25s} - Acc: {row['Test_Accuracy']:.4f} | F1: {row['F1_Macro']:.4f}\")\n",
    "\n",
    "# Guardar resultados\n",
    "results_path = REPORTS_DIR / \"baseline_results.csv\"\n",
    "results_df.to_csv(results_path, index=False)\n",
    "print(f\"\\nğŸ’¾ Resultados guardados en: {results_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"âœ… ENTRENAMIENTO DE BASELINE COMPLETADO\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ“Š PARTE 4: VISUALIZACIÃ“N DE RESULTADOS BASELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ğŸ“Š VISUALIZACIÃ“N DE RESULTADOS BASELINE\n",
    "GrÃ¡ficos comparativos de rendimiento\n",
    "\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configurar estilo\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ğŸ“Š GENERANDO VISUALIZACIONES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Crear figura con subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('ğŸ—ï¸ ComparaciÃ³n de Modelos Baseline', fontsize=18, fontweight='bold', y=0.995)\n",
    "\n",
    "# 1. ComparaciÃ³n de Accuracy (Train vs Test)\n",
    "ax1 = axes[0, 0]\n",
    "x = np.arange(len(results_df))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax1.bar(x - width/2, results_df['Train_Accuracy'], width, label='Train', alpha=0.8, color='#4CAF50')\n",
    "bars2 = ax1.bar(x + width/2, results_df['Test_Accuracy'], width, label='Test', alpha=0.8, color='#2196F3')\n",
    "\n",
    "ax1.set_xlabel('Modelo', fontweight='bold')\n",
    "ax1.set_ylabel('Accuracy', fontweight='bold')\n",
    "ax1.set_title('ğŸ¯ Train vs Test Accuracy', fontweight='bold', pad=10)\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(results_df['Model'], rotation=45, ha='right')\n",
    "ax1.legend()\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "ax1.set_ylim([0.5, 1.0])\n",
    "\n",
    "# AÃ±adir lÃ­nea de 80%\n",
    "ax1.axhline(y=0.8, color='red', linestyle='--', alpha=0.5, label='80% Baseline')\n",
    "\n",
    "# 2. MÃ©tricas por Modelo (F1, Precision, Recall)\n",
    "ax2 = axes[0, 1]\n",
    "metrics_data = results_df[['Model', 'F1_Macro', 'Precision', 'Recall']].set_index('Model')\n",
    "metrics_data.plot(kind='bar', ax=ax2, width=0.8, alpha=0.8)\n",
    "\n",
    "ax2.set_xlabel('Modelo', fontweight='bold')\n",
    "ax2.set_ylabel('Score', fontweight='bold')\n",
    "ax2.set_title('ğŸ“ˆ MÃ©tricas de ClasificaciÃ³n', fontweight='bold', pad=10)\n",
    "ax2.legend(title='MÃ©trica', loc='lower right')\n",
    "ax2.set_xticklabels(ax2.get_xticklabels(), rotation=45, ha='right')\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "ax2.set_ylim([0.5, 1.0])\n",
    "\n",
    "# 3. Overfitting Analysis\n",
    "ax3 = axes[1, 0]\n",
    "colors = ['green' if x < 0.05 else 'orange' if x < 0.1 else 'red' for x in results_df['Overfit']]\n",
    "bars = ax3.barh(results_df['Model'], results_df['Overfit'], color=colors, alpha=0.7)\n",
    "\n",
    "ax3.set_xlabel('Train Acc - Test Acc', fontweight='bold')\n",
    "ax3.set_title('âš ï¸ AnÃ¡lisis de Overfitting', fontweight='bold', pad=10)\n",
    "ax3.axvline(x=0.05, color='orange', linestyle='--', alpha=0.5, label='Overfitting Leve')\n",
    "ax3.axvline(x=0.1, color='red', linestyle='--', alpha=0.5, label='Overfitting Alto')\n",
    "ax3.legend()\n",
    "ax3.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# AÃ±adir valores en las barras\n",
    "for i, bar in enumerate(bars):\n",
    "    width = bar.get_width()\n",
    "    ax3.text(width, bar.get_y() + bar.get_height()/2, \n",
    "             f'{width:.3f}', ha='left', va='center', fontsize=9)\n",
    "\n",
    "# 4. Tiempo de Entrenamiento\n",
    "ax4 = axes[1, 1]\n",
    "ax4.barh(results_df['Model'], results_df['Train_Time'], alpha=0.8, color='#9C27B0')\n",
    "\n",
    "ax4.set_xlabel('Tiempo (segundos)', fontweight='bold')\n",
    "ax4.set_title('â±ï¸ Tiempo de Entrenamiento', fontweight='bold', pad=10)\n",
    "ax4.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# AÃ±adir valores en las barras\n",
    "for i, (model, time) in enumerate(zip(results_df['Model'], results_df['Train_Time'])):\n",
    "    ax4.text(time, i, f' {time:.2f}s', va='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Guardar figura\n",
    "figures_dir = REPORTS_DIR / \"figures\"\n",
    "figures_dir.mkdir(exist_ok=True)\n",
    "plt.savefig(figures_dir / \"baseline_comparison.png\", dpi=300, bbox_inches='tight')\n",
    "print(f\"\\nâœ… VisualizaciÃ³n guardada en: {figures_dir / 'baseline_comparison.png'}\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"âœ… VISUALIZACIONES COMPLETADAS\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ”¢ PARTE 5: MATRICES DE CONFUSIÃ“N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ğŸ”¢ MATRICES DE CONFUSIÃ“N PARA TOP 3 MODELOS\n",
    "AnÃ¡lisis detallado de errores de clasificaciÃ³n\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ğŸ”¢ GENERANDO MATRICES DE CONFUSIÃ“N\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Seleccionar top 3 modelos\n",
    "top3_models = results_df.head(3)['Model'].tolist()\n",
    "\n",
    "# Crear figura\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "fig.suptitle('ğŸ”¢ Matrices de ConfusiÃ³n - Top 3 Modelos', fontsize=16, fontweight='bold', y=1.02)\n",
    "\n",
    "for idx, model_name in enumerate(top3_models):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Obtener predicciones\n",
    "    y_pred = trained_models[model_name]['y_pred_test']\n",
    "    \n",
    "    # Calcular matriz de confusiÃ³n\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Normalizar por filas (recall por clase)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    # Plot\n",
    "    sns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap='Blues', \n",
    "                xticklabels=EMOTION_LABELS, yticklabels=EMOTION_LABELS,\n",
    "                ax=ax, cbar_kws={'label': 'Proportion'})\n",
    "    \n",
    "    # AÃ±adir conteos en las celdas\n",
    "    for i in range(len(EMOTION_LABELS)):\n",
    "        for j in range(len(EMOTION_LABELS)):\n",
    "            text = ax.text(j + 0.5, i + 0.7, f'n={cm[i, j]}',\n",
    "                          ha=\"center\", va=\"center\", color=\"gray\", fontsize=8)\n",
    "    \n",
    "    ax.set_title(f'{model_name}\\nAccuracy: {results_df[results_df[\"Model\"]==model_name][\"Test_Accuracy\"].values[0]:.4f}',\n",
    "                 fontweight='bold', pad=10)\n",
    "    ax.set_xlabel('PredicciÃ³n', fontweight='bold')\n",
    "    ax.set_ylabel('Real', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(figures_dir / \"confusion_matrices_top3.png\", dpi=300, bbox_inches='tight')\n",
    "print(f\"\\nâœ… Matrices guardadas en: {figures_dir / 'confusion_matrices_top3.png'}\")\n",
    "plt.show()\n",
    "\n",
    "# AnÃ¡lisis de errores mÃ¡s comunes\n",
    "print(\"\\nğŸ“Š ANÃLISIS DE ERRORES MÃS COMUNES:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for model_name in top3_models:\n",
    "    y_pred = trained_models[model_name]['y_pred_test']\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print(f\"\\n{model_name}:\")\n",
    "    \n",
    "    # Encontrar los 3 errores mÃ¡s comunes (excluyendo diagonal)\n",
    "    errors = []\n",
    "    for i in range(len(EMOTION_LABELS)):\n",
    "        for j in range(len(EMOTION_LABELS)):\n",
    "            if i != j:  # Excluir aciertos (diagonal)\n",
    "                errors.append((cm[i, j], EMOTION_LABELS[i], EMOTION_LABELS[j]))\n",
    "    \n",
    "    errors.sort(reverse=True)\n",
    "    \n",
    "    for count, real, pred in errors[:3]:\n",
    "        if count > 0:\n",
    "            pct = (count / cm.sum()) * 100\n",
    "            print(f\"   â€¢ {real} â†’ {pred}: {count} veces ({pct:.1f}% del total)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"âœ… MATRICES DE CONFUSIÃ“N COMPLETADAS\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ›ï¸ PARTE 6: OPTIMIZACIÃ“N DE HIPERPARÃMETROS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ğŸ›ï¸ OPTIMIZACIÃ“N DE HIPERPARÃMETROS PARA EL MEJOR MODELO\n",
    "Usando GridSearchCV para encontrar la mejor configuraciÃ³n\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ğŸ›ï¸ OPTIMIZACIÃ“N DE HIPERPARÃMETROS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Seleccionar el mejor modelo baseline\n",
    "best_baseline = results_df.iloc[0]['Model']\n",
    "best_baseline_acc = results_df.iloc[0]['Test_Accuracy']\n",
    "\n",
    "print(f\"\\nğŸ† Mejor modelo baseline: {best_baseline}\")\n",
    "print(f\"   Accuracy actual: {best_baseline_acc:.4f}\")\n",
    "print(f\"\\nğŸ” Iniciando bÃºsqueda de hiperparÃ¡metros...\\n\")\n",
    "\n",
    "# Definir espacios de bÃºsqueda segÃºn el modelo\n",
    "if 'Random Forest' in best_baseline:\n",
    "    base_model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [10, 20, 30, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'max_features': ['sqrt', 'log2', None]\n",
    "    }\n",
    "    search_type = 'RandomizedSearchCV'\n",
    "    n_iter = 50\n",
    "\n",
    "elif 'XGBoost' in best_baseline:\n",
    "    from xgboost import XGBClassifier\n",
    "    base_model = XGBClassifier(random_state=42, n_jobs=-1, eval_metric='mlogloss')\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [3, 5, 7, 9],\n",
    "        'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "        'subsample': [0.7, 0.8, 0.9, 1.0],\n",
    "        'colsample_bytree': [0.7, 0.8, 0.9, 1.0]\n",
    "    }\n",
    "    search_type = 'RandomizedSearchCV'\n",
    "    n_iter = 50\n",
    "\n",
    "elif 'LightGBM' in best_baseline:\n",
    "    from lightgbm import LGBMClassifier\n",
    "    base_model = LGBMClassifier(random_state=42, n_jobs=-1, verbose=-1)\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [3, 5, 7, -1],\n",
    "        'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "        'num_leaves': [31, 50, 70, 100],\n",
    "        'subsample': [0.7, 0.8, 0.9, 1.0]\n",
    "    }\n",
    "    search_type = 'RandomizedSearchCV'\n",
    "    n_iter = 50\n",
    "\n",
    "elif 'SVM' in best_baseline:\n",
    "    base_model = SVC(random_state=42, probability=True)\n",
    "    param_grid = {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'gamma': ['scale', 'auto', 0.001, 0.01, 0.1],\n",
    "        'kernel': ['rbf', 'poly']\n",
    "    }\n",
    "    search_type = 'GridSearchCV'\n",
    "\n",
    "elif 'Logistic' in best_baseline:\n",
    "    base_model = LogisticRegression(random_state=42, n_jobs=-1, max_iter=1000)\n",
    "    param_grid = {\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "        'solver': ['saga'],\n",
    "        'l1_ratio': [0.1, 0.5, 0.9]\n",
    "    }\n",
    "    search_type = 'GridSearchCV'\n",
    "\n",
    "elif 'Gradient Boosting' in best_baseline:\n",
    "    base_model = GradientBoostingClassifier(random_state=42)\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 7, 9],\n",
    "        'subsample': [0.7, 0.8, 0.9, 1.0]\n",
    "    }\n",
    "    search_type = 'RandomizedSearchCV'\n",
    "    n_iter = 50\n",
    "\n",
    "else:\n",
    "    # Por defecto, usar el modelo existente\n",
    "    base_model = trained_models[best_baseline]['model']\n",
    "    param_grid = {}\n",
    "    search_type = 'None'\n",
    "\n",
    "print(f\"   MÃ©todo de bÃºsqueda: {search_type}\")\n",
    "print(f\"   ParÃ¡metros a explorar: {len(param_grid)} dimensiones\")\n",
    "\n",
    "# Realizar bÃºsqueda\n",
    "if search_type == 'RandomizedSearchCV':\n",
    "    search = RandomizedSearchCV(\n",
    "        base_model,\n",
    "        param_grid,\n",
    "        n_iter=n_iter,\n",
    "        cv=5,\n",
    "        scoring='f1_macro',\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        verbose=1\n",
    "    )\n",
    "elif search_type == 'GridSearchCV':\n",
    "    search = GridSearchCV(\n",
    "        base_model,\n",
    "        param_grid,\n",
    "        cv=5,\n",
    "        scoring='f1_macro',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "else:\n",
    "    print(\"\\nâš ï¸  No se realizarÃ¡ bÃºsqueda de hiperparÃ¡metros\")\n",
    "    best_model = base_model\n",
    "    search = None\n",
    "\n",
    "if search is not None:\n",
    "    print(f\"\\nâ³ Entrenando... (esto puede tomar varios minutos)\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    search.fit(X_train, y_train)\n",
    "    \n",
    "    search_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\nâœ… BÃºsqueda completada en {search_time:.2f}s\")\n",
    "    \n",
    "    # Mejor modelo encontrado\n",
    "    best_model = search.best_estimator_\n",
    "    \n",
    "    print(f\"\\nğŸ† MEJORES HIPERPARÃMETROS:\")\n",
    "    print(\"-\" * 80)\n",
    "    for param, value in search.best_params_.items():\n",
    "        print(f\"   â€¢ {param}: {value}\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š MEJORA EN RENDIMIENTO:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"   â€¢ CV Score (F1-Macro): {search.best_score_:.4f}\")\n",
    "    \n",
    "    # Evaluar en test set\n",
    "    y_pred_optimized = best_model.predict(X_test)\n",
    "    optimized_acc = accuracy_score(y_test, y_pred_optimized)\n",
    "    optimized_f1 = f1_score(y_test, y_pred_optimized, average='macro')\n",
    "    \n",
    "    print(f\"   â€¢ Test Accuracy: {optimized_acc:.4f} (baseline: {best_baseline_acc:.4f})\")\n",
    "    print(f\"   â€¢ Test F1-Macro: {optimized_f1:.4f}\")\n",
    "    print(f\"   â€¢ Mejora: {(optimized_acc - best_baseline_acc)*100:+.2f}%\")\n",
    "    \n",
    "    # Guardar resultados de la bÃºsqueda\n",
    "    cv_results = pd.DataFrame(search.cv_results_)\n",
    "    cv_results_path = REPORTS_DIR / \"hyperparameter_search_results.csv\"\n",
    "    cv_results.to_csv(cv_results_path, index=False)\n",
    "    print(f\"\\nğŸ’¾ Resultados de bÃºsqueda guardados en: {cv_results_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"âœ… OPTIMIZACIÃ“N COMPLETADA\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ“ˆ PARTE 7: EVALUACIÃ“N FINAL DEL MEJOR MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ğŸ“ˆ EVALUACIÃ“N COMPLETA DEL MODELO FINAL\n",
    "Classification report, ROC curves, y mÃ©tricas detalladas\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.metrics import classification_report, roc_curve, auc, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ğŸ“ˆ EVALUACIÃ“N FINAL DEL MODELO OPTIMIZADO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Predicciones del modelo final\n",
    "y_pred_final = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)\n",
    "\n",
    "# 1. Classification Report Detallado\n",
    "print(\"\\nğŸ“Š CLASSIFICATION REPORT:\")\n",
    "print(\"-\" * 80)\n",
    "print(classification_report(\n",
    "    y_test, \n",
    "    y_pred_final, \n",
    "    target_names=EMOTION_LABELS,\n",
    "    digits=4\n",
    "))\n",
    "\n",
    "# 2. Matriz de ConfusiÃ³n Final\n",
    "print(\"\\nğŸ”¢ MATRIZ DE CONFUSIÃ“N FINAL:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "fig.suptitle(f'ğŸ† {best_baseline} (Optimizado) - Matriz de ConfusiÃ³n', \n",
    "             fontsize=14, fontweight='bold', y=1.02)\n",
    "\n",
    "# Matriz absoluta\n",
    "cm = confusion_matrix(y_test, y_pred_final)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=EMOTION_LABELS, yticklabels=EMOTION_LABELS,\n",
    "            ax=axes[0], cbar_kws={'label': 'Count'})\n",
    "axes[0].set_title('Conteos Absolutos', fontweight='bold', pad=10)\n",
    "axes[0].set_xlabel('PredicciÃ³n', fontweight='bold')\n",
    "axes[0].set_ylabel('Real', fontweight='bold')\n",
    "\n",
    "# Matriz normalizada\n",
    "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(cm_norm, annot=True, fmt='.2%', cmap='Blues', \n",
    "            xticklabels=EMOTION_LABELS, yticklabels=EMOTION_LABELS,\n",
    "            ax=axes[1], cbar_kws={'label': 'Proportion'})\n",
    "axes[1].set_title('Proporciones (Recall por Clase)', fontweight='bold', pad=10)\n",
    "axes[1].set_xlabel('PredicciÃ³n', fontweight='bold')\n",
    "axes[1].set_ylabel('Real', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(figures_dir / \"final_confusion_matrix.png\", dpi=300, bbox_inches='tight')\n",
    "print(f\"   âœ… Matriz guardada en: {figures_dir / 'final_confusion_matrix.png'}\")\n",
    "plt.show()\n",
    "\n",
    "# 3. Curvas ROC Multi-clase\n",
    "print(\"\\nğŸ“‰ CURVAS ROC POR CLASE:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Binarizar las etiquetas\n",
    "y_test_bin = label_binarize(y_test, classes=[0, 1, 2, 3])\n",
    "n_classes = y_test_bin.shape[1]\n",
    "\n",
    "# Calcular ROC y AUC para cada clase\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_pred_proba[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC curves\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = ['#2196F3', '#4CAF50', '#FF9800', '#9C27B0']\n",
    "\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label=f'{EMOTION_LABELS[i]} (AUC = {roc_auc[i]:.4f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Random (AUC = 0.5000)')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontweight='bold', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontweight='bold', fontsize=12)\n",
    "plt.title(f'ğŸ“‰ Curvas ROC por Clase - {best_baseline} (Optimizado)', \n",
    "          fontweight='bold', fontsize=14, pad=15)\n",
    "plt.legend(loc=\"lower right\", fontsize=10)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(figures_dir / \"roc_curves.png\", dpi=300, bbox_inches='tight')\n",
    "print(f\"   âœ… Curvas ROC guardadas en: {figures_dir / 'roc_curves.png'}\")\n",
    "plt.show()\n",
    "\n",
    "# Imprimir AUC por clase\n",
    "print(\"\\n   AUC por Clase:\")\n",
    "for i, label in enumerate(EMOTION_LABELS):\n",
    "    print(f\"   â€¢ {label:10s}: {roc_auc[i]:.4f}\")\n",
    "\n",
    "# AUC promedio\n",
    "macro_auc = np.mean(list(roc_auc.values()))\n",
    "print(f\"\\n   â€¢ Macro-Average AUC: {macro_auc:.4f}\")\n",
    "\n",
    "# 4. MÃ©tricas Finales Consolidadas\n",
    "final_metrics = {\n",
    "    'model_name': best_baseline,\n",
    "    'is_optimized': search is not None,\n",
    "    'test_accuracy': accuracy_score(y_test, y_pred_final),\n",
    "    'test_f1_macro': f1_score(y_test, y_pred_final, average='macro'),\n",
    "    'test_f1_weighted': f1_score(y_test, y_pred_final, average='weighted'),\n",
    "    'test_precision_macro': precision_score(y_test, y_pred_final, average='macro'),\n",
    "    'test_recall_macro': recall_score(y_test, y_pred_final, average='macro'),\n",
    "    'macro_auc': macro_auc,\n",
    "    'hyperparameters': search.best_params_ if search is not None else {},\n",
    "    'confusion_matrix': cm.tolist(),\n",
    "    'class_metrics': {}\n",
    "}\n",
    "\n",
    "# AÃ±adir mÃ©tricas por clase\n",
    "for i, label in enumerate(EMOTION_LABELS):\n",
    "    mask = y_test == i\n",
    "    class_acc = accuracy_score(y_test[mask], y_pred_final[mask])\n",
    "    class_f1 = f1_score(y_test == i, y_pred_final == i)\n",
    "    \n",
    "    final_metrics['class_metrics'][label] = {\n",
    "        'accuracy': float(class_acc),\n",
    "        'f1_score': float(class_f1),\n",
    "        'auc': float(roc_auc[i]),\n",
    "        'support': int(mask.sum())\n",
    "    }\n",
    "\n",
    "# Guardar mÃ©tricas finales\n",
    "final_metrics_path = REPORTS_DIR / \"final_model_evaluation.json\"\n",
    "with open(final_metrics_path, 'w') as f:\n",
    "    json.dump(final_metrics, f, indent=2)\n",
    "\n",
    "print(f\"\\nğŸ’¾ MÃ©tricas finales guardadas en: {final_metrics_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"âœ… EVALUACIÃ“N FINAL COMPLETADA\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ’¾ PARTE 8: GUARDADO Y VERSIONADO DEL MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ğŸ’¾ GUARDADO DEL MODELO FINAL Y VERSIONADO CON DVC\n",
    "SerializaciÃ³n del modelo optimizado y metadata\n",
    "\"\"\"\n",
    "\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ğŸ’¾ GUARDANDO MODELO FINAL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. Crear directorio para el modelo optimizado\n",
    "optimized_dir = MODELS_DIR / \"optimized\"\n",
    "optimized_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# 2. Nombres de archivo\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "model_filename = f\"best_model_{timestamp}.pkl\"\n",
    "model_path = optimized_dir / model_filename\n",
    "\n",
    "# TambiÃ©n guardamos una copia con nombre fijo para producciÃ³n\n",
    "production_model_path = optimized_dir / \"production_model.pkl\"\n",
    "\n",
    "print(f\"\\nğŸ“¦ Serializando modelo...\")\n",
    "print(f\"   â€¢ Archivo versionado: {model_filename}\")\n",
    "print(f\"   â€¢ Archivo producciÃ³n: production_model.pkl\")\n",
    "\n",
    "# 3. Guardar el modelo\n",
    "joblib.dump(best_model, model_path)\n",
    "joblib.dump(best_model, production_model_path)\n",
    "\n",
    "model_size_kb = model_path.stat().st_size / 1024\n",
    "print(f\"\\nâœ… Modelo guardado ({model_size_kb:.1f} KB)\")\n",
    "\n",
    "# 4. Crear metadata del modelo\n",
    "model_metadata = {\n",
    "    'model_name': best_baseline,\n",
    "    'is_optimized': search is not None,\n",
    "    'timestamp': timestamp,\n",
    "    'model_file': model_filename,\n",
    "    'model_size_kb': float(model_size_kb),\n",
    "    \n",
    "    # MÃ©tricas de entrenamiento\n",
    "    'train_samples': int(len(X_train)),\n",
    "    'test_samples': int(len(X_test)),\n",
    "    'n_features': int(X_train.shape[1]),\n",
    "    'n_classes': 4,\n",
    "    'class_labels': EMOTION_LABELS,\n",
    "    \n",
    "    # MÃ©tricas de rendimiento\n",
    "    'test_accuracy': float(final_metrics['test_accuracy']),\n",
    "    'test_f1_macro': float(final_metrics['test_f1_macro']),\n",
    "    'test_f1_weighted': float(final_metrics['test_f1_weighted']),\n",
    "    'test_precision_macro': float(final_metrics['test_precision_macro']),\n",
    "    'test_recall_macro': float(final_metrics['test_recall_macro']),\n",
    "    'macro_auc': float(final_metrics['macro_auc']),\n",
    "    \n",
    "    # HiperparÃ¡metros\n",
    "    'hyperparameters': final_metrics['hyperparameters'],\n",
    "    \n",
    "    # InformaciÃ³n del dataset\n",
    "    'data_split_info': split_metadata,\n",
    "    \n",
    "    # MÃ©tricas por clase\n",
    "    'class_metrics': final_metrics['class_metrics'],\n",
    "    \n",
    "    # Versiones de librerÃ­as\n",
    "    'sklearn_version': sklearn.__version__,\n",
    "    'python_version': sys.version,\n",
    "}\n",
    "\n",
    "# Guardar metadata\n",
    "metadata_path = optimized_dir / f\"model_metadata_{timestamp}.json\"\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(model_metadata, f, indent=2)\n",
    "\n",
    "# TambiÃ©n guardamos metadata de producciÃ³n\n",
    "production_metadata_path = optimized_dir / \"production_model_metadata.json\"\n",
    "with open(production_metadata_path, 'w') as f:\n",
    "    json.dump(model_metadata, f, indent=2)\n",
    "\n",
    "print(f\"\\nâœ… Metadata guardada\")\n",
    "print(f\"   â€¢ {metadata_path.name}\")\n",
    "print(f\"   â€¢ production_model_metadata.json\")\n",
    "\n",
    "# 5. Guardar tambiÃ©n los modelos baseline para comparaciÃ³n\n",
    "print(f\"\\nğŸ’¾ Guardando modelos baseline para comparaciÃ³n...\")\n",
    "baseline_dir = MODELS_DIR / \"baseline\"\n",
    "baseline_dir.mkdir(exist_ok=True)\n",
    "\n",
    "for model_name in top3_models:\n",
    "    model = trained_models[model_name]['model']\n",
    "    safe_name = model_name.replace(' ', '_').replace('(', '').replace(')', '').lower()\n",
    "    baseline_path = baseline_dir / f\"{safe_name}_baseline.pkl\"\n",
    "    joblib.dump(model, baseline_path)\n",
    "    print(f\"   âœ… {model_name}\")\n",
    "\n",
    "# 6. Crear archivo .dvc para versionado\n",
    "print(f\"\\nâ˜ï¸  Configurando DVC para versionado...\")\n",
    "\n",
    "# Agregar archivos a DVC\n",
    "files_to_track = [\n",
    "    production_model_path,\n",
    "    production_metadata_path\n",
    "]\n",
    "\n",
    "for file_path in files_to_track:\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            ['dvc', 'add', str(file_path)],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            cwd=PROJECT_ROOT\n",
    "        )\n",
    "        if result.returncode == 0:\n",
    "            print(f\"   âœ… {file_path.name} agregado a DVC\")\n",
    "        else:\n",
    "            print(f\"   âš ï¸  Error agregando {file_path.name}: {result.stderr}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   âš ï¸  Error con DVC: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"âœ… MODELO GUARDADO Y VERSIONADO\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nğŸ“¤ PRÃ“XIMOS PASOS:\")\n",
    "print(\"   1. git add models/optimized/*.dvc\")\n",
    "print(\"   2. git commit -m 'Add optimized model'\")\n",
    "print(\"   3. dvc push\")\n",
    "print(\"   4. git push\")\n",
    "print(\"\\nğŸ’¡ Para cargar el modelo en producciÃ³n:\")\n",
    "print(\"   import joblib\")\n",
    "print(f\"   model = joblib.load('{production_model_path}')\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ“„ PARTE 9: REPORTE FINAL DE MODELADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ğŸ“„ GENERACIÃ“N DEL REPORTE FINAL DE MODELADO\n",
    "Resumen ejecutivo con todos los hallazgos\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ğŸ“„ REPORTE FINAL DE MODELADO - FASE 2\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "report = f\"\"\"\n",
    "{'='*80}\n",
    "ğŸ¼ TURKISH MUSIC EMOTION CLASSIFICATION\n",
    "ğŸ“Š REPORTE DE MODELADO - FASE 2\n",
    "{'='*80}\n",
    "\n",
    "ğŸ“… Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "ğŸ‘¥ Equipo: David Cruz, Javier Rebull, Sandra Cervantes\n",
    "ğŸ›ï¸ InstituciÃ³n: ITESM - MaestrÃ­a en IA Aplicada\n",
    "\n",
    "{'='*80}\n",
    "ğŸ“Š RESUMEN EJECUTIVO\n",
    "{'='*80}\n",
    "\n",
    "ğŸ¯ OBJETIVO:\n",
    "   Desarrollar un modelo de clasificaciÃ³n multiclase para predecir emociones\n",
    "   (Happy, Sad, Angry, Relax) a partir de caracterÃ­sticas acÃºsticas de mÃºsica\n",
    "   turca.\n",
    "\n",
    "ğŸ“ˆ DATASET:\n",
    "   â€¢ Total de muestras: {len(X_train) + len(X_test):,}\n",
    "   â€¢ Training set: {len(X_train):,} ({len(X_train)/(len(X_train)+len(X_test))*100:.1f}%)\n",
    "   â€¢ Test set: {len(X_test):,} ({len(X_test)/(len(X_train)+len(X_test))*100:.1f}%)\n",
    "   â€¢ NÃºmero de features: {X_train.shape[1]}\n",
    "   â€¢ Clases: {len(EMOTION_LABELS)} (balanceadas)\n",
    "\n",
    "{'='*80}\n",
    "ğŸ—ï¸ MODELOS EVALUADOS (BASELINE)\n",
    "{'='*80}\n",
    "\n",
    "Se entrenaron y evaluaron {len(baseline_models)} algoritmos con configuraciones\n",
    "por defecto:\n",
    "\"\"\"\n",
    "\n",
    "# Agregar resultados de baseline\n",
    "report += \"\\nğŸ† RANKING DE MODELOS BASELINE:\\n\\n\"\n",
    "for idx, row in results_df.iterrows():\n",
    "    medal = \"ğŸ¥‡\" if idx == 0 else \"ğŸ¥ˆ\" if idx == 1 else \"ğŸ¥‰\" if idx == 2 else \"  \"\n",
    "    report += f\"{medal} {idx+1}. {row['Model']:25s} | Acc: {row['Test_Accuracy']:.4f} | F1: {row['F1_Macro']:.4f}\\n\"\n",
    "\n",
    "# Mejor modelo y optimizaciÃ³n\n",
    "report += f\"\"\"\n",
    "{'='*80}\n",
    "ğŸ›ï¸ OPTIMIZACIÃ“N DE HIPERPARÃMETROS\n",
    "{'='*80}\n",
    "\n",
    "ğŸ† MEJOR MODELO: {best_baseline}\n",
    "\n",
    "{'ğŸ“ CONFIGURACIÃ“N BASELINE:':}\n",
    "   â€¢ Test Accuracy: {best_baseline_acc:.4f}\n",
    "   â€¢ Test F1-Macro: {results_df.iloc[0]['F1_Macro']:.4f}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "if search is not None:\n",
    "    report += f\"\"\"\n",
    "ğŸ” BÃšSQUEDA DE HIPERPARÃMETROS:\n",
    "   â€¢ MÃ©todo: {search_type}\n",
    "   â€¢ Configuraciones probadas: {len(search.cv_results_['params']) if hasattr(search, 'cv_results_') else 'N/A'}\n",
    "   â€¢ Cross-validation folds: 5\n",
    "   â€¢ MÃ©trica optimizada: F1-Macro\n",
    "\n",
    "âš™ï¸ MEJORES HIPERPARÃMETROS:\n",
    "\"\"\"\n",
    "    for param, value in final_metrics['hyperparameters'].items():\n",
    "        report += f\"   â€¢ {param}: {value}\\n\"\n",
    "else:\n",
    "    report += \"\\nâš ï¸  No se realizÃ³ optimizaciÃ³n de hiperparÃ¡metros\\n\"\n",
    "\n",
    "# MÃ©tricas finales\n",
    "report += f\"\"\"\n",
    "{'='*80}\n",
    "ğŸ“Š RENDIMIENTO FINAL DEL MODELO\n",
    "{'='*80}\n",
    "\n",
    "ğŸ¯ MÃ‰TRICAS GLOBALES:\n",
    "   â€¢ Test Accuracy: {final_metrics['test_accuracy']:.4f}\n",
    "   â€¢ Test F1-Macro: {final_metrics['test_f1_macro']:.4f}\n",
    "   â€¢ Test F1-Weighted: {final_metrics['test_f1_weighted']:.4f}\n",
    "   â€¢ Test Precision (Macro): {final_metrics['test_precision_macro']:.4f}\n",
    "   â€¢ Test Recall (Macro): {final_metrics['test_recall_macro']:.4f}\n",
    "   â€¢ Macro AUC-ROC: {final_metrics['macro_auc']:.4f}\n",
    "\n",
    "ğŸ“ˆ MÃ‰TRICAS POR CLASE:\n",
    "\"\"\"\n",
    "\n",
    "for emotion, metrics in final_metrics['class_metrics'].items():\n",
    "    report += f\"\\n   {emotion}:\" \n",
    "    report += f\"\\n      â€¢ Accuracy: {metrics['accuracy']:.4f}\"\n",
    "    report += f\"\\n      â€¢ F1-Score: {metrics['f1_score']:.4f}\"\n",
    "    report += f\"\\n      â€¢ AUC-ROC: {metrics['auc']:.4f}\"\n",
    "    report += f\"\\n      â€¢ Support: {metrics['support']}\\n\"\n",
    "\n",
    "# AnÃ¡lisis de errores\n",
    "report += f\"\"\"\n",
    "{'='*80}\n",
    "ğŸ” ANÃLISIS DE ERRORES\n",
    "{'='*80}\n",
    "\n",
    "ğŸ”¢ MATRIZ DE CONFUSIÃ“N (ver visualizaciÃ³n):\n",
    "   Las confusiones mÃ¡s comunes se visualizan en:\n",
    "   reports/figures/final_confusion_matrix.png\n",
    "\n",
    "ğŸ’¡ INSIGHTS:\n",
    "\"\"\"\n",
    "\n",
    "# Encontrar la clase con mejor y peor rendimiento\n",
    "class_f1_scores = {emotion: metrics['f1_score'] \n",
    "                   for emotion, metrics in final_metrics['class_metrics'].items()}\n",
    "best_class = max(class_f1_scores, key=class_f1_scores.get)\n",
    "worst_class = min(class_f1_scores, key=class_f1_scores.get)\n",
    "\n",
    "report += f\"\\n   â€¢ Clase mejor clasificada: {best_class} (F1: {class_f1_scores[best_class]:.4f})\"\n",
    "report += f\"\\n   â€¢ Clase mÃ¡s difÃ­cil: {worst_class} (F1: {class_f1_scores[worst_class]:.4f})\"\n",
    "\n",
    "# Recomendaciones\n",
    "report += f\"\"\"\n",
    "\n",
    "{'='*80}\n",
    "ğŸ’¡ RECOMENDACIONES Y PRÃ“XIMOS PASOS\n",
    "{'='*80}\n",
    "\n",
    "ğŸ”§ MEJORAS POTENCIALES:\n",
    "   1. Feature Engineering:\n",
    "      â€¢ Explorar interacciones entre features\n",
    "      â€¢ Agregar features de contexto temporal\n",
    "      â€¢ Considerar tÃ©cnicas de selecciÃ³n de features\n",
    "\n",
    "   2. Ensemble Methods:\n",
    "      â€¢ Voting Classifier con top-3 modelos\n",
    "      â€¢ Stacking con meta-learner\n",
    "      â€¢ Blending de predicciones\n",
    "\n",
    "   3. TÃ©cnicas Avanzadas:\n",
    "      â€¢ Redes neuronales profundas (si hay mÃ¡s datos)\n",
    "      â€¢ Transfer learning con modelos pre-entrenados\n",
    "      â€¢ AugmentaciÃ³n de datos sintÃ©ticos\n",
    "\n",
    "   4. CalibraciÃ³n de Probabilidades:\n",
    "      â€¢ Isotonic regression o Platt scaling\n",
    "      â€¢ Para mejorar interpretabilidad de probabilidades\n",
    "\n",
    "ğŸ“¦ DEPLOYMENT:\n",
    "   â€¢ Modelo listo para producciÃ³n en: models/optimized/production_model.pkl\n",
    "   â€¢ Metadata disponible en: models/optimized/production_model_metadata.json\n",
    "   â€¢ Versionado con DVC configurado\n",
    "\n",
    "ğŸ”„ MONITOREO:\n",
    "   â€¢ Establecer baseline de mÃ©tricas actuales\n",
    "   â€¢ Monitorear drift en distribuciÃ³n de features\n",
    "   â€¢ Tracking de performance en producciÃ³n\n",
    "   â€¢ Re-entrenamiento periÃ³dico con nuevos datos\n",
    "\n",
    "{'='*80}\n",
    "ğŸ“ ARCHIVOS GENERADOS\n",
    "{'='*80}\n",
    "\n",
    "ğŸ“Š REPORTES:\n",
    "   â€¢ reports/baseline_results.csv\n",
    "   â€¢ reports/final_model_evaluation.json\n",
    "   â€¢ reports/hyperparameter_search_results.csv (si aplica)\n",
    "   â€¢ reports/modeling_report.txt (este archivo)\n",
    "\n",
    "ğŸ“ˆ VISUALIZACIONES:\n",
    "   â€¢ reports/figures/baseline_comparison.png\n",
    "   â€¢ reports/figures/confusion_matrices_top3.png\n",
    "   â€¢ reports/figures/final_confusion_matrix.png\n",
    "   â€¢ reports/figures/roc_curves.png\n",
    "\n",
    "ğŸ’¾ MODELOS:\n",
    "   â€¢ models/baseline/*.pkl (modelos baseline)\n",
    "   â€¢ models/optimized/production_model.pkl\n",
    "   â€¢ models/optimized/production_model_metadata.json\n",
    "   â€¢ models/optimized/*.dvc (archivos de versionado)\n",
    "\n",
    "{'='*80}\n",
    "âœ… FASE 2 COMPLETADA EXITOSAMENTE\n",
    "{'='*80}\n",
    "\n",
    "ğŸ¯ Objetivos cumplidos:\n",
    "   âœ… Modelos baseline entrenados y comparados\n",
    "   âœ… OptimizaciÃ³n de hiperparÃ¡metros realizada\n",
    "   âœ… EvaluaciÃ³n completa con mÃºltiples mÃ©tricas\n",
    "   âœ… Visualizaciones generadas\n",
    "   âœ… Modelo versionado con DVC\n",
    "   âœ… DocumentaciÃ³n completa\n",
    "\n",
    "ğŸš€ El modelo estÃ¡ listo para la Fase 3: Deployment\n",
    "\n",
    "{'='*80}\n",
    "Generado: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "Equipo: David Cruz â€¢ Javier Rebull â€¢ Sandra Cervantes\n",
    "ITESM - MaestrÃ­a en Inteligencia Artificial Aplicada\n",
    "{'='*80}\n",
    "\"\"\"\n",
    "\n",
    "# Imprimir reporte\n",
    "print(report)\n",
    "\n",
    "# Guardar reporte\n",
    "report_path = REPORTS_DIR / \"modeling_report.txt\"\n",
    "with open(report_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(report)\n",
    "\n",
    "print(f\"\\nğŸ’¾ Reporte guardado en: {report_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸ‰ Â¡NOTEBOOK COMPLETADO EXITOSAMENTE!\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nğŸµ De emociones musicales a predicciones precisas con MLOps ğŸ¤–\")\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
