{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🤖 Operaciones de Aprendizaje Automático (MLOps)\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "![Institution](https://img.shields.io/badge/🏛️_ITESM-Tecnológico_de_Monterrey-003366?style=flat-square&labelColor=002147)\n",
    "![Program](https://img.shields.io/badge/🎓_Maestría-Inteligencia_Artificial_Aplicada-7B2CBF?style=flat-square&labelColor=5A189A)\n",
    "![Phase](https://img.shields.io/badge/🤖_Fase_2-Modelado_y_Evaluación-10B981?style=flat-square&labelColor=059669)\n",
    "![Deadline](https://img.shields.io/badge/📅_Entrega-13_Octubre_2025-EF4444?style=flat-square&labelColor=DC2626)\n",
    "\n",
    "</div>\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "```\n",
    "╔═══════════════════════════════════════════════════════════════╗\n",
    "║                   🎼 TURKISH MUSIC EMOTION                    ║\n",
    "║         Machine Learning Model Training & Evaluation          ║\n",
    "╚═══════════════════════════════════════════════════════════════╝\n",
    "```\n",
    "\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "## 👨‍🏫 **Equipo Docente**\n",
    "\n",
    "<table align=\"center\" style=\"border: none;\">\n",
    "<tr>\n",
    "<td width=\"50%\" style=\"border: none;\">\n",
    "\n",
    "**👔 Profesores Titulares**\n",
    "- Dr. Gerardo Rodríguez Hernández\n",
    "- Maestro Ricardo Valdez Hernández\n",
    "\n",
    "</td>\n",
    "<td width=\"50%\" style=\"border: none;\">\n",
    "\n",
    "**🎓 Equipo de Apoyo**\n",
    "- Maestra María Mylen Treviño Elizondo  \n",
    "  *Profesora Asistente*\n",
    "- M. en C. José Ángel Martínez Navarro  \n",
    "  *Profesor Tutor*\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "---\n",
    "\n",
    "## 💥 **Equipo de Desarrollo**\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "<table style=\"width:100%; border:none; background-color: #1a1a2e;\">\n",
    "<tr>\n",
    "<td align=\"center\" style=\"border:none; padding:20px 10px; background-color: #16213e; color: #ffffff;\">\n",
    "\n",
    "<img src=\"https://iili.io/Kw90kmB.png\" alt=\"David Cruz Beltrán\" width=\"160\" style=\"border-radius: 50%; border: 5px solid #667eea; box-shadow: 0 8px 16px rgba(102, 126, 234, 0.4);\"/>\n",
    "\n",
    "<h3 style=\"color: #ffffff;\">David Cruz Beltrán</h3>\n",
    "\n",
    "![Matricula](https://img.shields.io/badge/ID-A01360416-667eea?style=for-the-badge)\n",
    "\n",
    "<p style=\"color: #ffffff;\"><strong>🔧 Software Engineer</strong><br/>\n",
    "<em>Model Pipeline & Versioning</em></p>\n",
    "\n",
    "</td>\n",
    "<td align=\"center\" style=\"border:none; padding:20px 10px; background-color: #16213e; color: #ffffff;\">\n",
    "\n",
    "<img src=\"https://iili.io/KuvsGKx.png\" alt=\"Javier Augusto Rebull Saucedo\" width=\"160\" style=\"border-radius: 50%; border: 5px solid #764ba2; box-shadow: 0 8px 16px rgba(118, 75, 162, 0.4);\"/>\n",
    "\n",
    "<h3 style=\"color: #ffffff;\">Javier Augusto Rebull Saucedo</h3>\n",
    "\n",
    "![Matricula](https://img.shields.io/badge/ID-A01795838-764ba2?style=for-the-badge)\n",
    "\n",
    "<p style=\"color: #ffffff;\"><strong>⚙️ SRE / Data Engineer</strong><br/>\n",
    "<em>Model Deployment & Monitoring</em></p>\n",
    "\n",
    "</td>\n",
    "<td align=\"center\" style=\"border:none; padding:20px 10px; background-color: #16213e; color: #ffffff;\">\n",
    "\n",
    "<img src=\"https://iili.io/Kw91d74.png\" alt=\"Sandra Luz Cervantes Espinoza\" width=\"160\" style=\"border-radius: 50%; border: 5px solid #f093fb; box-shadow: 0 8px 16px rgba(240, 147, 251, 0.4);\"/>\n",
    "\n",
    "<h3 style=\"color: #ffffff;\">Sandra Luz Cervantes Espinoza</h3>\n",
    "\n",
    "![Matricula](https://img.shields.io/badge/ID-A01796937-f093fb?style=for-the-badge)\n",
    "\n",
    "<p style=\"color: #ffffff;\"><strong>🤖 ML Engineer / Data Scientist</strong><br/>\n",
    "<em>Model Training & Optimization</em></p>\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 **Objetivos de la Fase 2**\n",
    "\n",
    "<table width=\"100%\">\n",
    "<tr>\n",
    "<td width=\"25%\" align=\"center\">\n",
    "\n",
    "### 🏗️ **Construcción**\n",
    "```\n",
    "🔨 Baseline Models\n",
    "🧪 Experimentación\n",
    "📊 Comparación\n",
    "```\n",
    "\n",
    "</td>\n",
    "<td width=\"25%\" align=\"center\">\n",
    "\n",
    "### 🎛️ **Ajuste**\n",
    "```\n",
    "🔍 Grid Search\n",
    "🎲 Random Search\n",
    "⚡ Bayesian Opt\n",
    "```\n",
    "\n",
    "</td>\n",
    "<td width=\"25%\" align=\"center\">\n",
    "\n",
    "### 📊 **Evaluación**\n",
    "```\n",
    "🎯 Accuracy\n",
    "📈 F1-Score\n",
    "🔢 Confusion Matrix\n",
    "```\n",
    "\n",
    "</td>\n",
    "<td width=\"25%\" align=\"center\">\n",
    "\n",
    "### 💾 **Versionado**\n",
    "```\n",
    "📦 Model Registry\n",
    "🏷️ Tagging\n",
    "☁️ DVC Push\n",
    "```\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "---\n",
    "\n",
    "## 🤖 **Algoritmos a Evaluar**\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "| Categoría | Algoritmos | Justificación |\n",
    "|:---------:|:-----------|:--------------|\n",
    "| **🌳 Tree-Based** | Random Forest, XGBoost, LightGBM | Robustos, manejan no-linealidad, feature importance |\n",
    "| **🎯 Linear** | Logistic Regression, SVM | Baseline rápido, interpretable |\n",
    "| **🧠 Neural** | MLP Classifier | Captura relaciones complejas |\n",
    "| **📏 Distance** | KNN | Simple, efectivo con normalización |\n",
    "| **🎲 Ensemble** | Voting, Stacking | Combina fortalezas de múltiples modelos |\n",
    "\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "## 📊 **Métricas de Evaluación**\n",
    "\n",
    "<table width=\"100%\">\n",
    "<tr>\n",
    "<td width=\"33%\" align=\"center\">\n",
    "\n",
    "### 🎯 **Principales**\n",
    "- **Accuracy**: Proporción de predicciones correctas\n",
    "- **F1-Score**: Balance precision-recall\n",
    "- **Macro F1**: F1 promedio por clase\n",
    "\n",
    "</td>\n",
    "<td width=\"33%\" align=\"center\">\n",
    "\n",
    "### 🔍 **Por Clase**\n",
    "- **Precision**: VP / (VP + FP)\n",
    "- **Recall**: VP / (VP + FN)\n",
    "- **Support**: Muestras por clase\n",
    "\n",
    "</td>\n",
    "<td width=\"33%\" align=\"center\">\n",
    "\n",
    "### 📈 **Visuales**\n",
    "- **Confusion Matrix**: Errores por clase\n",
    "- **ROC Curve**: Threshold analysis\n",
    "- **Learning Curves**: Overfitting check\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "---\n",
    "\n",
    "## 🚀 **Pipeline de Modelado**\n",
    "\n",
    "```mermaid\n",
    "graph LR\n",
    "    A[📥 Load Splits] --> B[🏗️ Baseline Models]\n",
    "    B --> C[📊 Compare Results]\n",
    "    C --> D[🎯 Select Top 3]\n",
    "    D --> E[🎛️ Hyperparameter Tuning]\n",
    "    E --> F[🏆 Best Model]\n",
    "    F --> G[📈 Final Evaluation]\n",
    "    G --> H[💾 Save & Version]\n",
    "    H --> I[☁️ DVC Push]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "### **🎵 De emociones musicales a predicciones precisas con MLOps 🤖**\n",
    "\n",
    "---\n",
    "\n",
    "![Made with Love](https://img.shields.io/badge/Made_with-❤️_and_🎵-FF69B4?style=flat-square)\n",
    "![ITESM](https://img.shields.io/badge/ITESM-MNA_2025-003366?style=flat-square)\n",
    "![MLOps](https://img.shields.io/badge/MLOps-Phase_2-10B981?style=flat-square)\n",
    "\n",
    "---\n",
    "\n",
    "📅 **Fecha de entrega:** 13 de Octubre 2025 • 01:00 hrs  \n",
    "📧 **Contacto:** A través de Canvas\n",
    "\n",
    "---\n",
    "\n",
    "*Proyecto desarrollado como parte de la Maestría en Inteligencia Artificial Aplicada*  \n",
    "*Instituto Tecnológico y de Estudios Superiores de Monterrey*\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 🔍 PARTE 1: VALIDACIÓN DE ENTORNO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "================================================================================\n",
    "🔍 VALIDACIÓN DEL ENTORNO Y DEPENDENCIAS - MODELING PHASE\n",
    "================================================================================\n",
    "\"\"\"\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# ====================\n",
    "# 1. CONFIGURACIÓN DEL DIRECTORIO\n",
    "# ====================\n",
    "print(\"📁 Verificando directorio de trabajo...\")\n",
    "current_dir = Path.cwd()\n",
    "print(f\"   Directorio actual: {current_dir}\")\n",
    "\n",
    "# Si estamos en notebooks/, subir un nivel\n",
    "if current_dir.name == \"notebooks\":\n",
    "    project_root = current_dir.parent\n",
    "    os.chdir(project_root)\n",
    "    print(f\"   ✅ Raíz del proyecto: {project_root}\")\n",
    "else:\n",
    "    project_root = current_dir\n",
    "    print(f\"   ✅ Ya estamos en la raíz: {project_root}\")\n",
    "\n",
    "# Actualizar PROJECT_ROOT global\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "PROCESSED_DATA_DIR = DATA_DIR / \"processed\"\n",
    "MODELS_DIR = PROJECT_ROOT / \"models\"\n",
    "REPORTS_DIR = PROJECT_ROOT / \"reports\"\n",
    "\n",
    "print(f\"   ✅ Directorio de trabajo: {PROJECT_ROOT}\\n\")\n",
    "\n",
    "# ====================\n",
    "# 2. VERIFICAR MÓDULO ACOUSTIC_ML\n",
    "# ====================\n",
    "print(\"📦 Verificando módulo acoustic_ml...\")\n",
    "try:\n",
    "    import acoustic_ml\n",
    "    print(f\"   ✅ acoustic_ml v{acoustic_ml.__version__}\")\n",
    "    print(f\"   📍 Ubicación: {acoustic_ml.__file__}\\n\")\n",
    "except ImportError as e:\n",
    "    print(f\"   ❌ ERROR: {e}\")\n",
    "    print(\"   💡 Solución: pip install -e .\\n\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# ====================\n",
    "# 3. VERIFICAR DEPENDENCIAS CRÍTICAS\n",
    "# ====================\n",
    "print(\"🔧 Verificando dependencias críticas...\")\n",
    "dependencies = {\n",
    "    # Core\n",
    "    'pandas': 'Procesamiento de datos',\n",
    "    'numpy': 'Operaciones numéricas',\n",
    "    \n",
    "    # ML Framework\n",
    "    'sklearn': 'Scikit-learn (ML principal)',\n",
    "    'xgboost': 'XGBoost (gradient boosting)',\n",
    "    'lightgbm': 'LightGBM (gradient boosting)',\n",
    "    \n",
    "    # Visualization\n",
    "    'matplotlib': 'Visualizaciones',\n",
    "    'seaborn': 'Gráficos estadísticos',\n",
    "    \n",
    "    # Utilities\n",
    "    'joblib': 'Guardado de modelos',\n",
    "    'json': 'Manejo de metadata (built-in)',\n",
    "}\n",
    "\n",
    "missing_deps = []\n",
    "for package, description in dependencies.items():\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f\"   ✅ {package:20s} - {description}\")\n",
    "    except ImportError:\n",
    "        print(f\"   ❌ {package:20s} - {description}\")\n",
    "        missing_deps.append(package)\n",
    "\n",
    "if missing_deps:\n",
    "    print(f\"\\n   ❌ Faltan: {', '.join(missing_deps)}\")\n",
    "    print(f\"   💡 Solución: pip install {' '.join(missing_deps)}\\n\")\n",
    "    sys.exit(1)\n",
    "\n",
    "print()\n",
    "\n",
    "# ====================\n",
    "# 4. VERIFICAR MODELOS DE SKLEARN\n",
    "# ====================\n",
    "print(\"🤖 Verificando modelos de ML disponibles...\")\n",
    "ml_models = {\n",
    "    'RandomForestClassifier': 'sklearn.ensemble',\n",
    "    'LogisticRegression': 'sklearn.linear_model',\n",
    "    'SVC': 'sklearn.svm',\n",
    "    'KNeighborsClassifier': 'sklearn.neighbors',\n",
    "    'MLPClassifier': 'sklearn.neural_network',\n",
    "    'GradientBoostingClassifier': 'sklearn.ensemble',\n",
    "}\n",
    "\n",
    "for model, module in ml_models.items():\n",
    "    try:\n",
    "        exec(f\"from {module} import {model}\")\n",
    "        print(f\"   ✅ {model:30s} - {module}\")\n",
    "    except ImportError as e:\n",
    "        print(f\"   ❌ {model:30s} - ERROR: {e}\")\n",
    "        missing_deps.append(f\"{module}.{model}\")\n",
    "\n",
    "# XGBoost y LightGBM\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    print(f\"   ✅ {'XGBClassifier':30s} - xgboost v{xgb.__version__}\")\n",
    "except ImportError:\n",
    "    print(f\"   ⚠️  {'XGBClassifier':30s} - No disponible (opcional)\")\n",
    "\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    print(f\"   ✅ {'LGBMClassifier':30s} - lightgbm v{lgb.__version__}\")\n",
    "except ImportError:\n",
    "    print(f\"   ⚠️  {'LGBMClassifier':30s} - No disponible (opcional)\")\n",
    "\n",
    "print()\n",
    "\n",
    "# ====================\n",
    "# 5. VERIFICAR HERRAMIENTAS DE EVALUACIÓN\n",
    "# ====================\n",
    "print(\"📊 Verificando herramientas de evaluación...\")\n",
    "eval_tools = {\n",
    "    'classification_report': 'sklearn.metrics',\n",
    "    'confusion_matrix': 'sklearn.metrics',\n",
    "    'accuracy_score': 'sklearn.metrics',\n",
    "    'f1_score': 'sklearn.metrics',\n",
    "    'precision_score': 'sklearn.metrics',\n",
    "    'recall_score': 'sklearn.metrics',\n",
    "    'GridSearchCV': 'sklearn.model_selection',\n",
    "    'RandomizedSearchCV': 'sklearn.model_selection',\n",
    "    'cross_val_score': 'sklearn.model_selection',\n",
    "}\n",
    "\n",
    "for tool, module in eval_tools.items():\n",
    "    try:\n",
    "        exec(f\"from {module} import {tool}\")\n",
    "        print(f\"   ✅ {tool:25s} - {module}\")\n",
    "    except ImportError as e:\n",
    "        print(f\"   ❌ {tool:25s} - ERROR: {e}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# ====================\n",
    "# 6. VERIFICAR DVC\n",
    "# ====================\n",
    "print(\"☁️  Verificando DVC y sincronización...\")\n",
    "\n",
    "errors = []\n",
    "warnings = []\n",
    "\n",
    "if (PROJECT_ROOT / \".dvc\").exists():\n",
    "    print(\"   ✅ Repositorio DVC inicializado\")\n",
    "else:\n",
    "    print(\"   ❌ Repositorio DVC no encontrado\")\n",
    "    errors.append(\"Repositorio DVC no inicializado\")\n",
    "\n",
    "import subprocess\n",
    "\n",
    "try:\n",
    "    result = subprocess.run(\n",
    "        ['dvc', 'status'],\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        cwd=PROJECT_ROOT,\n",
    "        timeout=15\n",
    "    )\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        output = result.stdout.strip()\n",
    "        \n",
    "        if not output or \"up to date\" in output.lower():\n",
    "            print(\"   ✅ Datos sincronizados con S3\")\n",
    "        else:\n",
    "            has_real_changes = any(\n",
    "                keyword in output.lower() \n",
    "                for keyword in ['changed', 'modified', 'deleted', 'new file', 'added']\n",
    "            )\n",
    "            \n",
    "            if has_real_changes:\n",
    "                print(f\"   ❌ Cambios pendientes en DVC\")\n",
    "                errors.append(\"Sincronizar DVC antes de continuar\")\n",
    "            else:\n",
    "                print(f\"   ✅ DVC sincronizado\")\n",
    "except Exception as e:\n",
    "    print(f\"   ⚠️  No se pudo verificar DVC: {e}\")\n",
    "    warnings.append(f\"Error al verificar DVC: {str(e)}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# ====================\n",
    "# 7. VERIFICAR ARCHIVOS DE ENTRADA (SPLITS)\n",
    "# ====================\n",
    "print(\"📂 Verificando datasets de entrada (train/test splits)...\")\n",
    "\n",
    "required_files = {\n",
    "    'X_train.csv': 'Features de entrenamiento',\n",
    "    'X_test.csv': 'Features de prueba',\n",
    "    'y_train.csv': 'Target de entrenamiento',\n",
    "    'y_test.csv': 'Target de prueba',\n",
    "    'split_metadata.json': 'Metadata del split',\n",
    "}\n",
    "\n",
    "for filename, description in required_files.items():\n",
    "    filepath = PROCESSED_DATA_DIR / filename\n",
    "    if filepath.exists():\n",
    "        size_kb = filepath.stat().st_size / 1024\n",
    "        print(f\"   ✅ {filename:25s} - {description} ({size_kb:.1f} KB)\")\n",
    "    else:\n",
    "        print(f\"   ❌ {filename:25s} - NO ENCONTRADO\")\n",
    "        errors.append(f\"Falta archivo: {filename}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# ====================\n",
    "# 8. VERIFICAR/CREAR DIRECTORIOS DE SALIDA\n",
    "# ====================\n",
    "print(\"📁 Verificando directorios de salida...\")\n",
    "\n",
    "output_dirs = {\n",
    "    MODELS_DIR: 'Modelos entrenados',\n",
    "    MODELS_DIR / 'baseline': 'Modelos baseline',\n",
    "    MODELS_DIR / 'optimized': 'Modelos optimizados',\n",
    "    REPORTS_DIR: 'Reportes de evaluación',\n",
    "    REPORTS_DIR / 'figures': 'Gráficos y visualizaciones',\n",
    "}\n",
    "\n",
    "for dir_path, description in output_dirs.items():\n",
    "    if dir_path.exists():\n",
    "        print(f\"   ✅ {str(dir_path.relative_to(PROJECT_ROOT)):30s} - {description}\")\n",
    "    else:\n",
    "        dir_path.mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"   ✨ {str(dir_path.relative_to(PROJECT_ROOT)):30s} - Creado ({description})\")\n",
    "\n",
    "print()\n",
    "\n",
    "# ====================\n",
    "# 9. RESUMEN FINAL\n",
    "# ====================\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if errors:\n",
    "    print(\"❌ ERRORES CRÍTICOS DETECTADOS:\")\n",
    "    print(\"=\" * 80)\n",
    "    for i, error in enumerate(errors, 1):\n",
    "        print(f\"\\n   {i}. {error}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"💡 SOLUCIONES:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"   • Datos faltantes: dvc pull\")\n",
    "    print(\"   • Módulos faltantes: pip install -e .\")\n",
    "    print(\"   • Ejecutar notebook 03_Fase01_Explora_Preprocesa_datos.ipynb primero\")\n",
    "    print(\"\\n🛑 EJECUCIÓN DETENIDA\")\n",
    "    print(\"=\" * 80)\n",
    "    raise RuntimeError(\"❌ Validación falló - corrige errores antes de continuar\")\n",
    "\n",
    "if warnings:\n",
    "    print(\"⚠️  ADVERTENCIAS (NO CRÍTICAS):\")\n",
    "    print(\"=\" * 80)\n",
    "    for i, warning in enumerate(warnings, 1):\n",
    "        print(f\"   {i}. {warning}\")\n",
    "    print()\n",
    "\n",
    "print(\"✅ TODAS LAS VALIDACIONES CRÍTICAS PASARON\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "print(\"🎯 Este notebook realizará:\")\n",
    "print(\"   1. ✅ Carga de datasets train/test\")\n",
    "print(\"   2. ✅ Entrenamiento de modelos baseline\")\n",
    "print(\"   3. ✅ Comparación de resultados\")\n",
    "print(\"   4. ✅ Optimización de hiperparámetros\")\n",
    "print(\"   5. ✅ Selección del mejor modelo\")\n",
    "print(\"   6. ✅ Evaluación final completa\")\n",
    "print(\"   7. ✅ Guardado y versionado con DVC\")\n",
    "print()\n",
    "print(\"📤 OUTPUTS que se generarán:\")\n",
    "print(\"   • models/baseline/*.pkl (modelos baseline)\")\n",
    "print(\"   • models/optimized/*.pkl (mejor modelo)\")\n",
    "print(\"   • reports/model_comparison.csv\")\n",
    "print(\"   • reports/final_evaluation.json\")\n",
    "print(\"   • reports/figures/*.png (visualizaciones)\")\n",
    "print()\n",
    "print(\"🚀 Notebook listo para ejecutarse\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 📥 PARTE 2: CARGA DE DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "📥 CARGA DE DATASETS DE ENTRENAMIENTO Y PRUEBA\n",
    "Cargamos los splits generados en la fase de EDA\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"📥 CARGANDO DATASETS TRAIN/TEST\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Cargar splits\n",
    "print(\"\\n🔄 Cargando archivos...\")\n",
    "\n",
    "X_train = pd.read_csv(PROCESSED_DATA_DIR / \"X_train.csv\")\n",
    "print(f\"   ✅ X_train: {X_train.shape[0]:,} muestras × {X_train.shape[1]} features\")\n",
    "\n",
    "X_test = pd.read_csv(PROCESSED_DATA_DIR / \"X_test.csv\")\n",
    "print(f\"   ✅ X_test:  {X_test.shape[0]:,} muestras × {X_test.shape[1]} features\")\n",
    "\n",
    "y_train = pd.read_csv(PROCESSED_DATA_DIR / \"y_train.csv\")['Class']\n",
    "print(f\"   ✅ y_train: {len(y_train):,} valores\")\n",
    "\n",
    "y_test = pd.read_csv(PROCESSED_DATA_DIR / \"y_test.csv\")['Class']\n",
    "print(f\"   ✅ y_test:  {len(y_test):,} valores\")\n",
    "\n",
    "# Cargar metadata\n",
    "with open(PROCESSED_DATA_DIR / \"split_metadata.json\", 'r') as f:\n",
    "    split_metadata = json.load(f)\n",
    "print(f\"   ✅ Metadata del split cargada\")\n",
    "\n",
    "# Verificar integridad\n",
    "print(\"\\n🔍 VERIFICACIÓN DE INTEGRIDAD:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# 1. Tamaños coinciden\n",
    "assert len(X_train) == len(y_train), \"❌ X_train y y_train no coinciden\"\n",
    "assert len(X_test) == len(y_test), \"❌ X_test y y_test no coinciden\"\n",
    "print(\"   ✅ Tamaños de X e y coinciden\")\n",
    "\n",
    "# 2. Mismas features\n",
    "assert list(X_train.columns) == list(X_test.columns), \"❌ Features diferentes\"\n",
    "print(f\"   ✅ Mismas {len(X_train.columns)} features en train y test\")\n",
    "\n",
    "# 3. Sin valores nulos\n",
    "assert X_train.isnull().sum().sum() == 0, \"❌ Valores nulos en X_train\"\n",
    "assert X_test.isnull().sum().sum() == 0, \"❌ Valores nulos en X_test\"\n",
    "assert y_train.isnull().sum() == 0, \"❌ Valores nulos en y_train\"\n",
    "assert y_test.isnull().sum() == 0, \"❌ Valores nulos en y_test\"\n",
    "print(\"   ✅ Sin valores nulos\")\n",
    "\n",
    "# 4. Clases válidas\n",
    "valid_classes = {0, 1, 2, 3}\n",
    "assert set(y_train.unique()).issubset(valid_classes), \"❌ Clases inválidas en y_train\"\n",
    "assert set(y_test.unique()).issubset(valid_classes), \"❌ Clases inválidas en y_test\"\n",
    "print(f\"   ✅ Clases válidas: {sorted(y_train.unique())}\")\n",
    "\n",
    "# Mapeo de emociones\n",
    "EMOTION_NAMES = {0: '😊 Happy', 1: '😢 Sad', 2: '😠 Angry', 3: '😌 Relax'}\n",
    "EMOTION_LABELS = ['Happy', 'Sad', 'Angry', 'Relax']\n",
    "\n",
    "# Distribución de clases\n",
    "print(\"\\n📊 DISTRIBUCIÓN DE CLASES:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "train_dist = y_train.value_counts().sort_index()\n",
    "test_dist = y_test.value_counts().sort_index()\n",
    "\n",
    "print(f\"\\n{'Emoción':15s} | {'Train':>8s} | {'%':>6s} | {'Test':>8s} | {'%':>6s}\")\n",
    "print(\"-\" * 60)\n",
    "for class_id in sorted(y_train.unique()):\n",
    "    emotion = EMOTION_NAMES[int(class_id)]\n",
    "    train_count = train_dist.get(class_id, 0)\n",
    "    test_count = test_dist.get(class_id, 0)\n",
    "    train_pct = (train_count / len(y_train)) * 100\n",
    "    test_pct = (test_count / len(y_test)) * 100\n",
    "    print(f\"{emotion:15s} | {train_count:8d} | {train_pct:5.1f}% | {test_count:8d} | {test_pct:5.1f}%\")\n",
    "\n",
    "print(f\"\\n{'TOTAL':15s} | {len(y_train):8d} | 100.0% | {len(y_test):8d} | 100.0%\")\n",
    "\n",
    "# Información del split\n",
    "print(\"\\n📋 INFORMACIÓN DEL SPLIT:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"   • Fecha de split: {split_metadata.get('split_date', 'N/A')}\")\n",
    "print(f\"   • Test size: {split_metadata.get('test_size', 'N/A')}\")\n",
    "print(f\"   • Random state: {split_metadata.get('random_state', 'N/A')}\")\n",
    "print(f\"   • Estratificado: {'Sí' if split_metadata.get('stratified', False) else 'No'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"✅ DATOS CARGADOS Y VERIFICADOS CORRECTAMENTE\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 🏗️ PARTE 3: MODELOS BASELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "🏗️ ENTRENAMIENTO DE MODELOS BASELINE\n",
    "Entrenamos múltiples algoritmos con parámetros por defecto\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, precision_score, recall_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"🏗️ ENTRENAMIENTO DE MODELOS BASELINE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Definir modelos baseline\n",
    "baseline_models = {\n",
    "    'Random Forest': RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'Logistic Regression': LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'SVM (RBF)': SVC(\n",
    "        kernel='rbf',\n",
    "        random_state=42,\n",
    "        probability=True  # Para ROC curves\n",
    "    ),\n",
    "    'KNN': KNeighborsClassifier(\n",
    "        n_neighbors=5,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'MLP Neural Network': MLPClassifier(\n",
    "        hidden_layer_sizes=(100, 50),\n",
    "        max_iter=500,\n",
    "        random_state=42\n",
    "    ),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(\n",
    "        n_estimators=100,\n",
    "        random_state=42\n",
    "    ),\n",
    "}\n",
    "\n",
    "# Intentar agregar XGBoost y LightGBM si están disponibles\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    baseline_models['XGBoost'] = XGBClassifier(\n",
    "        n_estimators=100,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        eval_metric='mlogloss'\n",
    "    )\n",
    "except ImportError:\n",
    "    print(\"⚠️  XGBoost no disponible - saltando\")\n",
    "\n",
    "try:\n",
    "    from lightgbm import LGBMClassifier\n",
    "    baseline_models['LightGBM'] = LGBMClassifier(\n",
    "        n_estimators=100,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    )\n",
    "except ImportError:\n",
    "    print(\"⚠️  LightGBM no disponible - saltando\")\n",
    "\n",
    "print(f\"\\n🤖 Modelos a entrenar: {len(baseline_models)}\\n\")\n",
    "\n",
    "# Entrenar y evaluar cada modelo\n",
    "results = []\n",
    "trained_models = {}\n",
    "\n",
    "for i, (name, model) in enumerate(baseline_models.items(), 1):\n",
    "    print(f\"{i}/{len(baseline_models)} - Entrenando {name}...\")\n",
    "    \n",
    "    # Entrenar\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    # Predecir\n",
    "    start_time = time.time()\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    pred_time = time.time() - start_time\n",
    "    \n",
    "    # Métricas\n",
    "    train_acc = accuracy_score(y_train, y_pred_train)\n",
    "    test_acc = accuracy_score(y_test, y_pred_test)\n",
    "    test_f1_macro = f1_score(y_test, y_pred_test, average='macro')\n",
    "    test_f1_weighted = f1_score(y_test, y_pred_test, average='weighted')\n",
    "    test_precision = precision_score(y_test, y_pred_test, average='macro')\n",
    "    test_recall = recall_score(y_test, y_pred_test, average='macro')\n",
    "    \n",
    "    # Guardar resultados\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Train_Accuracy': train_acc,\n",
    "        'Test_Accuracy': test_acc,\n",
    "        'F1_Macro': test_f1_macro,\n",
    "        'F1_Weighted': test_f1_weighted,\n",
    "        'Precision': test_precision,\n",
    "        'Recall': test_recall,\n",
    "        'Train_Time': train_time,\n",
    "        'Pred_Time': pred_time,\n",
    "        'Overfit': train_acc - test_acc\n",
    "    })\n",
    "    \n",
    "    # Guardar modelo entrenado\n",
    "    trained_models[name] = {\n",
    "        'model': model,\n",
    "        'y_pred_train': y_pred_train,\n",
    "        'y_pred_test': y_pred_test\n",
    "    }\n",
    "    \n",
    "    print(f\"   ✅ Test Accuracy: {test_acc:.4f} | F1-Macro: {test_f1_macro:.4f} | Tiempo: {train_time:.2f}s\\n\")\n",
    "\n",
    "# Crear DataFrame de resultados\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('Test_Accuracy', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"📊 RESULTADOS DE MODELOS BASELINE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n🏆 RANKING POR TEST ACCURACY:\\n\")\n",
    "print(results_df[[\n",
    "    'Model', 'Test_Accuracy', 'F1_Macro', 'F1_Weighted', \n",
    "    'Precision', 'Recall', 'Overfit', 'Train_Time'\n",
    "]].to_string(index=False))\n",
    "\n",
    "# Top 3 modelos\n",
    "print(\"\\n🥇 TOP 3 MODELOS:\")\n",
    "print(\"-\" * 80)\n",
    "for i, row in results_df.head(3).iterrows():\n",
    "    print(f\"{i+1}. {row['Model']:25s} - Acc: {row['Test_Accuracy']:.4f} | F1: {row['F1_Macro']:.4f}\")\n",
    "\n",
    "# Guardar resultados\n",
    "results_path = REPORTS_DIR / \"baseline_results.csv\"\n",
    "results_df.to_csv(results_path, index=False)\n",
    "print(f\"\\n💾 Resultados guardados en: {results_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"✅ ENTRENAMIENTO DE BASELINE COMPLETADO\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 📊 PARTE 4: VISUALIZACIÓN DE RESULTADOS BASELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "📊 VISUALIZACIÓN DE RESULTADOS BASELINE\n",
    "Gráficos comparativos de rendimiento\n",
    "\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configurar estilo\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"📊 GENERANDO VISUALIZACIONES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Crear figura con subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('🏗️ Comparación de Modelos Baseline', fontsize=18, fontweight='bold', y=0.995)\n",
    "\n",
    "# 1. Comparación de Accuracy (Train vs Test)\n",
    "ax1 = axes[0, 0]\n",
    "x = np.arange(len(results_df))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax1.bar(x - width/2, results_df['Train_Accuracy'], width, label='Train', alpha=0.8, color='#4CAF50')\n",
    "bars2 = ax1.bar(x + width/2, results_df['Test_Accuracy'], width, label='Test', alpha=0.8, color='#2196F3')\n",
    "\n",
    "ax1.set_xlabel('Modelo', fontweight='bold')\n",
    "ax1.set_ylabel('Accuracy', fontweight='bold')\n",
    "ax1.set_title('🎯 Train vs Test Accuracy', fontweight='bold', pad=10)\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(results_df['Model'], rotation=45, ha='right')\n",
    "ax1.legend()\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "ax1.set_ylim([0.5, 1.0])\n",
    "\n",
    "# Añadir línea de 80%\n",
    "ax1.axhline(y=0.8, color='red', linestyle='--', alpha=0.5, label='80% Baseline')\n",
    "\n",
    "# 2. Métricas por Modelo (F1, Precision, Recall)\n",
    "ax2 = axes[0, 1]\n",
    "metrics_data = results_df[['Model', 'F1_Macro', 'Precision', 'Recall']].set_index('Model')\n",
    "metrics_data.plot(kind='bar', ax=ax2, width=0.8, alpha=0.8)\n",
    "\n",
    "ax2.set_xlabel('Modelo', fontweight='bold')\n",
    "ax2.set_ylabel('Score', fontweight='bold')\n",
    "ax2.set_title('📈 Métricas de Clasificación', fontweight='bold', pad=10)\n",
    "ax2.legend(title='Métrica', loc='lower right')\n",
    "ax2.set_xticklabels(ax2.get_xticklabels(), rotation=45, ha='right')\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "ax2.set_ylim([0.5, 1.0])\n",
    "\n",
    "# 3. Overfitting Analysis\n",
    "ax3 = axes[1, 0]\n",
    "colors = ['green' if x < 0.05 else 'orange' if x < 0.1 else 'red' for x in results_df['Overfit']]\n",
    "bars = ax3.barh(results_df['Model'], results_df['Overfit'], color=colors, alpha=0.7)\n",
    "\n",
    "ax3.set_xlabel('Train Acc - Test Acc', fontweight='bold')\n",
    "ax3.set_title('⚠️ Análisis de Overfitting', fontweight='bold', pad=10)\n",
    "ax3.axvline(x=0.05, color='orange', linestyle='--', alpha=0.5, label='Overfitting Leve')\n",
    "ax3.axvline(x=0.1, color='red', linestyle='--', alpha=0.5, label='Overfitting Alto')\n",
    "ax3.legend()\n",
    "ax3.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Añadir valores en las barras\n",
    "for i, bar in enumerate(bars):\n",
    "    width = bar.get_width()\n",
    "    ax3.text(width, bar.get_y() + bar.get_height()/2, \n",
    "             f'{width:.3f}', ha='left', va='center', fontsize=9)\n",
    "\n",
    "# 4. Tiempo de Entrenamiento\n",
    "ax4 = axes[1, 1]\n",
    "ax4.barh(results_df['Model'], results_df['Train_Time'], alpha=0.8, color='#9C27B0')\n",
    "\n",
    "ax4.set_xlabel('Tiempo (segundos)', fontweight='bold')\n",
    "ax4.set_title('⏱️ Tiempo de Entrenamiento', fontweight='bold', pad=10)\n",
    "ax4.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Añadir valores en las barras\n",
    "for i, (model, time) in enumerate(zip(results_df['Model'], results_df['Train_Time'])):\n",
    "    ax4.text(time, i, f' {time:.2f}s', va='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Guardar figura\n",
    "figures_dir = REPORTS_DIR / \"figures\"\n",
    "figures_dir.mkdir(exist_ok=True)\n",
    "plt.savefig(figures_dir / \"baseline_comparison.png\", dpi=300, bbox_inches='tight')\n",
    "print(f\"\\n✅ Visualización guardada en: {figures_dir / 'baseline_comparison.png'}\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"✅ VISUALIZACIONES COMPLETADAS\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 🔢 PARTE 5: MATRICES DE CONFUSIÓN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "🔢 MATRICES DE CONFUSIÓN PARA TOP 3 MODELOS\n",
    "Análisis detallado de errores de clasificación\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"🔢 GENERANDO MATRICES DE CONFUSIÓN\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Seleccionar top 3 modelos\n",
    "top3_models = results_df.head(3)['Model'].tolist()\n",
    "\n",
    "# Crear figura\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "fig.suptitle('🔢 Matrices de Confusión - Top 3 Modelos', fontsize=16, fontweight='bold', y=1.02)\n",
    "\n",
    "for idx, model_name in enumerate(top3_models):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Obtener predicciones\n",
    "    y_pred = trained_models[model_name]['y_pred_test']\n",
    "    \n",
    "    # Calcular matriz de confusión\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Normalizar por filas (recall por clase)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    # Plot\n",
    "    sns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap='Blues', \n",
    "                xticklabels=EMOTION_LABELS, yticklabels=EMOTION_LABELS,\n",
    "                ax=ax, cbar_kws={'label': 'Proportion'})\n",
    "    \n",
    "    # Añadir conteos en las celdas\n",
    "    for i in range(len(EMOTION_LABELS)):\n",
    "        for j in range(len(EMOTION_LABELS)):\n",
    "            text = ax.text(j + 0.5, i + 0.7, f'n={cm[i, j]}',\n",
    "                          ha=\"center\", va=\"center\", color=\"gray\", fontsize=8)\n",
    "    \n",
    "    ax.set_title(f'{model_name}\\nAccuracy: {results_df[results_df[\"Model\"]==model_name][\"Test_Accuracy\"].values[0]:.4f}',\n",
    "                 fontweight='bold', pad=10)\n",
    "    ax.set_xlabel('Predicción', fontweight='bold')\n",
    "    ax.set_ylabel('Real', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(figures_dir / \"confusion_matrices_top3.png\", dpi=300, bbox_inches='tight')\n",
    "print(f\"\\n✅ Matrices guardadas en: {figures_dir / 'confusion_matrices_top3.png'}\")\n",
    "plt.show()\n",
    "\n",
    "# Análisis de errores más comunes\n",
    "print(\"\\n📊 ANÁLISIS DE ERRORES MÁS COMUNES:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for model_name in top3_models:\n",
    "    y_pred = trained_models[model_name]['y_pred_test']\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print(f\"\\n{model_name}:\")\n",
    "    \n",
    "    # Encontrar los 3 errores más comunes (excluyendo diagonal)\n",
    "    errors = []\n",
    "    for i in range(len(EMOTION_LABELS)):\n",
    "        for j in range(len(EMOTION_LABELS)):\n",
    "            if i != j:  # Excluir aciertos (diagonal)\n",
    "                errors.append((cm[i, j], EMOTION_LABELS[i], EMOTION_LABELS[j]))\n",
    "    \n",
    "    errors.sort(reverse=True)\n",
    "    \n",
    "    for count, real, pred in errors[:3]:\n",
    "        if count > 0:\n",
    "            pct = (count / cm.sum()) * 100\n",
    "            print(f\"   • {real} → {pred}: {count} veces ({pct:.1f}% del total)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"✅ MATRICES DE CONFUSIÓN COMPLETADAS\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 🎛️ PARTE 6: OPTIMIZACIÓN DE HIPERPARÁMETROS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "🎛️ OPTIMIZACIÓN DE HIPERPARÁMETROS PARA EL MEJOR MODELO\n",
    "Usando GridSearchCV para encontrar la mejor configuración\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"🎛️ OPTIMIZACIÓN DE HIPERPARÁMETROS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Seleccionar el mejor modelo baseline\n",
    "best_baseline = results_df.iloc[0]['Model']\n",
    "best_baseline_acc = results_df.iloc[0]['Test_Accuracy']\n",
    "\n",
    "print(f\"\\n🏆 Mejor modelo baseline: {best_baseline}\")\n",
    "print(f\"   Accuracy actual: {best_baseline_acc:.4f}\")\n",
    "print(f\"\\n🔍 Iniciando búsqueda de hiperparámetros...\\n\")\n",
    "\n",
    "# Definir espacios de búsqueda según el modelo\n",
    "if 'Random Forest' in best_baseline:\n",
    "    base_model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [10, 20, 30, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'max_features': ['sqrt', 'log2', None]\n",
    "    }\n",
    "    search_type = 'RandomizedSearchCV'\n",
    "    n_iter = 50\n",
    "\n",
    "elif 'XGBoost' in best_baseline:\n",
    "    from xgboost import XGBClassifier\n",
    "    base_model = XGBClassifier(random_state=42, n_jobs=-1, eval_metric='mlogloss')\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [3, 5, 7, 9],\n",
    "        'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "        'subsample': [0.7, 0.8, 0.9, 1.0],\n",
    "        'colsample_bytree': [0.7, 0.8, 0.9, 1.0]\n",
    "    }\n",
    "    search_type = 'RandomizedSearchCV'\n",
    "    n_iter = 50\n",
    "\n",
    "elif 'LightGBM' in best_baseline:\n",
    "    from lightgbm import LGBMClassifier\n",
    "    base_model = LGBMClassifier(random_state=42, n_jobs=-1, verbose=-1)\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [3, 5, 7, -1],\n",
    "        'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "        'num_leaves': [31, 50, 70, 100],\n",
    "        'subsample': [0.7, 0.8, 0.9, 1.0]\n",
    "    }\n",
    "    search_type = 'RandomizedSearchCV'\n",
    "    n_iter = 50\n",
    "\n",
    "elif 'SVM' in best_baseline:\n",
    "    base_model = SVC(random_state=42, probability=True)\n",
    "    param_grid = {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'gamma': ['scale', 'auto', 0.001, 0.01, 0.1],\n",
    "        'kernel': ['rbf', 'poly']\n",
    "    }\n",
    "    search_type = 'GridSearchCV'\n",
    "\n",
    "elif 'Logistic' in best_baseline:\n",
    "    base_model = LogisticRegression(random_state=42, n_jobs=-1, max_iter=1000)\n",
    "    param_grid = {\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "        'solver': ['saga'],\n",
    "        'l1_ratio': [0.1, 0.5, 0.9]\n",
    "    }\n",
    "    search_type = 'GridSearchCV'\n",
    "\n",
    "elif 'Gradient Boosting' in best_baseline:\n",
    "    base_model = GradientBoostingClassifier(random_state=42)\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 7, 9],\n",
    "        'subsample': [0.7, 0.8, 0.9, 1.0]\n",
    "    }\n",
    "    search_type = 'RandomizedSearchCV'\n",
    "    n_iter = 50\n",
    "\n",
    "else:\n",
    "    # Por defecto, usar el modelo existente\n",
    "    base_model = trained_models[best_baseline]['model']\n",
    "    param_grid = {}\n",
    "    search_type = 'None'\n",
    "\n",
    "print(f\"   Método de búsqueda: {search_type}\")\n",
    "print(f\"   Parámetros a explorar: {len(param_grid)} dimensiones\")\n",
    "\n",
    "# Realizar búsqueda\n",
    "if search_type == 'RandomizedSearchCV':\n",
    "    search = RandomizedSearchCV(\n",
    "        base_model,\n",
    "        param_grid,\n",
    "        n_iter=n_iter,\n",
    "        cv=5,\n",
    "        scoring='f1_macro',\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        verbose=1\n",
    "    )\n",
    "elif search_type == 'GridSearchCV':\n",
    "    search = GridSearchCV(\n",
    "        base_model,\n",
    "        param_grid,\n",
    "        cv=5,\n",
    "        scoring='f1_macro',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "else:\n",
    "    print(\"\\n⚠️  No se realizará búsqueda de hiperparámetros\")\n",
    "    best_model = base_model\n",
    "    search = None\n",
    "\n",
    "if search is not None:\n",
    "    print(f\"\\n⏳ Entrenando... (esto puede tomar varios minutos)\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    search.fit(X_train, y_train)\n",
    "    \n",
    "    search_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\n✅ Búsqueda completada en {search_time:.2f}s\")\n",
    "    \n",
    "    # Mejor modelo encontrado\n",
    "    best_model = search.best_estimator_\n",
    "    \n",
    "    print(f\"\\n🏆 MEJORES HIPERPARÁMETROS:\")\n",
    "    print(\"-\" * 80)\n",
    "    for param, value in search.best_params_.items():\n",
    "        print(f\"   • {param}: {value}\")\n",
    "    \n",
    "    print(f\"\\n📊 MEJORA EN RENDIMIENTO:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"   • CV Score (F1-Macro): {search.best_score_:.4f}\")\n",
    "    \n",
    "    # Evaluar en test set\n",
    "    y_pred_optimized = best_model.predict(X_test)\n",
    "    optimized_acc = accuracy_score(y_test, y_pred_optimized)\n",
    "    optimized_f1 = f1_score(y_test, y_pred_optimized, average='macro')\n",
    "    \n",
    "    print(f\"   • Test Accuracy: {optimized_acc:.4f} (baseline: {best_baseline_acc:.4f})\")\n",
    "    print(f\"   • Test F1-Macro: {optimized_f1:.4f}\")\n",
    "    print(f\"   • Mejora: {(optimized_acc - best_baseline_acc)*100:+.2f}%\")\n",
    "    \n",
    "    # Guardar resultados de la búsqueda\n",
    "    cv_results = pd.DataFrame(search.cv_results_)\n",
    "    cv_results_path = REPORTS_DIR / \"hyperparameter_search_results.csv\"\n",
    "    cv_results.to_csv(cv_results_path, index=False)\n",
    "    print(f\"\\n💾 Resultados de búsqueda guardados en: {cv_results_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"✅ OPTIMIZACIÓN COMPLETADA\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 📈 PARTE 7: EVALUACIÓN FINAL DEL MEJOR MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "📈 EVALUACIÓN COMPLETA DEL MODELO FINAL\n",
    "Classification report, ROC curves, y métricas detalladas\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.metrics import classification_report, roc_curve, auc, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"📈 EVALUACIÓN FINAL DEL MODELO OPTIMIZADO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Predicciones del modelo final\n",
    "y_pred_final = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)\n",
    "\n",
    "# 1. Classification Report Detallado\n",
    "print(\"\\n📊 CLASSIFICATION REPORT:\")\n",
    "print(\"-\" * 80)\n",
    "print(classification_report(\n",
    "    y_test, \n",
    "    y_pred_final, \n",
    "    target_names=EMOTION_LABELS,\n",
    "    digits=4\n",
    "))\n",
    "\n",
    "# 2. Matriz de Confusión Final\n",
    "print(\"\\n🔢 MATRIZ DE CONFUSIÓN FINAL:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "fig.suptitle(f'🏆 {best_baseline} (Optimizado) - Matriz de Confusión', \n",
    "             fontsize=14, fontweight='bold', y=1.02)\n",
    "\n",
    "# Matriz absoluta\n",
    "cm = confusion_matrix(y_test, y_pred_final)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=EMOTION_LABELS, yticklabels=EMOTION_LABELS,\n",
    "            ax=axes[0], cbar_kws={'label': 'Count'})\n",
    "axes[0].set_title('Conteos Absolutos', fontweight='bold', pad=10)\n",
    "axes[0].set_xlabel('Predicción', fontweight='bold')\n",
    "axes[0].set_ylabel('Real', fontweight='bold')\n",
    "\n",
    "# Matriz normalizada\n",
    "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(cm_norm, annot=True, fmt='.2%', cmap='Blues', \n",
    "            xticklabels=EMOTION_LABELS, yticklabels=EMOTION_LABELS,\n",
    "            ax=axes[1], cbar_kws={'label': 'Proportion'})\n",
    "axes[1].set_title('Proporciones (Recall por Clase)', fontweight='bold', pad=10)\n",
    "axes[1].set_xlabel('Predicción', fontweight='bold')\n",
    "axes[1].set_ylabel('Real', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(figures_dir / \"final_confusion_matrix.png\", dpi=300, bbox_inches='tight')\n",
    "print(f\"   ✅ Matriz guardada en: {figures_dir / 'final_confusion_matrix.png'}\")\n",
    "plt.show()\n",
    "\n",
    "# 3. Curvas ROC Multi-clase\n",
    "print(\"\\n📉 CURVAS ROC POR CLASE:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Binarizar las etiquetas\n",
    "y_test_bin = label_binarize(y_test, classes=[0, 1, 2, 3])\n",
    "n_classes = y_test_bin.shape[1]\n",
    "\n",
    "# Calcular ROC y AUC para cada clase\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_pred_proba[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC curves\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = ['#2196F3', '#4CAF50', '#FF9800', '#9C27B0']\n",
    "\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label=f'{EMOTION_LABELS[i]} (AUC = {roc_auc[i]:.4f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Random (AUC = 0.5000)')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontweight='bold', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontweight='bold', fontsize=12)\n",
    "plt.title(f'📉 Curvas ROC por Clase - {best_baseline} (Optimizado)', \n",
    "          fontweight='bold', fontsize=14, pad=15)\n",
    "plt.legend(loc=\"lower right\", fontsize=10)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(figures_dir / \"roc_curves.png\", dpi=300, bbox_inches='tight')\n",
    "print(f\"   ✅ Curvas ROC guardadas en: {figures_dir / 'roc_curves.png'}\")\n",
    "plt.show()\n",
    "\n",
    "# Imprimir AUC por clase\n",
    "print(\"\\n   AUC por Clase:\")\n",
    "for i, label in enumerate(EMOTION_LABELS):\n",
    "    print(f\"   • {label:10s}: {roc_auc[i]:.4f}\")\n",
    "\n",
    "# AUC promedio\n",
    "macro_auc = np.mean(list(roc_auc.values()))\n",
    "print(f\"\\n   • Macro-Average AUC: {macro_auc:.4f}\")\n",
    "\n",
    "# 4. Métricas Finales Consolidadas\n",
    "final_metrics = {\n",
    "    'model_name': best_baseline,\n",
    "    'is_optimized': search is not None,\n",
    "    'test_accuracy': accuracy_score(y_test, y_pred_final),\n",
    "    'test_f1_macro': f1_score(y_test, y_pred_final, average='macro'),\n",
    "    'test_f1_weighted': f1_score(y_test, y_pred_final, average='weighted'),\n",
    "    'test_precision_macro': precision_score(y_test, y_pred_final, average='macro'),\n",
    "    'test_recall_macro': recall_score(y_test, y_pred_final, average='macro'),\n",
    "    'macro_auc': macro_auc,\n",
    "    'hyperparameters': search.best_params_ if search is not None else {},\n",
    "    'confusion_matrix': cm.tolist(),\n",
    "    'class_metrics': {}\n",
    "}\n",
    "\n",
    "# Añadir métricas por clase\n",
    "for i, label in enumerate(EMOTION_LABELS):\n",
    "    mask = y_test == i\n",
    "    class_acc = accuracy_score(y_test[mask], y_pred_final[mask])\n",
    "    class_f1 = f1_score(y_test == i, y_pred_final == i)\n",
    "    \n",
    "    final_metrics['class_metrics'][label] = {\n",
    "        'accuracy': float(class_acc),\n",
    "        'f1_score': float(class_f1),\n",
    "        'auc': float(roc_auc[i]),\n",
    "        'support': int(mask.sum())\n",
    "    }\n",
    "\n",
    "# Guardar métricas finales\n",
    "final_metrics_path = REPORTS_DIR / \"final_model_evaluation.json\"\n",
    "with open(final_metrics_path, 'w') as f:\n",
    "    json.dump(final_metrics, f, indent=2)\n",
    "\n",
    "print(f\"\\n💾 Métricas finales guardadas en: {final_metrics_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"✅ EVALUACIÓN FINAL COMPLETADA\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 💾 PARTE 8: GUARDADO Y VERSIONADO DEL MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "💾 GUARDADO DEL MODELO FINAL Y VERSIONADO CON DVC\n",
    "Serialización del modelo optimizado y metadata\n",
    "\"\"\"\n",
    "\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"💾 GUARDANDO MODELO FINAL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. Crear directorio para el modelo optimizado\n",
    "optimized_dir = MODELS_DIR / \"optimized\"\n",
    "optimized_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# 2. Nombres de archivo\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "model_filename = f\"best_model_{timestamp}.pkl\"\n",
    "model_path = optimized_dir / model_filename\n",
    "\n",
    "# También guardamos una copia con nombre fijo para producción\n",
    "production_model_path = optimized_dir / \"production_model.pkl\"\n",
    "\n",
    "print(f\"\\n📦 Serializando modelo...\")\n",
    "print(f\"   • Archivo versionado: {model_filename}\")\n",
    "print(f\"   • Archivo producción: production_model.pkl\")\n",
    "\n",
    "# 3. Guardar el modelo\n",
    "joblib.dump(best_model, model_path)\n",
    "joblib.dump(best_model, production_model_path)\n",
    "\n",
    "model_size_kb = model_path.stat().st_size / 1024\n",
    "print(f\"\\n✅ Modelo guardado ({model_size_kb:.1f} KB)\")\n",
    "\n",
    "# 4. Crear metadata del modelo\n",
    "model_metadata = {\n",
    "    'model_name': best_baseline,\n",
    "    'is_optimized': search is not None,\n",
    "    'timestamp': timestamp,\n",
    "    'model_file': model_filename,\n",
    "    'model_size_kb': float(model_size_kb),\n",
    "    \n",
    "    # Métricas de entrenamiento\n",
    "    'train_samples': int(len(X_train)),\n",
    "    'test_samples': int(len(X_test)),\n",
    "    'n_features': int(X_train.shape[1]),\n",
    "    'n_classes': 4,\n",
    "    'class_labels': EMOTION_LABELS,\n",
    "    \n",
    "    # Métricas de rendimiento\n",
    "    'test_accuracy': float(final_metrics['test_accuracy']),\n",
    "    'test_f1_macro': float(final_metrics['test_f1_macro']),\n",
    "    'test_f1_weighted': float(final_metrics['test_f1_weighted']),\n",
    "    'test_precision_macro': float(final_metrics['test_precision_macro']),\n",
    "    'test_recall_macro': float(final_metrics['test_recall_macro']),\n",
    "    'macro_auc': float(final_metrics['macro_auc']),\n",
    "    \n",
    "    # Hiperparámetros\n",
    "    'hyperparameters': final_metrics['hyperparameters'],\n",
    "    \n",
    "    # Información del dataset\n",
    "    'data_split_info': split_metadata,\n",
    "    \n",
    "    # Métricas por clase\n",
    "    'class_metrics': final_metrics['class_metrics'],\n",
    "    \n",
    "    # Versiones de librerías\n",
    "    'sklearn_version': sklearn.__version__,\n",
    "    'python_version': sys.version,\n",
    "}\n",
    "\n",
    "# Guardar metadata\n",
    "metadata_path = optimized_dir / f\"model_metadata_{timestamp}.json\"\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(model_metadata, f, indent=2)\n",
    "\n",
    "# También guardamos metadata de producción\n",
    "production_metadata_path = optimized_dir / \"production_model_metadata.json\"\n",
    "with open(production_metadata_path, 'w') as f:\n",
    "    json.dump(model_metadata, f, indent=2)\n",
    "\n",
    "print(f\"\\n✅ Metadata guardada\")\n",
    "print(f\"   • {metadata_path.name}\")\n",
    "print(f\"   • production_model_metadata.json\")\n",
    "\n",
    "# 5. Guardar también los modelos baseline para comparación\n",
    "print(f\"\\n💾 Guardando modelos baseline para comparación...\")\n",
    "baseline_dir = MODELS_DIR / \"baseline\"\n",
    "baseline_dir.mkdir(exist_ok=True)\n",
    "\n",
    "for model_name in top3_models:\n",
    "    model = trained_models[model_name]['model']\n",
    "    safe_name = model_name.replace(' ', '_').replace('(', '').replace(')', '').lower()\n",
    "    baseline_path = baseline_dir / f\"{safe_name}_baseline.pkl\"\n",
    "    joblib.dump(model, baseline_path)\n",
    "    print(f\"   ✅ {model_name}\")\n",
    "\n",
    "# 6. Crear archivo .dvc para versionado\n",
    "print(f\"\\n☁️  Configurando DVC para versionado...\")\n",
    "\n",
    "# Agregar archivos a DVC\n",
    "files_to_track = [\n",
    "    production_model_path,\n",
    "    production_metadata_path\n",
    "]\n",
    "\n",
    "for file_path in files_to_track:\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            ['dvc', 'add', str(file_path)],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            cwd=PROJECT_ROOT\n",
    "        )\n",
    "        if result.returncode == 0:\n",
    "            print(f\"   ✅ {file_path.name} agregado a DVC\")\n",
    "        else:\n",
    "            print(f\"   ⚠️  Error agregando {file_path.name}: {result.stderr}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ⚠️  Error con DVC: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"✅ MODELO GUARDADO Y VERSIONADO\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\n📤 PRÓXIMOS PASOS:\")\n",
    "print(\"   1. git add models/optimized/*.dvc\")\n",
    "print(\"   2. git commit -m 'Add optimized model'\")\n",
    "print(\"   3. dvc push\")\n",
    "print(\"   4. git push\")\n",
    "print(\"\\n💡 Para cargar el modelo en producción:\")\n",
    "print(\"   import joblib\")\n",
    "print(f\"   model = joblib.load('{production_model_path}')\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 📄 PARTE 9: REPORTE FINAL DE MODELADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "📄 GENERACIÓN DEL REPORTE FINAL DE MODELADO\n",
    "Resumen ejecutivo con todos los hallazgos\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"📄 REPORTE FINAL DE MODELADO - FASE 2\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "report = f\"\"\"\n",
    "{'='*80}\n",
    "🎼 TURKISH MUSIC EMOTION CLASSIFICATION\n",
    "📊 REPORTE DE MODELADO - FASE 2\n",
    "{'='*80}\n",
    "\n",
    "📅 Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "👥 Equipo: David Cruz, Javier Rebull, Sandra Cervantes\n",
    "🏛️ Institución: ITESM - Maestría en IA Aplicada\n",
    "\n",
    "{'='*80}\n",
    "📊 RESUMEN EJECUTIVO\n",
    "{'='*80}\n",
    "\n",
    "🎯 OBJETIVO:\n",
    "   Desarrollar un modelo de clasificación multiclase para predecir emociones\n",
    "   (Happy, Sad, Angry, Relax) a partir de características acústicas de música\n",
    "   turca.\n",
    "\n",
    "📈 DATASET:\n",
    "   • Total de muestras: {len(X_train) + len(X_test):,}\n",
    "   • Training set: {len(X_train):,} ({len(X_train)/(len(X_train)+len(X_test))*100:.1f}%)\n",
    "   • Test set: {len(X_test):,} ({len(X_test)/(len(X_train)+len(X_test))*100:.1f}%)\n",
    "   • Número de features: {X_train.shape[1]}\n",
    "   • Clases: {len(EMOTION_LABELS)} (balanceadas)\n",
    "\n",
    "{'='*80}\n",
    "🏗️ MODELOS EVALUADOS (BASELINE)\n",
    "{'='*80}\n",
    "\n",
    "Se entrenaron y evaluaron {len(baseline_models)} algoritmos con configuraciones\n",
    "por defecto:\n",
    "\"\"\"\n",
    "\n",
    "# Agregar resultados de baseline\n",
    "report += \"\\n🏆 RANKING DE MODELOS BASELINE:\\n\\n\"\n",
    "for idx, row in results_df.iterrows():\n",
    "    medal = \"🥇\" if idx == 0 else \"🥈\" if idx == 1 else \"🥉\" if idx == 2 else \"  \"\n",
    "    report += f\"{medal} {idx+1}. {row['Model']:25s} | Acc: {row['Test_Accuracy']:.4f} | F1: {row['F1_Macro']:.4f}\\n\"\n",
    "\n",
    "# Mejor modelo y optimización\n",
    "report += f\"\"\"\n",
    "{'='*80}\n",
    "🎛️ OPTIMIZACIÓN DE HIPERPARÁMETROS\n",
    "{'='*80}\n",
    "\n",
    "🏆 MEJOR MODELO: {best_baseline}\n",
    "\n",
    "{'📍 CONFIGURACIÓN BASELINE:':}\n",
    "   • Test Accuracy: {best_baseline_acc:.4f}\n",
    "   • Test F1-Macro: {results_df.iloc[0]['F1_Macro']:.4f}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "if search is not None:\n",
    "    report += f\"\"\"\n",
    "🔍 BÚSQUEDA DE HIPERPARÁMETROS:\n",
    "   • Método: {search_type}\n",
    "   • Configuraciones probadas: {len(search.cv_results_['params']) if hasattr(search, 'cv_results_') else 'N/A'}\n",
    "   • Cross-validation folds: 5\n",
    "   • Métrica optimizada: F1-Macro\n",
    "\n",
    "⚙️ MEJORES HIPERPARÁMETROS:\n",
    "\"\"\"\n",
    "    for param, value in final_metrics['hyperparameters'].items():\n",
    "        report += f\"   • {param}: {value}\\n\"\n",
    "else:\n",
    "    report += \"\\n⚠️  No se realizó optimización de hiperparámetros\\n\"\n",
    "\n",
    "# Métricas finales\n",
    "report += f\"\"\"\n",
    "{'='*80}\n",
    "📊 RENDIMIENTO FINAL DEL MODELO\n",
    "{'='*80}\n",
    "\n",
    "🎯 MÉTRICAS GLOBALES:\n",
    "   • Test Accuracy: {final_metrics['test_accuracy']:.4f}\n",
    "   • Test F1-Macro: {final_metrics['test_f1_macro']:.4f}\n",
    "   • Test F1-Weighted: {final_metrics['test_f1_weighted']:.4f}\n",
    "   • Test Precision (Macro): {final_metrics['test_precision_macro']:.4f}\n",
    "   • Test Recall (Macro): {final_metrics['test_recall_macro']:.4f}\n",
    "   • Macro AUC-ROC: {final_metrics['macro_auc']:.4f}\n",
    "\n",
    "📈 MÉTRICAS POR CLASE:\n",
    "\"\"\"\n",
    "\n",
    "for emotion, metrics in final_metrics['class_metrics'].items():\n",
    "    report += f\"\\n   {emotion}:\" \n",
    "    report += f\"\\n      • Accuracy: {metrics['accuracy']:.4f}\"\n",
    "    report += f\"\\n      • F1-Score: {metrics['f1_score']:.4f}\"\n",
    "    report += f\"\\n      • AUC-ROC: {metrics['auc']:.4f}\"\n",
    "    report += f\"\\n      • Support: {metrics['support']}\\n\"\n",
    "\n",
    "# Análisis de errores\n",
    "report += f\"\"\"\n",
    "{'='*80}\n",
    "🔍 ANÁLISIS DE ERRORES\n",
    "{'='*80}\n",
    "\n",
    "🔢 MATRIZ DE CONFUSIÓN (ver visualización):\n",
    "   Las confusiones más comunes se visualizan en:\n",
    "   reports/figures/final_confusion_matrix.png\n",
    "\n",
    "💡 INSIGHTS:\n",
    "\"\"\"\n",
    "\n",
    "# Encontrar la clase con mejor y peor rendimiento\n",
    "class_f1_scores = {emotion: metrics['f1_score'] \n",
    "                   for emotion, metrics in final_metrics['class_metrics'].items()}\n",
    "best_class = max(class_f1_scores, key=class_f1_scores.get)\n",
    "worst_class = min(class_f1_scores, key=class_f1_scores.get)\n",
    "\n",
    "report += f\"\\n   • Clase mejor clasificada: {best_class} (F1: {class_f1_scores[best_class]:.4f})\"\n",
    "report += f\"\\n   • Clase más difícil: {worst_class} (F1: {class_f1_scores[worst_class]:.4f})\"\n",
    "\n",
    "# Recomendaciones\n",
    "report += f\"\"\"\n",
    "\n",
    "{'='*80}\n",
    "💡 RECOMENDACIONES Y PRÓXIMOS PASOS\n",
    "{'='*80}\n",
    "\n",
    "🔧 MEJORAS POTENCIALES:\n",
    "   1. Feature Engineering:\n",
    "      • Explorar interacciones entre features\n",
    "      • Agregar features de contexto temporal\n",
    "      • Considerar técnicas de selección de features\n",
    "\n",
    "   2. Ensemble Methods:\n",
    "      • Voting Classifier con top-3 modelos\n",
    "      • Stacking con meta-learner\n",
    "      • Blending de predicciones\n",
    "\n",
    "   3. Técnicas Avanzadas:\n",
    "      • Redes neuronales profundas (si hay más datos)\n",
    "      • Transfer learning con modelos pre-entrenados\n",
    "      • Augmentación de datos sintéticos\n",
    "\n",
    "   4. Calibración de Probabilidades:\n",
    "      • Isotonic regression o Platt scaling\n",
    "      • Para mejorar interpretabilidad de probabilidades\n",
    "\n",
    "📦 DEPLOYMENT:\n",
    "   • Modelo listo para producción en: models/optimized/production_model.pkl\n",
    "   • Metadata disponible en: models/optimized/production_model_metadata.json\n",
    "   • Versionado con DVC configurado\n",
    "\n",
    "🔄 MONITOREO:\n",
    "   • Establecer baseline de métricas actuales\n",
    "   • Monitorear drift en distribución de features\n",
    "   • Tracking de performance en producción\n",
    "   • Re-entrenamiento periódico con nuevos datos\n",
    "\n",
    "{'='*80}\n",
    "📁 ARCHIVOS GENERADOS\n",
    "{'='*80}\n",
    "\n",
    "📊 REPORTES:\n",
    "   • reports/baseline_results.csv\n",
    "   • reports/final_model_evaluation.json\n",
    "   • reports/hyperparameter_search_results.csv (si aplica)\n",
    "   • reports/modeling_report.txt (este archivo)\n",
    "\n",
    "📈 VISUALIZACIONES:\n",
    "   • reports/figures/baseline_comparison.png\n",
    "   • reports/figures/confusion_matrices_top3.png\n",
    "   • reports/figures/final_confusion_matrix.png\n",
    "   • reports/figures/roc_curves.png\n",
    "\n",
    "💾 MODELOS:\n",
    "   • models/baseline/*.pkl (modelos baseline)\n",
    "   • models/optimized/production_model.pkl\n",
    "   • models/optimized/production_model_metadata.json\n",
    "   • models/optimized/*.dvc (archivos de versionado)\n",
    "\n",
    "{'='*80}\n",
    "✅ FASE 2 COMPLETADA EXITOSAMENTE\n",
    "{'='*80}\n",
    "\n",
    "🎯 Objetivos cumplidos:\n",
    "   ✅ Modelos baseline entrenados y comparados\n",
    "   ✅ Optimización de hiperparámetros realizada\n",
    "   ✅ Evaluación completa con múltiples métricas\n",
    "   ✅ Visualizaciones generadas\n",
    "   ✅ Modelo versionado con DVC\n",
    "   ✅ Documentación completa\n",
    "\n",
    "🚀 El modelo está listo para la Fase 3: Deployment\n",
    "\n",
    "{'='*80}\n",
    "Generado: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "Equipo: David Cruz • Javier Rebull • Sandra Cervantes\n",
    "ITESM - Maestría en Inteligencia Artificial Aplicada\n",
    "{'='*80}\n",
    "\"\"\"\n",
    "\n",
    "# Imprimir reporte\n",
    "print(report)\n",
    "\n",
    "# Guardar reporte\n",
    "report_path = REPORTS_DIR / \"modeling_report.txt\"\n",
    "with open(report_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(report)\n",
    "\n",
    "print(f\"\\n💾 Reporte guardado en: {report_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"🎉 ¡NOTEBOOK COMPLETADO EXITOSAMENTE!\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\n🎵 De emociones musicales a predicciones precisas con MLOps 🤖\")\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
